summarise(pnew = mean(avg_mut[1:30]))
pnew <- mean(New_data_cutoff$avg_mut[1:30])
pnew
New_data_ordered <- New_data_summary[order(New_data_summary$avg_mut, mut, reps, decreasing=TRUE), ]
New_data_ordered <- New_data_summary[order(New_data_summary$avg_mut, New_data_summary$mut, New_data_summary$reps, decreasing=TRUE), ]
New_data_ordered
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
New_data_ordered
## This part has some magic numbers I should get rid of
## or move to user input
New_data_cutoff <- New_data_ordered[New_data_ordered$n > 50,]
New_data_cutoff
New_data_ordered %>% group_by(mut, reps) %>%
summarise(pnew = mean(avg_mut[1:10]))
pnew <- mean(New_data_cutoff$avg_mut[1:30])
pnew
pnew <- mean(New_data_cutoff$avg_mut[1:10])
pnew
New_data_cutoff[1:10,]
avg_mut[1:10]
mean(New_data_cutoff$avg_mut[1:10])
New_data_cutoff %>% group_by(mut, reps) %>%
summarise(pnew = mean(avg_mut[1:10]))
pnew <- mean(New_data_cutoff$avg_mut[1:10])
pnew
New_data_estimate <- New_data_cutoff %>% group_by(mut, reps) %>%
summarise(pnew = mean(avg_mut[1:10]))
pnew <- New_data_estimate$pnew
pnew
test <- c(10, 15, 20, 25, 30, 40, 45, 50, 55, 60)
test[1:5]
test[1:5]
quantile(test, p=0.9)
quantile(test, p=0.8)
quantile(test, p=0.1)
quantile(test, p=0.01)
test <- c(5, 10, 15, 20, 25, 30, 40, 45, 50, 55, 60, 65)
quantile(test, p=0.1)
quantile(New_data_ordered$n, prob = (1 - 30/max(New_data_ordered$fnum))
)
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, n, decreasing=TRUE), ]
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, New_data_summary$n, decreasing=TRUE), ]
New_data_ordered
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
New_data_ordered
check <- New_data_cutoff %>% group_by(mut, reps) %>%
table()
check <- New_data_cutoff %<% count(mut, reps, sort = TRUE)
check <- New_data_cutoff %>% count(mut, reps, sort = TRUE)
check
New_data_cutoff %>% count(mut, reps, sort = TRUE)
New_data_cutoff %>% ungroup() %>%
count(mut, reps, sort = TRUE)
check <- New_data_cutoff %>% ungroup() %>%
count(mut, reps, sort = TRUE)
if(sum(check$n > 50) > 0)
if(sum(check$n > 50) > 0){
print("Damn")
}
if(sum(check$n < 50) > 0){
print("Damn")
}
test <- c(1, 2, 3)
message(test)
message("test is " test)
message(paste("Test is", test, sep=": "))
?rbind
rep(seq(from = 1, to = 2), each = 3)
devtools::document()
getwd()
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::document()
devtools::load_all()
devtools::load_all()
#Analyze data with fast analysis
df_fn <- fast_analysis(df_fast)
New_data_estimate
df_fast_slim <-  df_fast[df_fast$fnum < 100, ]
df_fn <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
#Analyze data with fast analysis
pnews <- c(0.125, 0.127, 0.088, 0.083)
df_fn <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
devtools::load_all()
df_fn <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
devtools::load_all()
df_fn <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
df_fn <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
df_fn <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
df_fn
fn_list <- df_fn
df_fn <- fn_list[[1]]
### Testing out Bayesian regularization at end of fast_analysis
nreps <- max(df_fn$Replicate)
#Average over replicates
avg_df_fn <- df_fn %>% dplyr::group_by(Gene_ID, Condition) %>%
summarize(avg_logit_fn = mean(logit_fn),
sd_boot = mean(logit_fn_sd),
sd_logit_fn = sd(logit_fn))
avg_df_fn
df_fn
nrow(df_fn)
max(df_fast_slim$fnum)
fn_list[[3]]
fn_list[[3]][[1]]$pnew[(fn_list[[3]][[1]]$mut == 2) && (fn_list[[3]][[1]]$reps == 1)]
fn_list[[3]][[1]]$pnew
fn_list[[3]][[1]]$pnew[(fn_list[[3]][[1]]$mut == 2) & (fn_list[[3]][[1]]$reps == 1)]
df_fn <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list <- df_fn
df_fn <- fn_list[[1]]
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
###HETEROSKEDASTICITY???###
require(tidyverse)
library(rstan)
library(loo)
require(extrafont)
library(bayesplot)
require(EnvStats)
library(devtools)
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
setwd("C:/Users/isaac/Documents/Simon_Lab/TimeLapse_Paper/Real_Data/")
#Load cB
cB <- readRDS("cB.rds")
# Define experimental design:
samp_list <- c('JS181101', 'JS181102','JS181107', 'JS181108',
'JS181113', 'JS181114')
type_list <- c(1, 1, 1, 1, 0, 0)
mut_list <- c(1, 1, 2, 2, 1 ,2)
rep_list <- c(rep(c(1,2), times=2), 1, 1)
tl <- 2 #label time
keep_params <- c(0.2, 50) #1st entry is mut rate cutoff for control sample; second is read count cutoff
#Process cB for fast analysis
df_fast <- cBtofast(cB,
samp_list,
type_list,
mut_list,
rep_list,
tl)
#Analyze data with fast analysis
pnews <- c(0.125, 0.127, 0.088, 0.083)
df_fast_slim <-  df_fast[df_fast$fnum < 100, ]
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
getwd()
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
df_fn <- fn_list[[1]]
df_fn
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
df_fn <- fn_list[[1]]
avg_df_fn <- fn_list[[2]]
avg_df_fn
hist(avg_df_fn$sd_boot)
mean(avg_df_fn$sd_boot)
mean(avg_df_fn$sd_logit_fn)
plot(avg_df_fn$sd_boot, avg_df_fn$sd_logit_fn)
devtools::load_all()
fn_list <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
devtools::load_all()
###HETEROSKEDASTICITY???###
require(tidyverse)
library(rstan)
library(loo)
require(extrafont)
library(bayesplot)
require(EnvStats)
library(devtools)
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
setwd("C:/Users/isaac/Documents/Simon_Lab/TimeLapse_Paper/Real_Data/")
#Load cB
cB <- readRDS("cB.rds")
# Define experimental design:
samp_list <- c('JS181101', 'JS181102','JS181107', 'JS181108',
'JS181113', 'JS181114')
type_list <- c(1, 1, 1, 1, 0, 0)
mut_list <- c(1, 1, 2, 2, 1 ,2)
rep_list <- c(rep(c(1,2), times=2), 1, 1)
tl <- 2 #label time
keep_params <- c(0.2, 50) #1st entry is mut rate cutoff for control sample; second is read count cutoff
#Process cB for fast analysis
df_fast <- cBtofast(cB,
samp_list,
type_list,
mut_list,
rep_list,
tl)
#Analyze data with fast analysis
pnews <- c(0.125, 0.127, 0.088, 0.083)
df_fast_slim <-  df_fast[df_fast$fnum < 1000, ]
#Analyze data with fast analysis
pnews <- c(0.125, 0.127, 0.088, 0.083)
df_fast_slim <-  df_fast[df_fast$fnum < 1000, ]
#Analyze data with fast analysis
pnews <- c(0.125, 0.127, 0.088, 0.083)
df <- df_fast_slim
nMT <- max(df$mut)
nreps <- max(df$reps)
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnews)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
pmuts_list <- list(New_data_estimate, pold)
pold <- 0.00207
pmuts_list <- list(New_data_estimate, pold)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
message("Estimating fraction news and uncertainties")
colnames(Mut_data)
0.5/0.75
(0.5/0.75)*50
30*(0.1/0.6)
Mut_data %>% group_by(fnum, mut, reps, TC, nT) %>%
mutate(New_prob = stats::dbinom(TC, size=nT, prob=New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])) %>%
mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
mutate(News = n*(New_prob/(New_prob + Old_prob))) %>% ungroup() %>%
group_by(fnum, mut, reps) %>%
summarise(Fn_rep_est = sum(News)/sum(n))
df_fast_slim <-  df_fast[df_fast$fnum < 100, ]
df <- df_fast_slim
nMT <- max(df$mut)
nreps <- max(df$reps)
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnews)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
pold <- 0.00207
pmuts_list <- list(New_data_estimate, pold)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
Mut_data %>% group_by(fnum, mut, reps, TC, nT) %>%
mutate(New_prob = stats::dbinom(TC, size=nT, prob=New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])) %>%
mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
mutate(News = n*(New_prob/(New_prob + Old_prob))) %>% ungroup() %>%
group_by(fnum, mut, reps) %>%
summarise(Fn_rep_est = sum(News)/sum(n))
Mut_data_est <- Mut_data %>% group_by(fnum, mut, reps, TC, nT) %>%
mutate(New_prob = stats::dbinom(TC, size=nT, prob=New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])) %>%
mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
mutate(News = n*(New_prob/(New_prob + Old_prob))) %>% ungroup() %>%
group_by(fnum, mut, reps) %>%
summarise(Fn_rep_est = sum(News)/sum(n))
pnews
fn_list <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
df_fn <- fn_list[[1]]
df_fn
Fn_estimate_old <- df_fn$fn_estimate[order(df_fn$Gene_ID, df_fn$Condition, df_fn$Replicate)]
plot(Fn_rep_est_efficient, Fn_estimate_old)
Fn_rep_est_efficient <- Mut_data_est$Fn_rep_est
plot(Fn_rep_est_efficient, Fn_estimate_old)
devtools::load_all()
getwd()
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
library(Rconics)
library(RConics)
b <- c(1, -6, 11, -6)
cubic(b)
use_package("RConics")
var_pop <- 0.2
var_of_var <- 0.2
two_params <- 8*(var_pop^4)/var_of_var
b <- c(1, -(4 + 2*(var_pop^2)/var_of_var), two_params, two_params)
roots <- RConics::cubic(b)
roots
b <- c(1, 0, 0, 1)
cubic(b)
?is.real
?is.complex
b <- c(1, -(4 + 2*(var_pop^2)/var_of_var), two_params, two_params)
roots <- RConics::cubic(b)
roots[(roots > 2) && (!is.complex(roots))]
roots[(roots > 2) & (!is.complex(roots))]
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
devtools::document()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::document()
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
?log2
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))
-log(1 - inv_logit(-1.79))
inv_logit(-1.79)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
mean(c(0.2, 0.3))
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
use_package("ashr")
effects <- rnorm(1000, mean = 0, sd = 1)
ses <- rgamma(1000, shape = 1, scale = 1)
fit <- ashr::ash(effects, ses)
fit <- ashr::ash(effects, ses)$results
fit
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast_slim, pnew = pnews, pold = 0.00207)
fn_list
fn_list <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
fn_list
devtools::load_all()
fn_list <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
fn_list
fn_df <- fn_list[[3]]
sum(fn_df$lfdr < 0.05)
sum(fn_df$lfsr < 0.05)
devtools::load_all()
fn_list <- fast_analysis(df_fast, pnew = pnews, pold = 0.00207)
sum(fn_df$lfsr < 0.05)
sum(fn_df$lfdr < 0.05)
### Code for estimating new mutation rates ###
Mut_data <- df_fast[,1:9]
colnames(Mut_data) <- c("sample", "XF", "TC", "nT", "n", "fnum", "type", "mut", "reps")
##New Mutation rate Estimation
# Extract only s4U labeled data to estimate s4U mut rate
New_data <- Mut_data[Mut_data$type == 1, ]
# Calculate avg. mut rate at each row
New_data$avg_mut <- New_data$TC/New_data$nT
# Remove rows with NAs
New_data[!is.na(New_data$avg_mut),]
# calculate total number of mutations
# which is the avg. for that row of dataframe times n
# the number of reads that had the identical average
New_data$weight_mut <- New_data$avg_mut*New_data$n
# Remove rows with NAs
New_data <- New_data[!is.na(New_data$avg_mut),]
# calculate total number of mutations
# which is the avg. for that row of dataframe times n
# the number of reads that had the identical average
New_data$weight_mut <- New_data$avg_mut*New_data$n
##New Mutation rate Estimation
# Extract only s4U labeled data to estimate s4U mut rate
New_data <- Mut_data[Mut_data$type == 1, ]
# Calculate avg. mut rate at each row
New_data$avg_mut <- New_data$TC/New_data$nT
# Remove rows with NAs
New_data <- New_data[!is.na(New_data$avg_mut),]
# calculate total number of mutations
# which is the avg. for that row of dataframe times n
# the number of reads that had the identical average
New_data$weight_mut <- New_data$avg_mut*New_data$n
# This is to estimate the total mutation rate for each gene in
# each replicate and each experimental condition
# Kind of slow and I wish I could speed it up, maybe using data.table?
New_data_summary <- New_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::do(purrr::invoke_map_dfc(list(purrr::map_df), #
list(list(dplyr::select(., weight_mut), sum),
list(dplyr::select(., n), sum))
)
)
New_data_summary
New_data
New_data_summary2 <- New_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n))
# Estimate avg. mutation rate for every gene-sample combo
New_data_summary$avg_mut <- New_data_summary$weight_mut/New_data_summary$n
New_data_summary2
New_data_summary
plot(New_data_summary$avg_mut, New_data_summary2$avg_mut)
devtools::load_all()
fn_list <- fast_analysis(df_fast)
New_data_ordered <- New_data_summary2[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
New_data_ordered
New_data_summary2 <- New_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n), n = sum(n))
New_data_ordered <- New_data_summary2[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
New_data_cutoff <- New_data_ordered[New_data_ordered$n > read_cut,]
read_cut <- 50
New_data_cutoff <- New_data_ordered[New_data_ordered$n > read_cut,]
New_data_cutoff
devtools::load_all()
fn_list <- fast_analysis(df_fast)
fn_list
?ashr::ash
effect_df <- fn_list[[3]]
effect_df
effects <- effect_df$effects
ses <- effect_df$ses
fit <- ash(effects, ses, method = "fdr")
fit <- ashr::ash(effects, ses, method = "fdr")
fit
fit$result$lfsr
plot(fit$result$lfdr, effect_df$lfdr)
devtools::load_all()
fn_list <- fast_analysis(df_fast)
fn_list
logit(0.25)
qnorm(0.25)
qnorm(0.25)/sqrt(pi/8)
qs <- seq(from = 0.01, to = 0.99, length.out = 1000)
plot(logit(qs), qnorm(qs))
abline(a = 1)
abline(coef = 1)
qs <- seq(from = 0.01, to = 0.99, length.out = 1000)
plot(logit(qs), qnorm(qs))
abline(coef = 1)
abline(coef = c(0, 1))
qs <- seq(from = 0.01, to = 0.99, length.out = 1000)
plot(logit(qs), qnorm(qs)/sqrt(pi/8))
abline(coef = c(0, 1))
fn_list
test1 <- c(1, 2, 3)
test2 <- c("Hello","Goodbye", "Bon Jour", "Au Revoir")
test3 <- matrix(1:4, nrow=2, ncol =2)
test_list <- list(test1, test2, test3)
names(test_list) <- c("Numbers", "Salutations", "List")
test_list$Numbers
devtools::load_all()
fn_list <- fast_analysis(df_fast)
fn_list$Mut_rates
fn_list$Hyperparams
fn_list$Regularized_ests
fn_list$Effects_df
fn_list$Hyperparams$
1
fn_list <- fast_analysis(df_fast, read_cut = 100)
effects_df <- fn_list$Effects_df
sum(effects_df$lfdr < 0.05)
sum(effects_df$lfsr < 0.05)
fn_list <- fast_analysis(df_fast, read_cut = 30)
effects_df <- fn_list$Effects_df
sum(effects_df$lfsr < 0.05)
sum(effects_df$lfdr < 0.05)
2^-12
log2(0.075)
log2(0.0075)
