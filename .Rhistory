cB_sim_1$sample <- as.character(cB_sim_1$sample)
DynData <- DynamicSeqData(cB_sim_1, metadf)
Fit <- DynamicSeqFit(DynData, features_cut = 10)
DynamicSeqFit(Fit, HybridFit = TRUE, Pooled = FALSE, StanFit = FALSE, chains = 2)
DynamicSeqFit(Fit, HybridFit = TRUE, Pooled = FALSE, StanFit = FALSE, chains = 1)
Fit <- DynamicSeqFit(Fit, HybridFit = TRUE, Pooled = FALSE, StanFit = FALSE, chains = 1)
colnames(Fit$Hybrid_Fit)
colnames(Fit$Hybrid_Fit$Effects_df)
colnames(Fit$Hybrid_Fit$Kdeg_df)
colnames(Fit$Hybrid_Fit$Fn_Estimates)
colnames(Fit$Hybrid_Fit$Fit_Summary)
devtools::document()
?TL_stan
devtools::document()
?summarise
devtools::load_all()
devtools::load_all()
devtools::document()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15)
devtools::document()
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 25, read_cut = 100)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = FALSE, features_cut = 15, read_cut = 100)
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15, read_cut = 100)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 5, read_cut = 100)
Fits
ls
?match.arg
devtools::document()
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 5, read_cut = 100)
?seq_along
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 5, read_cut = 100)
unique(DynData$cB$sample)
seq_along(samp_list)
samp_list <- unique(DynData$cB$sample)
samp_list[1]
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 5, read_cut = 100)
Fits$Data_lists$Count_Matrix
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 5, read_cut = 100)
Fits$Data_lists$Count_Matrix
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Data/Real_cBs/")
cB <- readRDS("cB.rds")
rm(cB_sim_1)
rm(DynData)
rm(Fits)
rm(Fit)
unique(cB$sample)
cB <- cB %>% select(XF, nT, TC, sample, n)
metadf <- data.frame(tl = c(2, 2, 2, 2, 0, 0),
Exp_ID = c(1L, 1L, 2L, 2L, 1L, 2L))
rownames(metadf) <- unique(cB$sample)
DynData <- DynamicSeqData(cB, metadf)
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, no_ctl = TRUE, features_cut = 15)
fast_analysis(Fits$Data_lists$Fast_df, features_cut = 15)
plotVolcano(Fits$Fast_Fit)
plotVolcano(Fits$Fast_Fit) + geom_point(size = 1)
plotVolcano(Fits$Fast_Fit) + geom_point(size = 3)
plotVolcano(Fits$Fast_Fit) + geom_point(size = 0.5)
plotVolcano(Fits$Fast_Fit) + geom_point(size = 0.5) + theme_mds
sum((Fits$Fast_Fit$Effects_df$padj < 0.05) & (Fits$Fast_Fit$Effects_df$effects < 0) )
sum((Fits$Fast_Fit$Effects_df$padj < 0.05) & (Fits$Fast_Fit$Effects_df$effects > 0) )
## Load fully hierarchical fit and compare
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Model_Refinement/Fits/Heterosked_Models/DCP2/")
fit_pool <- readRDS("DCP2_pooled_model_summary_2021_09_30.rds")
eff_df <- fit_pool[grepl("eff\\[", fit_pool$variable) & !grepl("TL_lambda_eff\\[", fit_pool$variable) ,]
L2FC_df <- fit_pool[grepl("L2FC_kd\\[", fit_pool$variable) & !grepl("TL_lambda_eff\\[", fit_pool$variable) ,]
eff_df
eff_df$FN <- 1:nrow(eff_df)
L2FC_df$FN <- 1:nrow(L2FC_df)
Fits$Fast_Fit$Effects_df
Fast_effects <- Fits$Fast_Fit$Effects_df
nrow(Fast_effects)
nrow(L2FC_df)
## Create dataframe with both analyses
compare_df <- data.frame(Stan_eff = eff_df$mean, Stan_eff_sd = eff_df$sd,
Stan_L2FC = L2FC_df$mean,
Fast_eff = Fast_effects$effects, Fast_eff_sd = Fast_effects$ses,
Fast_L2FC = Fast_effects$L2FC_kdegs)
ggplot(compare_df, aes(x = Stan_eff, y = Fast_eff)) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0, color = "red")
ggplot(compare_df, aes(x = Stan_eff, y = Fast_eff)) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0, color = "red") +
theme_mds +
xlab("Stan Effect Size Estimate") +
ylab("Fast Effect Size Estimate")
compare_df <- compare_df %>% mutate(Stan_pval = 2*pt(-abs(Stan_eff/Stan_eff_sd), df = 2 + Fits$Fast_Fit$Hyper_Parameters[1]))
compare_df$Fast_pval <- Fast_effects$padj
sig_df <- compare_df %>% mutate(Stan_sig = ifelse(Stan_pval < 0.05, ifelse(Stan_eff < 0, "Stabilized", "Destabilized"), "Not Sig" ),
Fast_sig = ifelse(Fast_pval < 0.05, ifelse(Fast_eff < 0, "Stabilized", "Destabilized"), "Not Sig" ))
table(sig_df$Stan_sig, sig_df$Fast_sig)
### Now look at real data
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
## Perform fast fit only
Fits <- DynamicSeqFit(DynData, StanFit = FALSE, HybridFit = FALSE, features_cut = 15)
plotVolcano(Fits$Fast_Fit) + geom_point(size = 0.5) + theme_mds
sum((Fits$Fast_Fit$Effects_df$padj < 0.05) & (Fits$Fast_Fit$Effects_df$effects > 0) )
## Load fully hierarchical fit and compare
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Model_Refinement/Fits/Heterosked_Models/DCP2/")
Fast_effects <- Fits$Fast_Fit$Effects_df
## Create dataframe with both analyses
compare_df <- data.frame(Stan_eff = eff_df$mean, Stan_eff_sd = eff_df$sd,
Stan_L2FC = L2FC_df$mean,
Fast_eff = Fast_effects$effects, Fast_eff_sd = Fast_effects$ses,
Fast_L2FC = Fast_effects$L2FC_kdegs)
ggplot(compare_df, aes(x = Stan_eff, y = Fast_eff)) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0, color = "red") +
theme_mds +
xlab("Stan Effect Size Estimate") +
ylab("Fast Effect Size Estimate")
ggplot(compare_df, aes(x = Stan_eff_sd, y = Fast_eff_sd)) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0, color = "red") +
theme_mds +
xlab("Stan Effect Size Uncertainty") +
ylab("Fast Effect Size Uncertainty")
compare_df <- compare_df %>% mutate(Stan_pval = 2*pt(-abs(Stan_eff/Stan_eff_sd), df = 2 + Fits$Fast_Fit$Hyper_Parameters[1]))
compare_df$Fast_pval <- Fast_effects$padj
sig_df <- compare_df %>% mutate(Stan_sig = ifelse(Stan_pval < 0.05, ifelse(Stan_eff < 0, "Stabilized", "Destabilized"), "Not Sig" ),
Fast_sig = ifelse(Fast_pval < 0.05, ifelse(Fast_eff < 0, "Stabilized", "Destabilized"), "Not Sig" ))
table(sig_df$Stan_sig, sig_df$Fast_sig)
sum((Fits$Fast_Fit$Effects_df$padj < 0.05) & (Fits$Fast_Fit$Effects_df$effects < 0) )
FnPCA(Fits$Fast_Fit)
fit_pool[order(fit_pool$ess_bulk),]
fit_pool[order(fit_pool$ess_bulk),]$variable
fit_pool[grep("a\\[", fit_pool$variable),]
fit_pool[grepl("a\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("b\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("mu_e\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("sig_e\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("z_e\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("z_fn\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("frac_new\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("L2FC_kd\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("alpha\\[", fit_pool$variable) & !grepl("alpha", fit_pool$variable),]
fit_pool[grepl("alpha\\[", fit_pool$variable),]
fit_pool[grepl("logit_fn", fit_pool$variable),]
Fits$Data_lists$Stan_data$sdf
getwd()
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
load_all()
# Libraries:
library(rstan)
library(rethinking)
library(tidyverse)
library(bayesplot)
library(viridis)
library(pracma)
library('VGAM')
# Plotting theme
theme_mds <-    theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line.x = element_line(colour = "black"),
axis.line.y = element_line(colour = "black"),
axis.ticks = element_line(colour = "black"),
axis.text = element_text(color="black", size = 12),
axis.title = element_text(color="black", size = 18),
strip.background = element_blank())
# Load stan
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#######BEGIN USER INPUT#######
#Label time (in minutes)
tl <- 60
StanSeq <- FALSE
efficient <- FALSE
#TL parameters
p_new <- 0.09       #New mutation rate
p_old <- 0.001       #Old mutation rate
read_lengths <- 200  #Read length
p_do <- 0            #Dropout probability
#Number of genes to simulate
ngene <- 100
#Number of experimental Conditions to simulate
num_conds <- 2
#Number of replicates of each experimental condition to simulate
nreps <- 3
#Standard deviation for L2FC of kdeg (L2FC_kd)
noise_deg_a <- -0.3
noise_deg_b <- -1.5
#Standard deviation for L2FC of ksyn (L2FC_ks)
noise_synth <- 0.1
# sd of Normal distribution from which non-null effects drawn
eff_sd <- 1
eff_mean <- 0
#Minimum L2FC_ks for significantly changing genes
low_L2FC_ks <- -1.0
#Max L2FC_ks for significantly changing genes
high_L2FC_ks <- -0.1
#Number of transcripts that have a significant L2FC_kd in each experimental condition
#L2FC is always relative to the first condition (the WT condition)
num_kd_DE <- c(0, rep(round(ngene/2), times = num_conds-1))
#Number of transcripts that have a significant L2FC_ks in each experimental condition
num_ks_DE <- rep(0, times = num_conds)
#If TRUE, simulates read counts from Negative binomial using ks/kd and scale_factor
sim_read_counts <- TRUE
#Scale factor for Read Count simulation; Only relevant if sim_read_counts is TRUE
scale_factor <- 500 #(one RNA molecule per cell corresponds to <scale_factor> sequencing read per replicate, on average)
#Set number of sequencing reads to be simulated; Only relevant if sim_read_counts is FALSE
nreads <- 50
#If TRUE, you can customize fn matrix before simulation function declaration
Custom <- FALSE
if(length(p_new) ==1){
p_new <- rep(p_new, times=num_conds)
}
if(length(p_old) == 1){
p_old <- rep(p_old, times=num_conds)
}
if(length(read_lengths) == 1){
read_lengths <- rep(read_lengths, times=num_conds)
}
if(length(p_do) == 1){
p_do <- rep(p_do, times=num_conds)
}
# Load stan options
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# Define helper functions:
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))
#Initialize matrices
fn <- rep(0, times=ngene*nreps*num_conds)
dim(fn) <- c(ngene, num_conds, nreps)
Counts <- fn
kd <- fn
ks <- fn
#Initialize vectors of mean values for each gene and condition
fn_mean_WT <- rep(0, times=ngene)
fn_mean <- inv_logit(rnorm(n=ngene, mean=0, sd=1.5))
kd_mean <- -log(1-fn_mean)/tl
ks_mean <- rexp(n=ngene, rate=1/(kd_mean*5))
effect_mean <- rep(0, times = ngene*num_conds)
dim(effect_mean) <- c(ngene, num_conds)
L2FC_ks_mean <- effect_mean
L2FC_kd_mean <- effect_mean
for(i in 1:ngene){
#Make sure the user didn't input the wrong
#number of significant genes
if (i == 1 ){
if (length(num_kd_DE) > num_conds){
print("num_kd_DE has too many elements")
break
} else if (length(num_kd_DE) < num_conds){
print("num_kd_DE has too few elements")
break
}
if (length(num_ks_DE) > num_conds){
print("num_ks_DE has too many elements")
break
} else if (length(num_ks_DE) < num_conds){
print("num_ks_DE has too few elements")
break
}
}
for(j in 1:num_conds){
if(j == 1){
effect_mean[i,1] <- 0
L2FC_ks_mean[i,1] <- 0
}else{
if(i < (ngene-num_kd_DE[j] + 1)){
effect_mean[i,j] <- 0
}else{
effect_mean[i,j] <- rnorm(n=1, mean=eff_mean, sd=eff_sd)
}
if(i < (ngene-num_ks_DE[j] + 1)){
L2FC_ks_mean[i,j] <- 0
}else{
if (runif(1) < 0.5){
L2FC_ks_mean[i,j] <- runif(n=1, min=low_L2FC_ks, max=high_L2FC_ks)
}else{
L2FC_ks_mean[i,j] <- runif(n=1, min=-high_L2FC_ks, max=-low_L2FC_ks)
}
}
}
}
}
L2FC_kd_mean <- log2(log(1 - inv_logit(fn_mean + effect_mean))/log(1- inv_logit(fn_mean)))
#Simulate read counts
if (sim_read_counts == TRUE){
L2FC_tot_mean <- L2FC_ks_mean - L2FC_kd_mean
RNA_conc <- (ks_mean*2^(L2FC_ks_mean))/(kd_mean*2^(L2FC_kd_mean))
a1 <- 5
a0 <- 0.01
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
Counts[i, j, k] <- rnbinom(n=1, size=1/((a1/(scale_factor*RNA_conc[i,j])) + a0), mu = scale_factor*RNA_conc[i,j])
#Counts[i, j, k] <- rpois(n=1, lambda = scale_factor*RNA_conc[i,j,k])
if(Counts[i, j, k] < 5){
Counts[i, j, k] <- Counts[i, j, k] + rpois(n=1, lambda = 2) + 1
}
}
}
}
} else{
if(sim_from_data == FALSE){
Counts <- rep(nreads, times= ngene*num_conds*nreps)
dim(Counts) <- c(ngene, num_conds, nreps)
}
}
hist(Counts)
plot(log10(Counts[,1,1]), log10(Counts[,1,2]), xlim=c(1, 4))
#SIMULATE L2FC OF DEG AND SYNTH RATE CONSTANTS; REPLICATE VARIABILITY SIMULATED
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
standard_RNA <- (log10(RNA_conc[i,j]*scale_factor) - mean(log10(RNA_conc[,j]*scale_factor)))/sd(log10(RNA_conc[,j]*scale_factor))
fn[i, j, k] <- inv_logit(rnorm(1, mean=(logit(fn_mean[i]) + effect_mean[i,j]), sd = exp(noise_deg_a*log10(RNA_conc[i,j]*scale_factor) + noise_deg_b )))
ks[i,j,k] <- exp(rnorm(1, mean=log((2^L2FC_ks_mean[i,j])*ks_mean[i]), sd=noise_synth))
}
}
}
kd <- -log(1 - fn)/tl
###Custom fn###
if(Custom == TRUE){
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
if( i < 101){
fn[i,j,k] <- 0.1
}else if(i < 201){
fn[i,j,k] <- 0.5
}else{
fn[i,j,k] <- 0.9
}
}
}
}
}
l <- ngene
p_do <- matrix(rep(0, times = num_conds*nreps), nrow = nreps, ncol = num_conds)
fn_real <- fn
for(j in 1:num_conds){
for(k in 1:nreps){
fn_real[,j,k] <- (fn[,j,k]*(1-p_do[k,j]))/(1 - p_do[k,j]*(1 - fn[,j,k]))
Counts[,j,k] <- Counts[,j,k] - Counts[,j,k]*fn[,j,k]*p_do[k,j]
}
}
# This is one very huge function
# It simulates TL-seq data, recording the number of TC mutations in each read, which is informed
# by whatever the fraction new for the particular transcript is
simulateData <- function(nmir = l,   # num of genes
fn_s4U = fn_real,   # fraction of s4U reads made after label introduction in non-heatshocked sample
#fn_s4U2 = fn_hs, # fraction of s4U reads made after label introduction in heatshocked sample
p_new_real_tc = p_new,                   # TC mutation rate in fed cells
p_old_real_tc = p_old,                  # TC mutation rate in unfed cells
read_length = read_lengths,
nreads = Counts, # per transript per sample
nsamp = (nreps*num_conds) + num_conds,
ctl = c(rep(1, times=nreps*num_conds), rep(0, times=num_conds)),   # cntl = 0 is no feed, cntl = 1 is feed
mt = c(rep(1:num_conds, each=nreps),seq(from=1,to=num_conds,by=1)),
replicate = c(rep(seq(from=1, to=nreps), times=num_conds), rep(1, times=num_conds))
#Could just generalize this, which is what next line does, repeating 1 for all but the last sample
#ctl = c(rep(1, times = nsamp-1),0) #assumes nsamp is odd, think it has to be
){
# mir_pnew_logit_tc <- rnorm(nmir, mean = logit(p_new_real_tc), sd = 0.2)  # Calculates an s4U mutation probability within given range
# mir_pnew_tc <- inv_logit(mir_pnew_logit_tc)   # figure out what the probability values actual are (unlogit the logit)
#
#
# mir_pold_logit_tc <- rnorm(nmir, mean = logit(p_old_real_tc), sd = 0.2)  # Calculates a background mutation probability within a given range
# mir_pold_tc <- inv_logit(mir_pold_logit_tc)  #unlogit the logit
# Start generating a vector with data
sample_data <- vector('list', length = nsamp)
for (s in 1:nsamp){
mir_data <- vector('list', length = nmir)
for (mir in 1:nmir){ #mir is feature number index, should change to gene or something
r <- replicate[s] #Replicate number index
MT <- mt[s]       #Experimental sample index
readsize = read_length[mt[s]]
mir_pold_tc <- p_old[mt[s]]
mir_pnew_tc <- p_new[mt[s]]
#Simulate which reads are labeled
newreads_tc <- rbernoulli(nreads[mir, MT, r], p = fn_s4U[mir, MT, r])# vector of reads, T/F is s4U labeled
#Simulate the nubmer of Us in each read
nu <- rbinom(n = nreads[mir,MT,r], size = readsize, prob = 0.25)
#Number of reads that are new
newreads_tc <- sum(newreads_tc)
#Generate number of mutations for new and old reads
if (!ctl[s]){ #If no s4U added, only old
nmut_tc <- rbinom(n = nreads[mir,MT,r], size=nu, prob = mir_pold_tc)
}else {
nmut_tc_new <- rbinom(n=newreads_tc, size=nu[1:newreads_tc], prob=mir_pnew_tc)
nmut_tc_old <- rbinom(n=(nreads[mir, MT, r]-newreads_tc), size = nu[(newreads_tc+1):nreads[mir, MT, r]], prob=mir_pold_tc)
nmut_tc <- c(nmut_tc_new, nmut_tc_old)
}
#Now make it look kind of like a cB file
# use mirMut for each gene, cntl is if cntl or not, x is # of new reads
df <- tibble(S = rep(s, times = nreads[mir, MT, r]),  #starting to generate something that looks like a cB file
TP = rep(ctl[s], times = nreads[mir, MT, r]),
R = rep(r, times=nreads[mir, MT, r]),
MIR = rep(mir, times = nreads[mir, MT, r]), # same as XF or fnum, so just feature number
TC = nmut_tc,
MT = rep(mt[s], times=nreads[mir, MT, r]),
num_us = nu)
#rep_data[[r]] <- df
#rep_data <- bind_rows(rep_data)
mir_data[[mir]] <- df
}
mir_data <- bind_rows(mir_data)
sample_data[[s]] <- mir_data
}
sample_data <- bind_rows(sample_data)
sim_df <- list(nmir = nmir,
fn_s4U = fn_s4U,
p_new_real_tc = p_new_real_tc,
p_old_real_tc = p_old_real_tc,
nreads = nreads, # per miR per sample
nsamp = nsamp,
ctl = ctl,
mir_pnew_tc = mir_pnew_tc,
mir_pold_tc = mir_pold_tc,
sample_data = sample_data
)
return(sim_df)   # return a list of all the things we should know.
}
for(i in Counts){
test <- rbinom(n = i, size= 200, prob = 0.25)
}
rm(test)
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Model_Refinement/Simulations/")
sim_df <- simulateData()
## Analyze with fast_analysis
sim_df_1 <- sim_df
# Extract simulated cB and summarise data
cB_sim_1 <- sim_df_1$sample_data
cB_sim_1 <- cB_sim_1 %>% group_by(S, TP, R, MIR, TC, MT, num_us) %>%
tally()
rm(sim_df_1)
# Define XF column
cB_sim_1$XF <- cB_sim_1$MIR
samp_list <- unique(cB_sim_1$S)
type_list <- rep(0, times=length(samp_list))
mut_list <- rep(0, times = length(samp_list))
rep_list <- rep(0, times = length(samp_list))
tl <- 1
count <- 1
for(i in samp_list){
type_list[count] <- unique(cB_sim_1$TP[cB_sim_1$S == i])
rep_list[count] <- unique(cB_sim_1$R[cB_sim_1$S == i])
mut_list[count] <- unique(cB_sim_1$MT[cB_sim_1$S == i])
count <- count + 1
}
keep_params <- c(0.2, 30)
colnames(cB_sim_1) <- c("sample", "TP", "R", "MIR", "TC", "MT", "nT", "n", "XF")
### TEST STAN ###
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
metadf <- data.frame(tl = type_list, Exp_ID = as.integer(mut_list))
rownames(metadf) <- unique(cB_sim_1$sample)
cB_sim_1$sample <- as.character(cB_sim_1$sample)
DynData <- DynamicSeqData(cB_sim_1, metadf)
cB_data <- cBprocess(DynData,
keep_input = keep_params,
Fast = TRUE)
Fit <- DynamicSeqFit(DynData, features_cut = 10)
Fit <- DynamicSeqFit(Fit, HybridFit = TRUE, Pooled = TRUE, StanFit = FALSE, chains = 1)
Fit$Data_lists$Stan_data$sdf[,c("XF", "fnum")] %>% dplyr::distinct()
devtools::load_all()
Fit <- DynamicSeqFit(Fit, HybridFit = TRUE, Pooled = TRUE, StanFit = FALSE, chains = 1)
Fit$Hybrid_Fit$Effects_df
colnames(Fit$Hybrid_Fit$Effects_df)
colnames(Fit$Hybrid_Fit$Kdeg_df)
colnames(Fit$Hybrid_Fit$Fn_Estimates)
names(Fit$Data_lists$Stan_data)
names(Fit$Data_lists)
colnames(Fit$Data_lists$Fast_df)
devtools::document()
?cBprocess
?rnorm
?rnbinom
?log10
?sd
?mean
?vector
?rbernoulli
?rbinom
?tibble
?bind_rows
?tally
