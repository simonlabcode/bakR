low_L2FC_ks <- -1.0
#Max L2FC_ks for significantly changing genes
high_L2FC_ks <- -0.1
#Number of transcripts that have a significant L2FC_kd in each experimental condition
#L2FC is always relative to the first condition (the WT condition)
num_kd_DE <- c(0, 40)
#Number of transcripts that have a significant L2FC_ks in each experimental condition
num_ks_DE <- rep(0, times = num_conds)
#If TRUE, simulates read counts from Negative binomial using ks/kd and scale_factor
sim_read_counts <- TRUE
#Scale factor for Read Count simulation; Only relevant if sim_read_counts is TRUE
scale_factor <- 200 #(one RNA molecule per cell corresponds to <scale_factor> sequencing read per replicate, on average)
#Set number of sequencing reads to be simulated; Only relevant if sim_read_counts is FALSE
nreads <- 50
#If TRUE, you can customize fn matrix before simulation function declaration
Custom <- FALSE
if(length(p_new) ==1){
p_new <- rep(p_new, times=num_conds)
}
if(length(p_old) == 1){
p_old <- rep(p_old, times=num_conds)
}
if(length(read_lengths) == 1){
read_lengths <- rep(read_lengths, times=num_conds)
}
if(length(p_do) == 1){
p_do <- rep(p_do, times=num_conds)
}
# Define helper functions:
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))
#Initialize matrices
fn <- rep(0, times=ngene*nreps*num_conds)
dim(fn) <- c(ngene, num_conds, nreps)
Counts <- fn
kd <- fn
ks <- fn
#Initialize vectors of mean values for each gene and condition
fn_mean_WT <- rep(0, times=ngene)
fn_mean <- inv_logit(rnorm(n=ngene, mean=0, sd=1.5))
kd_mean <- -log(1-fn_mean)/tl
ks_mean <- rexp(n=ngene, rate=1/(kd_mean*5))
effect_mean <- rep(0, times = ngene*num_conds)
dim(effect_mean) <- c(ngene, num_conds)
L2FC_ks_mean <- effect_mean
L2FC_kd_mean <- effect_mean
for(i in 1:ngene){
#Make sure the user didn't input the wrong
#number of significant genes
if (i == 1 ){
if (length(num_kd_DE) > num_conds){
print("num_kd_DE has too many elements")
break
} else if (length(num_kd_DE) < num_conds){
print("num_kd_DE has too few elements")
break
}
if (length(num_ks_DE) > num_conds){
print("num_ks_DE has too many elements")
break
} else if (length(num_ks_DE) < num_conds){
print("num_ks_DE has too few elements")
break
}
}
for(j in 1:num_conds){
if(j == 1){
effect_mean[i,1] <- 0
L2FC_ks_mean[i,1] <- 0
}else{
if(i < (ngene-num_kd_DE[j] + 1)){
effect_mean[i,j] <- 0
}else{
effect_mean[i,j] <- rnorm(n=1, mean=eff_mean, sd=eff_sd)
}
if(i < (ngene-num_ks_DE[j] + 1)){
L2FC_ks_mean[i,j] <- 0
}else{
if (runif(1) < 0.5){
L2FC_ks_mean[i,j] <- runif(n=1, min=low_L2FC_ks, max=high_L2FC_ks)
}else{
L2FC_ks_mean[i,j] <- runif(n=1, min=-high_L2FC_ks, max=-low_L2FC_ks)
}
}
}
}
}
L2FC_kd_mean <- log2(log(1 - inv_logit(fn_mean + effect_mean))/log(1- inv_logit(fn_mean)))
#Simulate read counts
if (sim_read_counts == TRUE){
L2FC_tot_mean <- L2FC_ks_mean - L2FC_kd_mean
RNA_conc <- (ks_mean*2^(L2FC_ks_mean))/(kd_mean*2^(L2FC_kd_mean))
a1 <- 5
a0 <- 0.01
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
Counts[i, j, k] <- rnbinom(n=1, size=1/((a1/(scale_factor*RNA_conc[i,j])) + a0), mu = scale_factor*RNA_conc[i,j])
#Counts[i, j, k] <- rpois(n=1, lambda = scale_factor*RNA_conc[i,j,k])
if(Counts[i, j, k] < 5){
Counts[i, j, k] <- Counts[i, j, k] + rpois(n=1, lambda = 2) + 1
}
}
}
}
} else{
if(sim_from_data == FALSE){
Counts <- rep(nreads, times= ngene*num_conds*nreps)
dim(Counts) <- c(ngene, num_conds, nreps)
}
}
hist(Counts)
plot(log10(Counts[,1,1]), log10(Counts[,1,2]), xlim=c(1, 4))
#SIMULATE L2FC OF DEG AND SYNTH RATE CONSTANTS; REPLICATE VARIABILITY SIMULATED
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
standard_RNA <- (log10(RNA_conc[i,j]*scale_factor) - mean(log10(RNA_conc[,j]*scale_factor)))/sd(log10(RNA_conc[,j]*scale_factor))
fn[i, j, k] <- inv_logit(rnorm(1, mean=(logit(fn_mean[i]) + effect_mean[i,j]), sd = rlnorm(1, noise_deg_a*standard_RNA + noise_deg_b, sd_rep )))
ks[i,j,k] <- exp(rnorm(1, mean=log((2^L2FC_ks_mean[i,j])*ks_mean[i]), sd=noise_synth))
}
}
}
kd <- -log(1 - fn)/tl
###Custom fn###
if(Custom == TRUE){
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
if( i < 101){
fn[i,j,k] <- 0.1
}else if(i < 201){
fn[i,j,k] <- 0.5
}else{
fn[i,j,k] <- 0.9
}
}
}
}
}
l <- ngene
p_do <- matrix(rep(0, times = num_conds*nreps), nrow = nreps, ncol = num_conds)
fn_real <- fn
for(j in 1:num_conds){
for(k in 1:nreps){
fn_real[,j,k] <- (fn[,j,k]*(1-p_do[k,j]))/(1 - p_do[k,j]*(1 - fn[,j,k]))
Counts[,j,k] <- Counts[,j,k] - Counts[,j,k]*fn[,j,k]*p_do[k,j]
}
}
# This is one very huge function
# It simulates TL-seq data, recording the number of TC mutations in each read, which is informed
# by whatever the fraction new for the particular transcript is
simulateData <- function(nmir = l,   # num of genes
fn_s4U = fn_real,   # fraction of s4U reads made after label introduction in non-heatshocked sample
#fn_s4U2 = fn_hs, # fraction of s4U reads made after label introduction in heatshocked sample
p_new_real_tc = p_new,                   # TC mutation rate in fed cells
p_old_real_tc = p_old,                  # TC mutation rate in unfed cells
read_length = read_lengths,
nreads = Counts, # per transript per sample
nsamp = (nreps*num_conds) + num_conds,
ctl = c(rep(1, times=nreps*num_conds), rep(0, times=num_conds)),   # cntl = 0 is no feed, cntl = 1 is feed
mt = c(rep(1:num_conds, each=nreps),seq(from=1,to=num_conds,by=1)),
replicate = c(rep(seq(from=1, to=nreps), times=num_conds), rep(1, times=num_conds))
#Could just generalize this, which is what next line does, repeating 1 for all but the last sample
#ctl = c(rep(1, times = nsamp-1),0) #assumes nsamp is odd, think it has to be
){
# mir_pnew_logit_tc <- rnorm(nmir, mean = logit(p_new_real_tc), sd = 0.2)  # Calculates an s4U mutation probability within given range
# mir_pnew_tc <- inv_logit(mir_pnew_logit_tc)   # figure out what the probability values actual are (unlogit the logit)
#
#
# mir_pold_logit_tc <- rnorm(nmir, mean = logit(p_old_real_tc), sd = 0.2)  # Calculates a background mutation probability within a given range
# mir_pold_tc <- inv_logit(mir_pold_logit_tc)  #unlogit the logit
# Start generating a vector with data
sample_data <- vector('list', length = nsamp)
for (s in 1:nsamp){
mir_data <- vector('list', length = nmir)
for (mir in 1:nmir){ #mir is feature number index, should change to gene or something
r <- replicate[s] #Replicate number index
MT <- mt[s]       #Experimental sample index
readsize = read_length[mt[s]]
mir_pold_tc <- p_old[mt[s]]
mir_pnew_tc <- p_new[mt[s]]
#Simulate which reads are labeled
newreads_tc <- rbernoulli(nreads[mir, MT, r], p = fn_s4U[mir, MT, r])# vector of reads, T/F is s4U labeled
#Simulate the nubmer of Us in each read
nu <- rbinom(n = nreads[mir,MT,r], size = readsize, prob = 0.25)
#Number of reads that are new
newreads_tc <- sum(newreads_tc)
#Generate number of mutations for new and old reads
if (!ctl[s]){ #If no s4U added, only old
nmut_tc <- rbinom(n = nreads[mir,MT,r], size=nu, prob = mir_pold_tc)
}else {
nmut_tc_new <- rbinom(n=newreads_tc, size=nu[1:newreads_tc], prob=mir_pnew_tc)
nmut_tc_old <- rbinom(n=(nreads[mir, MT, r]-newreads_tc), size = nu[(newreads_tc+1):nreads[mir, MT, r]], prob=mir_pold_tc)
nmut_tc <- c(nmut_tc_new, nmut_tc_old)
}
#Now make it look kind of like a cB file
# use mirMut for each gene, cntl is if cntl or not, x is # of new reads
df <- tibble(S = rep(s, times = nreads[mir, MT, r]),  #starting to generate something that looks like a cB file
TP = rep(ctl[s], times = nreads[mir, MT, r]),
R = rep(r, times=nreads[mir, MT, r]),
MIR = rep(mir, times = nreads[mir, MT, r]), # same as XF or fnum, so just feature number
TC = nmut_tc,
MT = rep(mt[s], times=nreads[mir, MT, r]),
num_us = nu)
#rep_data[[r]] <- df
#rep_data <- bind_rows(rep_data)
mir_data[[mir]] <- df
}
mir_data <- bind_rows(mir_data)
sample_data[[s]] <- mir_data
}
sample_data <- bind_rows(sample_data)
sim_df <- list(nmir = nmir,
fn_s4U = fn_s4U,
p_new_real_tc = p_new_real_tc,
p_old_real_tc = p_old_real_tc,
nreads = nreads, # per miR per sample
nsamp = nsamp,
ctl = ctl,
mir_pnew_tc = mir_pnew_tc,
mir_pold_tc = mir_pold_tc,
sample_data = sample_data
)
return(sim_df)   # return a list of all the things we should know.
}
sim_df_1 <- simulateData()
# Extract simulated cB and summarise data
cB_sim_1 <- data.table::setDT(sim_df_1$sample_data)
rm(sim_df_1)
cB_sim_1 <- cB_sim_1[,  .(n = .N), keyby = .(S, TP, R, MIR, TC, MT, num_us)]
for(i in 1:ngene){
#Make sure the user didn't input the wrong
#number of significant genes
if (i == 1 ){
if (length(num_kd_DE) > num_conds){
print("num_kd_DE has too many elements")
break
} else if (length(num_kd_DE) < num_conds){
print("num_kd_DE has too few elements")
break
}
if (length(num_ks_DE) > num_conds){
print("num_ks_DE has too many elements")
break
} else if (length(num_ks_DE) < num_conds){
print("num_ks_DE has too few elements")
break
}
}
for(j in 1:num_conds){
if(j == 1){
effect_mean[i,1] <- 0
L2FC_ks_mean[i,1] <- 0
}else{
if(i < (ngene-num_kd_DE[j] + 1)){
effect_mean[i,j] <- 0
}else{
effect_mean[i,j] <- rnorm(n=1, mean=eff_mean, sd=eff_sd)
}
if(i < (ngene-num_ks_DE[j] + 1)){
L2FC_ks_mean[i,j] <- 0
}else{
if (runif(1) < 0.5){
L2FC_ks_mean[i,j] <- runif(n=1, min=low_L2FC_ks, max=high_L2FC_ks)
}else{
L2FC_ks_mean[i,j] <- runif(n=1, min=-high_L2FC_ks, max=-low_L2FC_ks)
}
}
}
}
}
L2FC_kd_mean <- log2(log(1 - inv_logit(fn_mean + effect_mean))/log(1- inv_logit(fn_mean)))
#Simulate read counts
if (sim_read_counts == TRUE){
L2FC_tot_mean <- L2FC_ks_mean - L2FC_kd_mean
RNA_conc <- (ks_mean*2^(L2FC_ks_mean))/(kd_mean*2^(L2FC_kd_mean))
a1 <- 5
a0 <- 0.01
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
Counts[i, j, k] <- rnbinom(n=1, size=1/((a1/(scale_factor*RNA_conc[i,j])) + a0), mu = scale_factor*RNA_conc[i,j])
#Counts[i, j, k] <- rpois(n=1, lambda = scale_factor*RNA_conc[i,j,k])
if(Counts[i, j, k] < 5){
Counts[i, j, k] <- Counts[i, j, k] + rpois(n=1, lambda = 2) + 1
}
}
}
}
} else{
if(sim_from_data == FALSE){
Counts <- rep(nreads, times= ngene*num_conds*nreps)
dim(Counts) <- c(ngene, num_conds, nreps)
}
}
#SIMULATE L2FC OF DEG AND SYNTH RATE CONSTANTS; REPLICATE VARIABILITY SIMULATED
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
standard_RNA <- (log10(RNA_conc[i,j]*scale_factor) - mean(log10(RNA_conc[,j]*scale_factor)))/sd(log10(RNA_conc[,j]*scale_factor))
fn[i, j, k] <- inv_logit(rnorm(1, mean=(logit(fn_mean[i]) + effect_mean[i,j]), sd = rlnorm(1, noise_deg_a*standard_RNA + noise_deg_b, sd_rep )))
ks[i,j,k] <- exp(rnorm(1, mean=log((2^L2FC_ks_mean[i,j])*ks_mean[i]), sd=noise_synth))
}
}
}
?standardize
?standardize
?scale
log_RNA <- log10(RNA_conc*scale_factor)
standard_RNA <- scale(log_RNA, scale = colSums(log_RNA))
mean(standard_RNA[,1])
mean(standard_RNA[,2])
sd(standard_RNA[,2])
sd(standard_RNA[,1])
log_RNA <- log10(RNA_conc*scale_factor)
standard_RNA <- scale(log_RNA, center = TRUE, scale = colSums(log_RNA))
sd(standard_RNA[,1])
sd(standard_RNA[,2])
colSums(log_RNA)
log_RNA
?sweep
apply(log_RNA, 1:2, sd)
standard_RNA <- scale(log_RNA, center = TRUE, scale = sweep(log_RNA, num_conds, FUN = "sd"))
standard_RNA <- sweep(sweep(log_RNA, num_conds, mean(log_RNA), FUN = "-"), num_conds, sd(log_RNA), FUN = "/")
mean(standard_RNA[,1])
mean(standard_RNA[,2])
sd(standard_RNA[,1])
sd(standard_RNA[,2])
hist(standard_RNA)
sd(standard_RNA[,2])
#SIMULATE L2FC OF DEG AND SYNTH RATE CONSTANTS; REPLICATE VARIABILITY SIMULATED
## This is slow
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
standard_RNA <- (log10(RNA_conc[i,j]*scale_factor) - mean(log10(RNA_conc[,j]*scale_factor)))/sd(log10(RNA_conc[,j]*scale_factor))
fn[i, j, k] <- inv_logit(rnorm(1, mean=(logit(fn_mean[i]) + effect_mean[i,j]), sd = rlnorm(1, noise_deg_a*standard_RNA + noise_deg_b, sd_rep )))
ks[i,j,k] <- exp(rnorm(1, mean=log((2^L2FC_ks_mean[i,j])*ks_mean[i]), sd=noise_synth))
}
}
}
standard_RNA <- sweep(sweep(log_RNA, num_conds, mean(log_RNA), FUN = "-"), num_conds, sd(log_RNA), FUN = "/")
#SIMULATE L2FC OF DEG AND SYNTH RATE CONSTANTS; REPLICATE VARIABILITY SIMULATED
## This is slow
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
fn[i, j, k] <- inv_logit(rnorm(1, mean=(logit(fn_mean[i]) + effect_mean[i,j]), sd = rlnorm(1, noise_deg_a*standard_RNA[i,j] + noise_deg_b, sd_rep )))
ks[i,j,k] <- exp(rnorm(1, mean=log((2^L2FC_ks_mean[i,j])*ks_mean[i]), sd=noise_synth))
}
}
}
hist(fn)
hist(ks)
kd <- -log(1 - fn)/tl
###Custom fn###
if(Custom == TRUE){
for(i in 1:ngene){
for(j in 1:num_conds){
for(k in 1:nreps){
if( i < 101){
fn[i,j,k] <- 0.1
}else if(i < 201){
fn[i,j,k] <- 0.5
}else{
fn[i,j,k] <- 0.9
}
}
}
}
}
l <- ngene
p_do <- matrix(rep(0, times = num_conds*nreps), nrow = nreps, ncol = num_conds)
fn_real <- fn
for(j in 1:num_conds){
for(k in 1:nreps){
fn_real[,j,k] <- (fn[,j,k]*(1-p_do[k,j]))/(1 - p_do[k,j]*(1 - fn[,j,k]))
Counts[,j,k] <- Counts[,j,k] - Counts[,j,k]*fn[,j,k]*p_do[k,j]
}
}
# This is one very huge function
# It simulates TL-seq data, recording the number of TC mutations in each read, which is informed
# by whatever the fraction new for the particular transcript is
simulateData <- function(nmir = l,   # num of genes
fn_s4U = fn_real,   # fraction of s4U reads made after label introduction in non-heatshocked sample
#fn_s4U2 = fn_hs, # fraction of s4U reads made after label introduction in heatshocked sample
p_new_real_tc = p_new,                   # TC mutation rate in fed cells
p_old_real_tc = p_old,                  # TC mutation rate in unfed cells
read_length = read_lengths,
nreads = Counts, # per transript per sample
nsamp = (nreps*num_conds) + num_conds,
ctl = c(rep(1, times=nreps*num_conds), rep(0, times=num_conds)),   # cntl = 0 is no feed, cntl = 1 is feed
mt = c(rep(1:num_conds, each=nreps),seq(from=1,to=num_conds,by=1)),
replicate = c(rep(seq(from=1, to=nreps), times=num_conds), rep(1, times=num_conds))
#Could just generalize this, which is what next line does, repeating 1 for all but the last sample
#ctl = c(rep(1, times = nsamp-1),0) #assumes nsamp is odd, think it has to be
){
# mir_pnew_logit_tc <- rnorm(nmir, mean = logit(p_new_real_tc), sd = 0.2)  # Calculates an s4U mutation probability within given range
# mir_pnew_tc <- inv_logit(mir_pnew_logit_tc)   # figure out what the probability values actual are (unlogit the logit)
#
#
# mir_pold_logit_tc <- rnorm(nmir, mean = logit(p_old_real_tc), sd = 0.2)  # Calculates a background mutation probability within a given range
# mir_pold_tc <- inv_logit(mir_pold_logit_tc)  #unlogit the logit
# Start generating a vector with data
sample_data <- vector('list', length = nsamp)
for (s in 1:nsamp){
mir_data <- vector('list', length = nmir)
for (mir in 1:nmir){ #mir is feature number index, should change to gene or something
r <- replicate[s] #Replicate number index
MT <- mt[s]       #Experimental sample index
readsize = read_length[mt[s]]
mir_pold_tc <- p_old[mt[s]]
mir_pnew_tc <- p_new[mt[s]]
#Simulate which reads are labeled
newreads_tc <- rbernoulli(nreads[mir, MT, r], p = fn_s4U[mir, MT, r])# vector of reads, T/F is s4U labeled
#Simulate the nubmer of Us in each read
nu <- rbinom(n = nreads[mir,MT,r], size = readsize, prob = 0.25)
#Number of reads that are new
newreads_tc <- sum(newreads_tc)
#Generate number of mutations for new and old reads
if (!ctl[s]){ #If no s4U added, only old
nmut_tc <- rbinom(n = nreads[mir,MT,r], size=nu, prob = mir_pold_tc)
}else {
nmut_tc_new <- rbinom(n=newreads_tc, size=nu[1:newreads_tc], prob=mir_pnew_tc)
nmut_tc_old <- rbinom(n=(nreads[mir, MT, r]-newreads_tc), size = nu[(newreads_tc+1):nreads[mir, MT, r]], prob=mir_pold_tc)
nmut_tc <- c(nmut_tc_new, nmut_tc_old)
}
#Now make it look kind of like a cB file
# use mirMut for each gene, cntl is if cntl or not, x is # of new reads
df <- tibble(S = rep(s, times = nreads[mir, MT, r]),  #starting to generate something that looks like a cB file
TP = rep(ctl[s], times = nreads[mir, MT, r]),
R = rep(r, times=nreads[mir, MT, r]),
MIR = rep(mir, times = nreads[mir, MT, r]), # same as XF or fnum, so just feature number
TC = nmut_tc,
MT = rep(mt[s], times=nreads[mir, MT, r]),
num_us = nu)
#rep_data[[r]] <- df
#rep_data <- bind_rows(rep_data)
mir_data[[mir]] <- df
}
mir_data <- bind_rows(mir_data)
sample_data[[s]] <- mir_data
}
sample_data <- bind_rows(sample_data)
sim_df <- list(nmir = nmir,
fn_s4U = fn_s4U,
p_new_real_tc = p_new_real_tc,
p_old_real_tc = p_old_real_tc,
nreads = nreads, # per miR per sample
nsamp = nsamp,
ctl = ctl,
mir_pnew_tc = mir_pnew_tc,
mir_pold_tc = mir_pold_tc,
sample_data = sample_data
)
return(sim_df)   # return a list of all the things we should know.
}
?fread
setwd("C:/Users/isaac/Documents/Simon_Lab/TimeLapse_Paper/Real_Data/")
# Load the cB you want to analyze
fread("cB.rds")
# Load the cB you want to analyze
cB <- fread("cB.rds",
select = c("sample", "XF", "TC", "n"))
# Load the cB you want to analyze
cB <- readRDS('cB_TL_downsample.rds') %>%
select(sample, XF, TC, n)
# Load the cB you want to analyze
cB <- readRDS('cB.rds') %>%
select(sample, XF, TC, n)
cB <- setDT(cB)
# Vector of sample names as they appear in the cB
# Equivalent to unique(cB$sample)
samp_list <- c('JS181101', 'JS181102','JS181107', 'JS181108',
'JS181113', 'JS181114')
# Define which samples are s4U fed
type_list <- c(1, 1, 1, 1, 0, 0)
# Length of s4U labeling
tl <- 1
# Define which sample is the reference and which should be compared to reference
mut_list <- c(1, 1, 2, 2, 1, 2)
names(type_list) <- samp_list
names(mut_list) <- samp_list
# Devine control samples:
cv1 <- samp_list[!type_list]
# Helper function:
getType <- function(s) type_list[paste(s)]
getMut <- function(s) mut_list[paste(s)]
reliableFeatures <- function(df = cB,
cv = cv1,
high_p = 0.2,
totcut = 1000){
y <- df %>%
dplyr::ungroup() %>%
filter(sample %in% samp_list,
!grepl('__', XF)) %>%
dplyr::mutate(totTC = TC*n*ifelse(sample %in% cv, 1, 0) ) %>%
dplyr::group_by(sample, XF) %>%
dplyr::summarize(tot_mut = sum(totTC),
totcounts = sum(n)) %>%
dplyr::filter(totcounts >= totcut) %>%
dplyr::filter(tot_mut/totcounts < high_p) %>%
dplyr::ungroup() %>%
dplyr::group_by(XF) %>%
dplyr::summarize(counts = n()) %>%
dplyr::filter(counts == length(samp_list)) %>%
dplyr::select(XF) %>%
unlist() %>%
unique()
return(y)
}
