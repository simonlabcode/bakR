I_den = 1 + exp(mean) + (((1 + exp(mean))^2)/exp(mean) )*1/(((lam_n/lam_o)^TC)*exp(-(lam_n - lam_o)) -1 ),
Fisher = n*(I_num/(I_den^2))) %>%
group_by(fnum, MT, R) %>%
summarise(Fisher = (sum(Fisher)/sum(n)), ntot = sum(n), sd_true = mean(sd), sd_fish = 1/sqrt(ntot*Fisher))
ggplot(fn_fisher, aes(x = log10(ntot), y = log(sd_true))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Read Counts)") +
ylab("log(Logit(Fn) Uncertainty)")
ggplot(fn_fisher, aes(x = log(sd_true), y = log(sd_fish), color = log10(ntot))) +
geom_point(size = 1) +
theme_mds +
geom_abline(slope = 1, intercept = 0, color = "red") +
xlab("True sd") +
ylab("Fisher Info sd") +
scale_color_gradient(low = "blue", high = "red")
fn_linear <- fn_fisher %>% mutate(sd_true = log(sd_true), ntot = log10(ntot))
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Data/Real_cBs/")
cB <- readRDS("cB.rds")
rm(cB_sim_1)
rm(data_list)
rm(data_list_Hogg)
rm(fit_Hogg)
# This is the name of all of all the samples you want to analyze as they show up in
# the sample column of the cB. Order is important for next couple lines
samp_list <- c('JS181101', 'JS181102','JS181107', 'JS181108',
'JS181113', 'JS181114')
# Samples in samp_list are no s4U controls
c_list <- c('JS181113', 'JS181114')
# 1 = if corresponding sample in samp_list is s4U fed;
# 0 = no s4U control
# Order of type_list corresponds to order of samp_list
type_list <- c(1, 1, 1, 1, 0, 0)
# Experimental condition IDs
# 1 = reference, > 1 = experimental conditions that you want to compare to reference
mut_list <- c(1, 1, 2, 2, 1 ,2)
# Replicate ID
# Arbitrarily labels 1st, 2nd, etc. replicate of each experimental condition
rep_list <- c(rep(c(1,2), times=2), 1, 1)
data_list <- cBprocess(cB, samp_list, type_list, mut_list, rep_list, 2, Fast = TRUE)
rm(cB)
Fast_df <- data_list$Fast_df
fast_list <- fast_analysis(Fast_df)
fast_list$Fn_Estimates
fn_fisher
fn_fast <- fast_list$Fn_Estimates
fn_fast <- fn_fast[order(fn_fast$Gene_ID, fn_fast$Condition, fn_fast$Replicate),]
fn_fast
max(fn_fast$Gene_ID)
fn_fast$true_sd <- fn_fisher$sd_true
colnames(fn_fast)
ggplot(fn_fast, aes(x = true_sd, y = logit_fn_se, color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd")
min(fn_fast$logit_fn_se)
max(fn_fast$logit_fn_se)
ggplot(fn_fast, aes(x = log(true_sd), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd")
fn_fast
fn_fisher
data_list$Stan_data$sdf
data_list$Stan_data$sdf %>% select(sample, XF, fnum)
DCP2_sdf
fast_data <- data_list$Stan_data$sdf %>% select(XF, fnum) %>% distinct()
DCP2_fnum_to_XF <- DCP2_sdf %>% select(XF, fnum) %>% distinct()
lookup_fnum_to_XF <- merge(fast_data, DCP2_fnum_to_XF, by = "XF")
lookup_fnum_to_XF
colnames(lookup_fnum_to_XF) <- c("XF", "fnum_fast", "fnum_Stan")
fn_fast
fn_fast <- fast_list$Fn_Estimates
fn_fast <- fn_fast[order(fn_fast$Gene_ID, fn_fast$Condition, fn_fast$Replicate),]
fn_fast
merge(fn_fast, lookup_fnum_to_XF, by.x = "Gene_ID", by.y = "fnum_fast")
fn_fast_lookup <- merge(fn_fast, lookup_fnum_to_XF, by.x = "Gene_ID", by.y = "fnum_fast")
colnames(fn_fisher)
colnames(fn_fast_lookup)
fn_fast_merge <- merge(fn_fast_lookup, fn_fisher, by.x = c("Gene_ID", "Condition", "Replicate"), by.y = c("fnum", "MT", "R"))
ggplot(fn_fast, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd")
ggplot(fn_fast_merge, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd")
fn_fast_merge <- merge(fn_fast_lookup, fn_fisher, by.x = c("fnum_Stan", "Condition", "Replicate"), by.y = c("fnum", "MT", "R"))
ggplot(fn_fast_merge, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd")
ggplot(fn_fast_merge, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd") +
scale_color_gradient(high = "red", low = "blue") +
geom_abline(slope = 1, intercept = 0)
fn_fast_merge
colnames(fn_fast_merge)
ggplot(fn_fast_merge, aes(x = log10(nreads), y = log(logit_fn_se))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Reads)") +
ylab("Log(logit_fn se)")
ggplot(fn_fast_merge, aes(x = log10(nreads), y = log(sd_true))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Reads)") +
ylab("Log(logit_fn se)")
ggplot(fn_fast_merge, aes(x = log10(nreads), y = log(logit_fn_se))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Reads)") +
ylab("Log(logit_fn se)") +
ylim(c(-4.5, -0.5))
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
?fast_analysis
### Inspecting code directly
df <- Fast_df
pnew <- NULL
pold <- NULL
read_cut <- 50
features_cut <- 30
nbin <- NULL
prior_weight <- 2
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))
#Trim df and name columns
if(is.null(pnew)){
message("Estimating labeled mutation rate")
Mut_data <- df[,1:9]
colnames(Mut_data) <- c("sample", "XF", "TC", "nT", "n", "fnum", "type", "mut", "reps")
##New Mutation rate Estimation
# Extract only s4U labeled data to estimate s4U mut rate
New_data <- Mut_data[Mut_data$type == 1, ]
# Calculate avg. mut rate at each row
New_data$avg_mut <- New_data$TC/New_data$nT
# Remove rows with NAs
New_data <- New_data[!is.na(New_data$avg_mut),]
# calculate total number of mutations
# which is the avg. for that row of dataframe times n
# the number of reads that had the identical average
New_data$weight_mut <- New_data$avg_mut*New_data$n
# This is to estimate the total mutation rate for each gene in
# each replicate and each experimental condition
New_data_summary <- New_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n), n = sum(n))
# Order datalist so that it's ordered by sample and then avg mutation rate
# Goal is to use the highest avg. mutation rates to estimate s4U mutation rate,
# assuming that highest mutation rates are from fast turnover, compeltely
# labeled transcripts
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
## This part has some magic numbers I should get rid of
## or move to user input
New_data_cutoff <- New_data_ordered[New_data_ordered$n > read_cut,]
# Check to make sure that the number of features that made it past the
# read count filter is still more than the total number of features required for
# mutation rate estimate
check <- New_data_cutoff %>% dplyr::ungroup() %>%
dplyr::count(mut, reps, sort = TRUE)
if(sum(check$n < features_cut) > 0){
stop("Not enough features made it past the read cutoff filter in one sample; try decreasing read_cut or features_cut")
}else{
New_data_estimate <- New_data_cutoff %>% dplyr::group_by(mut, reps) %>%
dplyr::summarise(pnew = mean(avg_mut[1:features_cut]))
message(paste(c("Estimated pnews are: ", New_data_estimate$pnew), collapse = " "))
}
}else{ # Need to construct pmut dataframe from User input
nMT <- max(df$mut)
nreps <- max(df$reps)
if(length(pnew) == 1){
pnew_vect <- rep(pnew, times = (nMT*nreps))
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnew_vect)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
} else if( length(pnew) != (nMT*nreps) ){
stop("User inputted pnew is not of length 1 or of length equal to number of samples")
} else{
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnew)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
}
}
if(is.null(pold)){
message("Estimating unlabeled mutation rate")
#Old mutation rate estimation
Mut_data <- df[,1:9]
colnames(Mut_data) <- c("sample", "XF", "TC", "nT", "n", "fnum", "type", "mut", "reps")
Old_data <- Mut_data[Mut_data$type == 0, ]
Old_data$avg_mut <- Old_data$TC/Old_data$nT
# Remove rows with NAs
Old_data <- Old_data[!is.na(Old_data$avg_mut),]
Old_data$weight_mut <- Old_data$avg_mut*Old_data$n
#Old_data$n <- rep(1, times=nrow(Old_data))
Old_data_summary <- Old_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n), n = sum(n))
# Order data differently than for s4U mut rate estimation
# Difference is that every mutation is a background mutation in these samples
# So we just want the highest confidence estimation, meaning we should only
# order by read counts
Old_data_ordered <- Old_data_summary[order(Old_data_summary$n, decreasing=TRUE), ]
## This part has some magic numbers I should get rid of
## or move to user input
Old_data_cutoff <- Old_data_ordered[Old_data_ordered$n > read_cut,]
# Check to make sure that the number of features that made it past the
# read count filter is still more than the total number of features required for
# mutation rate estimate
check <- nrow(Old_data_cutoff)
if(check < features_cut){
stop("Not enough features made it past the read cutoff filter in one sample; try decreasing read_cut or features_cut")
}else{
pold <- mean(Old_data_cutoff$avg_mut[1:features_cut])
message(paste(c("Estimated pold is: ", pold), collapse = " "))
}
}
pmuts_list <- list(New_data_estimate, pold)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
# Estimate fraction new in each replicate using binomial model
message("Estimating fraction labeled")
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
dplyr::mutate(pnew_est = New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)]) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew_est)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
New_data_estimate
Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
test <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
test %>% mutate(pnew_est = New_data_estimate[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])
test %>% ungroup() %>% mutate(pnew_est = New_data_estimate[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])
New_data_estimate[(New_data_estimate$mut == c(1, 1, 1)) & (New_data_estimate$reps == c(1, 2, 1))]
(New_data_estimate$mut == c(1, 1, 1))
Mut_data
Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
dplyr::mutate(pnew_est = New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)]) %>%
Mut_data <- merge(Mut_data, New_data_estimate, by = c("mut", "reps"))
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew_est)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
Mut_data
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
Mut_data <- merge(Mut_data, Mut_data_est[, c("logit_fn_rep", "fnum", "mut", "reps")], by = c("fnum", "mut", "reps"))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
dplyr::mutate(Exp_l_fn = exp(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew_est/pold)^TC)*exp(-(U_cont)*(pnew_est - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew_est/pold)^TC)*exp(-(U_cont)*(pnew_est - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
colnames(Mut_data)
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1),]
colnames(Mut_data)
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
?summarise
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
colnames(Mut_data)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
# Estimate fraction new in each replicate using binomial model
message("Estimating fraction labeled")
Mut_data <- merge(Mut_data, New_data_estimate, by = c("mut", "reps"))
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1),]
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1) & (Mut_data$TC == 0),]
test <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep")
test[(test$fnum == 1) & (test$mut == 1) & (test$reps == 1) & (test$TC == 0),]
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew, logit_fn_rep) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
dplyr::mutate(Exp_l_fn = exp(logit_fn_rep)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
Mut_data
colnames(Mut_data)
Mut_data <- merge(Mut_data, Mut_data_est[, c("logit_fn_rep", "fnum", "mut", "reps")], by = c("fnum", "mut", "reps"))
colnames(Mut_data)
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew, logit_fn_rep) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
dplyr::mutate(Exp_l_fn = exp(logit_fn_rep)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
getwd()
devtools::load_all()
rm(df)
rm(test)
rm(Mut_data_est)
rm(New_data_estimate)
rm(New_data)
rm(New_data_cutoff)
rm(New_data_ordered)
rm(New_data_summary)
rm(Old_data)
rm(Old_data_cutoff)
rm(Old_data_ordered)
fast_list <- fast_analysis(Fast_df)
fn_fast <- fast_list$Fn_Estimates
fn_fast <- fn_fast[order(fn_fast$Gene_ID, fn_fast$Condition, fn_fast$Replicate),]
fast_data <- data_list$Stan_data$sdf %>% select(XF, fnum) %>% distinct()
DCP2_fnum_to_XF <- DCP2_sdf %>% select(XF, fnum) %>% distinct()
lookup_fnum_to_XF <- merge(fast_data, DCP2_fnum_to_XF, by = "XF")
colnames(lookup_fnum_to_XF) <- c("XF", "fnum_fast", "fnum_Stan")
fn_fast_lookup <- merge(fn_fast, lookup_fnum_to_XF, by.x = "Gene_ID", by.y = "fnum_fast")
fn_fast_merge <- merge(fn_fast_lookup, fn_fisher, by.x = c("fnum_Stan", "Condition", "Replicate"), by.y = c("fnum", "MT", "R"))
ggplot(fn_fast_merge, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd") +
scale_color_gradient(high = "red", low = "blue") +
geom_abline(slope = 1, intercept = 0)
ggplot(fn_fast_merge, aes(x = log10(nreads), y = log(logit_fn_se))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Reads)") +
ylab("Log(logit_fn se)") +
ylim(c(-4.5, -0.5))
