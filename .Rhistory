setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
devtools::load_all()
devtools::load_all()
fast_list <- fast_analysis(Fast_df)
?fast_analysis
### Inspecting code directly
df <- Fast_df
pnew <- NULL
pold <- NULL
read_cut <- 50
features_cut <- 30
nbin <- NULL
prior_weight <- 2
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))
#Trim df and name columns
if(is.null(pnew)){
message("Estimating labeled mutation rate")
Mut_data <- df[,1:9]
colnames(Mut_data) <- c("sample", "XF", "TC", "nT", "n", "fnum", "type", "mut", "reps")
##New Mutation rate Estimation
# Extract only s4U labeled data to estimate s4U mut rate
New_data <- Mut_data[Mut_data$type == 1, ]
# Calculate avg. mut rate at each row
New_data$avg_mut <- New_data$TC/New_data$nT
# Remove rows with NAs
New_data <- New_data[!is.na(New_data$avg_mut),]
# calculate total number of mutations
# which is the avg. for that row of dataframe times n
# the number of reads that had the identical average
New_data$weight_mut <- New_data$avg_mut*New_data$n
# This is to estimate the total mutation rate for each gene in
# each replicate and each experimental condition
New_data_summary <- New_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n), n = sum(n))
# Order datalist so that it's ordered by sample and then avg mutation rate
# Goal is to use the highest avg. mutation rates to estimate s4U mutation rate,
# assuming that highest mutation rates are from fast turnover, compeltely
# labeled transcripts
New_data_ordered <- New_data_summary[order(New_data_summary$mut, New_data_summary$reps, New_data_summary$avg_mut, decreasing=TRUE), ]
## This part has some magic numbers I should get rid of
## or move to user input
New_data_cutoff <- New_data_ordered[New_data_ordered$n > read_cut,]
# Check to make sure that the number of features that made it past the
# read count filter is still more than the total number of features required for
# mutation rate estimate
check <- New_data_cutoff %>% dplyr::ungroup() %>%
dplyr::count(mut, reps, sort = TRUE)
if(sum(check$n < features_cut) > 0){
stop("Not enough features made it past the read cutoff filter in one sample; try decreasing read_cut or features_cut")
}else{
New_data_estimate <- New_data_cutoff %>% dplyr::group_by(mut, reps) %>%
dplyr::summarise(pnew = mean(avg_mut[1:features_cut]))
message(paste(c("Estimated pnews are: ", New_data_estimate$pnew), collapse = " "))
}
}else{ # Need to construct pmut dataframe from User input
nMT <- max(df$mut)
nreps <- max(df$reps)
if(length(pnew) == 1){
pnew_vect <- rep(pnew, times = (nMT*nreps))
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnew_vect)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
} else if( length(pnew) != (nMT*nreps) ){
stop("User inputted pnew is not of length 1 or of length equal to number of samples")
} else{
rep_vect <- rep(seq(from = 1, to = nreps), times = nMT)
mut_vect <- rep(seq(from = 1, to = nMT), each = nreps)
New_data_estimate <- data.frame(mut_vect, rep_vect, pnew)
colnames(New_data_estimate) <- c("mut", "reps", "pnew")
}
}
if(is.null(pold)){
message("Estimating unlabeled mutation rate")
#Old mutation rate estimation
Mut_data <- df[,1:9]
colnames(Mut_data) <- c("sample", "XF", "TC", "nT", "n", "fnum", "type", "mut", "reps")
Old_data <- Mut_data[Mut_data$type == 0, ]
Old_data$avg_mut <- Old_data$TC/Old_data$nT
# Remove rows with NAs
Old_data <- Old_data[!is.na(Old_data$avg_mut),]
Old_data$weight_mut <- Old_data$avg_mut*Old_data$n
#Old_data$n <- rep(1, times=nrow(Old_data))
Old_data_summary <- Old_data %>%
dplyr::group_by(reps, mut, fnum) %>% # group by gene, replicate ID, and experiment ID
dplyr::summarise(avg_mut = sum(weight_mut)/sum(n), n = sum(n))
# Order data differently than for s4U mut rate estimation
# Difference is that every mutation is a background mutation in these samples
# So we just want the highest confidence estimation, meaning we should only
# order by read counts
Old_data_ordered <- Old_data_summary[order(Old_data_summary$n, decreasing=TRUE), ]
## This part has some magic numbers I should get rid of
## or move to user input
Old_data_cutoff <- Old_data_ordered[Old_data_ordered$n > read_cut,]
# Check to make sure that the number of features that made it past the
# read count filter is still more than the total number of features required for
# mutation rate estimate
check <- nrow(Old_data_cutoff)
if(check < features_cut){
stop("Not enough features made it past the read cutoff filter in one sample; try decreasing read_cut or features_cut")
}else{
pold <- mean(Old_data_cutoff$avg_mut[1:features_cut])
message(paste(c("Estimated pold is: ", pold), collapse = " "))
}
}
pmuts_list <- list(New_data_estimate, pold)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
# Estimate fraction new in each replicate using binomial model
message("Estimating fraction labeled")
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
dplyr::mutate(pnew_est = New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)]) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew_est)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
New_data_estimate
Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
test <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
test %>% mutate(pnew_est = New_data_estimate[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])
test %>% ungroup() %>% mutate(pnew_est = New_data_estimate[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)])
New_data_estimate[(New_data_estimate$mut == c(1, 1, 1)) & (New_data_estimate$reps == c(1, 2, 1))]
(New_data_estimate$mut == c(1, 1, 1))
Mut_data
Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
dplyr::mutate(pnew_est = New_data_estimate$pnew[(New_data_estimate$mut == mut) & (New_data_estimate$reps == reps)]) %>%
Mut_data <- merge(Mut_data, New_data_estimate, by = c("mut", "reps"))
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew_est)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
Mut_data
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
Mut_data <- merge(Mut_data, Mut_data_est[, c("logit_fn_rep", "fnum", "mut", "reps")], by = c("fnum", "mut", "reps"))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
dplyr::mutate(Exp_l_fn = exp(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew_est/pold)^TC)*exp(-(U_cont)*(pnew_est - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew_est/pold)^TC)*exp(-(U_cont)*(pnew_est - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
colnames(Mut_data)
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1),]
colnames(Mut_data)
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n))
?summarise
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
colnames(Mut_data)
Mut_data <- df
Mut_data <- Mut_data[Mut_data$type == 1,]
ngene <- max(Mut_data$fnum)
num_conds <- max(Mut_data$mut)
nreps <- max(Mut_data$reps)
fn_rep_est <- rep(0, times=ngene*num_conds*nreps)
dim(fn_rep_est) <- c(ngene, num_conds, nreps)
R_ID <- fn_rep_est
MT_ID <- R_ID
FN_ID <- R_ID
# Estimate fraction new in each replicate using binomial model
message("Estimating fraction labeled")
Mut_data <- merge(Mut_data, New_data_estimate, by = c("mut", "reps"))
Mut_data_est <- Mut_data %>% dplyr::group_by(fnum, mut, reps, TC, nT) %>%
# mutate(avg_mut = TC/nT) %>%
# #mutate(prior_new = ifelse(avg_mut >= (pnew_est - 0.01), 0.99, (avg_mut + 0.01)/pnew_est )) %>%
# mutate(prior_new = 0.9)%>%
dplyr::mutate(New_prob = stats::dbinom(TC, size=nT, prob=pnew)) %>%
dplyr::mutate(Old_prob = stats::dbinom(TC, size = nT, prob = pold)) %>%
dplyr::mutate(News = n*(New_prob/(New_prob + Old_prob))) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(nreads = sum(n), Fn_rep_est = sum(News)/nreads) %>%
dplyr::mutate(logit_fn_rep = ifelse(Fn_rep_est == 1, logit(0.999), ifelse(Fn_rep_est == 0, logit(0.001), logit(Fn_rep_est)))) %>%
dplyr::ungroup()
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1),]
Mut_data[(Mut_data$fnum == 1) & (Mut_data$mut == 1) & (Mut_data$reps == 1) & (Mut_data$TC == 0),]
test <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep")
test[(test$fnum == 1) & (test$mut == 1) & (test$reps == 1) & (test$TC == 0),]
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew, logit_fn_rep) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
dplyr::mutate(Exp_l_fn = exp(logit_fn_rep)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
Mut_data
colnames(Mut_data)
Mut_data <- merge(Mut_data, Mut_data_est[, c("logit_fn_rep", "fnum", "mut", "reps")], by = c("fnum", "mut", "reps"))
colnames(Mut_data)
## Estimate Fisher Info and uncertainties
## Could make more efficient by summarizing over nT info and using U_content to adjust pnew*avg_U
Mut_data <- Mut_data %>% ungroup() %>%
dplyr::group_by(fnum, mut, reps, TC, pnew, logit_fn_rep) %>%
dplyr::summarise(U_cont = sum(nT*n)/sum(n), n = sum(n), .groups = "keep") %>%
dplyr::mutate(Exp_l_fn = exp(logit_fn_rep)) %>%
# dplyr::mutate(fn = inv_logit(Mut_data_est$logit_fn_rep[(Mut_data_est$mut == mut) & (Mut_data_est$reps == reps) & (Mut_data_est$fnum == fnum)])) %>%
# dplyr::mutate(Fisher_fn_num = ((pnew_est*nT)^TC)*exp(-pnew_est*nT) - ((pold*nT)^TC)*exp(-pold*nT) ) %>%
# dplyr::mutate(Fisher_fn_den = fn*Fisher_fn_num + ((pold*nT)^TC)*exp(-pold*nT)) %>%
dplyr::mutate(Inv_Fisher_Logit_3 = 1/(((pnew/pold)^TC)*exp(-(U_cont)*(pnew - pold)) - 1 )) %>%
dplyr::mutate(Inv_Fisher_Logit_1 = 1 + Exp_l_fn ) %>%
dplyr::mutate(Inv_Fisher_Logit_2 = ((1 + Exp_l_fn)^2)/Exp_l_fn) %>%
dplyr::ungroup() %>%
dplyr::group_by(fnum, mut, reps) %>%
dplyr::summarise(Fisher_Logit = sum(n/((Inv_Fisher_Logit_1 + Inv_Fisher_Logit_2*Inv_Fisher_Logit_3)^2))/sum(n), tot_n = sum(n)) %>% #,
#Fisher_fn = sum(n*((Fisher_fn_num/Fisher_fn_den)^2)), tot_n = sum(n)) %>%
dplyr::mutate(Logit_fn_se = 1/sqrt(tot_n*Fisher_Logit)) #, Fn_se = 1/sqrt(tot_n*Fisher_fn))
getwd()
devtools::load_all()
rm(df)
rm(test)
rm(Mut_data_est)
rm(New_data_estimate)
rm(New_data)
rm(New_data_cutoff)
rm(New_data_ordered)
rm(New_data_summary)
rm(Old_data)
rm(Old_data_cutoff)
rm(Old_data_ordered)
fast_list <- fast_analysis(Fast_df)
fn_fast <- fast_list$Fn_Estimates
fn_fast <- fn_fast[order(fn_fast$Gene_ID, fn_fast$Condition, fn_fast$Replicate),]
fast_data <- data_list$Stan_data$sdf %>% select(XF, fnum) %>% distinct()
DCP2_fnum_to_XF <- DCP2_sdf %>% select(XF, fnum) %>% distinct()
lookup_fnum_to_XF <- merge(fast_data, DCP2_fnum_to_XF, by = "XF")
colnames(lookup_fnum_to_XF) <- c("XF", "fnum_fast", "fnum_Stan")
fn_fast_lookup <- merge(fn_fast, lookup_fnum_to_XF, by.x = "Gene_ID", by.y = "fnum_fast")
fn_fast_merge <- merge(fn_fast_lookup, fn_fisher, by.x = c("fnum_Stan", "Condition", "Replicate"), by.y = c("fnum", "MT", "R"))
ggplot(fn_fast_merge, aes(x = log(sd_true), y = log(logit_fn_se), color = log10(nreads))) +
geom_point(size = 1) +
theme_mds +
xlab("True sd") +
ylab("Fisher Info sd") +
scale_color_gradient(high = "red", low = "blue") +
geom_abline(slope = 1, intercept = 0)
ggplot(fn_fast_merge, aes(x = log10(nreads), y = log(logit_fn_se))) +
geom_point(size = 1) +
theme_mds +
xlab("log10(Reads)") +
ylab("Log(logit_fn se)") +
ylim(c(-4.5, -0.5))
test <- data.frame(nums = c(1, 2, 3), )
test <- data.frame(nums = c(1, 2, 3), letts = c("a", "b", "c"))
message(paste0(c("Estimated pnew is:" , test)))
test
message(paste0(c("Estimated pnew is:", capture.output(test))))
message(paste0(c("Estimated pnew is:", capture.output(test)), collapse = "\n"))
test %>% group_by("letts") %>% summarise(nums = nums*2)
library(tidyverse)
test %>% group_by("letts") %>% summarise(nums = nums*2)
library(devtools)
library(roxygen2)
document()
test <- data.frame(tl = c(1, 1, 1, 1, 0, 0), exp = c(1, 1, 2, 2, 1, 2))
test
test %>% mutate(dummy = 1:nrow(test)) %>% group_by(tl, exp) %>% mutate(r_id = 1:length(dummy))
library(tidyverse)
test %>% mutate(dummy = 1:nrow(test)) %>% group_by(tl, exp) %>% mutate(r_id = 1:length(dummy))
test %>% mutate(dummy = 1:nrow(test)) %>% group_by(tl, exp) %>% mutate(r_id = 1:length(tl))
test %>% %>% group_by(tl, exp) %>% mutate(r_id = 1:length(tl))
test %>% group_by(tl, exp) %>% mutate(r_id = 1:length(tl))
test %>% group_by(tl, exp) %>% mutate(r_id = 1:length(tl)) %>% select(r_id)
test %>% group_by(tl, exp) %>% mutate(r_id = 1:length(tl)) %>% ungroup() %>% select(r_id)
rownames(metadf) <- c("samp1", "samp2", "samp3", "samp4", "samp5", "samp6")
rownames(test) <- c("samp1", "samp2", "samp3", "samp4", "samp5", "samp6")
samp_list <- c("samp6", "samp3", "samp2", "samp4", "samp5", "samp1")
test[samp_list, ]
### Test it in actual code
library(devtools)
devtools::load_all()
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Data/Real_cBs/")
cB <- readRDS("cB.rds")
cB <- cB %>% select(XF, nT, TC, sample, n)
unique(cB$sample)
metadf <- data.frame(tl = c(2, 2, 2, 2, 0, 0),
Exp_ID = c(1L, 1L, 2L, 2L, 1L, 2L))
rownames(metadf) <- unique(cB$sample)
library(magrittr)
cB <- cB %>% dplyr::select(XF, nT, TC, sample, n)
unique(cB$sample)
metadf <- data.frame(tl = c(2, 2, 2, 2, 0, 0),
Exp_ID = c(1L, 1L, 2L, 2L, 1L, 2L))
rownames(metadf) <- unique(cB$sample)
DynamicData <- DynamicSeqData(cB, metadf)
data_list <- cBprocess(DynamicData, Fast = TRUE)
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
data_list <- cBprocess(DynamicData, Fast = TRUE)
data_list
DynamicData$cB
DynamicData$metadf
### Copy code from package
obj <- DynamicData
keep_input <- c(0.2, 50)
Fast <- TRUE
Stan <- TRUE
FOI <- NULL
cB <- obj$cB
metadf <- obj$metadf
samp_list <-unique(cB$sample)
c_list <- rownames(metadf[,"tl"] == 0)
s4U_list <- samp_list[!(samp_list %in% c_list)]
type_list <- ifelse(metadf[samp_list, "tl"] == 0, 0, 1)
mut_list <- metadf[samp_list, "Exp_ID"]
rep_list <- as.vector(metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id))
names(type_list) <- samp_list
names(mut_list) <- samp_list
names(rep_list) <- samp_list
samp_list
c_list
rownames(metadf)
rownames(metadf[metadf$tl == 0,])
c_list <- rownames(metadf[metadf$tl == 0,])
s4U_list <- samp_list[!(samp_list %in% c_list)]
type_list <- ifelse(metadf[samp_list, "tl"] == 0, 0, 1)
mut_list <- metadf[samp_list, "Exp_ID"]
rep_list <- as.vector(metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id))
samp_list
c_list
names(type_list) <- samp_list
names(mut_list) <- samp_list
names(rep_list) <- samp_list
rep_list
as.vector(metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id))
metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id)
rep_list <- as.vector(metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id))
rep_list$r_id
rep_list <- metadf[samp_list,] %>% dplyr::group_by(tl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id)
rep_list <- rep_list$r_id
samp_list
c_list
names(type_list) <- samp_list
names(mut_list) <- samp_list
names(rep_list) <- samp_list
nreps <- max(rep_list)
# Helper function:
getType <- function(s) type_list[paste(s)]
getMut <- function(s) mut_list[paste(s)]
getRep <- function(s) rep_list[paste(s)]
# Get reliable features:
if(concat == TRUE | is.null(FOI)){
reliables <- DynamicSeq::reliableFeatures(obj, high_p = keep_input[1], totcut = keep_input[2])
keep <- c(FOI, reliables[!(reliables %in% FOI)])
}else{
keep <- FOI
}
concat <- TRUE
# Get reliable features:
if(concat == TRUE | is.null(FOI)){
reliables <- DynamicSeq::reliableFeatures(obj, high_p = keep_input[1], totcut = keep_input[2])
keep <- c(FOI, reliables[!(reliables %in% FOI)])
}else{
keep <- FOI
}
setwd("C:/Users/isaac/Documents/Simon_Lab/MyfirstPaper/Data/Real_cBs/")
setwd("C:/Users/isaac/Documents/Simon_Lab/DynamicSeq/")
devtools::load_all()
data_list <- cBprocess(DynamicData, Fast = TRUE)
devtools::load_all()
data_list <- cBprocess(DynamicData, Fast = TRUE)
devtools::load_all()
data_list <- cBprocess(DynamicData, Fast = TRUE)
data_list$Stan_data$NF
print(DynamicData)
