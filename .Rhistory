samp_keep <- c("1", "2", "3", "7")
cB_filt <- cB[cB$sample %in% samp_keep]
cB_filt <- cB[cB$sample %in% samp_keep,]
cB_filt
ls
metadf <- meta
meta
metadf <- data.frame(tl = c(1, 1, 1, 0), Exp_ID = c(1, 1, 1, 1))
metadf
row.names(metadf) <- unique(cB_filt$sample)
metadf
bakRdata <- bakRData(cB_filt, metadf)
Fit <- bakRFit(bakRdata)
Fit$Fast_Fit$Fn_Estimates
Fit$Fast_Fit$Effects_df
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 5)
devtools::load_all()
bakRdata <- bakRData(cB_filt, metadf)
?bakRFit
devtools::load_all()
bakRdata <- bakRData(cB_filt, metadf)
library(devtools)
use_package("data.table")
?tibble
?rbinom
?unlist
?pmap
?rbernoulli
devtools::load_all()
devtools::document()
devtools::load_all()
sim <- Simulate_bakRData(1000)
devtools::load_all()
sim <- Simulate_bakRData(1000)
?bind_rows
devtools::load_all()
sim <- Simulate_bakRData(1000)
sim$bakRData$cB
unique(sim$bakRData$cB$sample)
sim$bakRData$metadf
devtools::load_all()
sim <- Simulate_bakRData(1000)
Fit <- bakRFit(sim_data$bakRData, StanRateEst = TRUE, RateEst_size = 10)
Fit <- bakRFit(sim$bakRData, StanRateEst = TRUE, RateEst_size = 10)
Fit <- bakRFit(sim$bakRData, StanRateEst = TRUE, RateEst_size = 10, low_reads = 1, high_reads = 100000)
sim$bakRData$cB
sim <- Simulate_bakRData(1000)
warnings()
devtools::load_all()
sim <- Simulate_bakRData(1000)
Fit <- bakRFit(sim$bakRData, StanRateEst = TRUE, RateEst_size = 10)
plotVolcano(Fit$Fast_Fit)
plotMA(Fit, Model = "MLE")
sim_fn <- sim$sim_list$Fn_rep_sim
sim_fn <- sim_fn[sim_fn$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Fn_Estimates$logit_fn, sim_fn$Logit_fn)
sim_L2FC <- sim_data$sim_list$Effect_sim
sim_L2FC <- sim$sim_list$Effect_sim
sim_L2FC <- sim_L2FC[sim_L2FC$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Effects_df$L2FC_kdeg, sim_L2FC$L2FC_kdeg)
sum(Fit$Fast_Fit$Effects_df$padj[Fit$Fast_Fit$Effects_df$XF <= 500] < 0.05)/sum(Fit$Fast_Fit$Effects_df$padj < 0.05)
sim <- Simulate_bakRData(10000)
Fit <- bakRFit(sim$bakRData, StanRateEst = TRUE, RateEst_size = 10)
plotVolcano(Fit$Fast_Fit)
plotMA(Fit, Model = "MLE")
sum(Fit$Fast_Fit$Effects_df$padj[Fit$Fast_Fit$Effects_df$XF <= 5000] < 0.05)/sum(Fit$Fast_Fit$Effects_df$padj < 0.05)
sim_fn <- sim$sim_list$Fn_rep_sim
sim_fn <- sim_fn[sim_fn$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Fn_Estimates$logit_fn, sim_fn$Logit_fn)
sim_L2FC <- sim$sim_list$Effect_sim
sim_L2FC <- sim_L2FC[sim_L2FC$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Effects_df$L2FC_kdeg, sim_L2FC$L2FC_kdeg)
devtools::load_all()
sim <- Simulate_bakRData(1000, STL = TRUE, STL_len = 50)
Fit <- bakRFit(sim$bakRData, StanRateEst = TRUE, RateEst_size = 7)
sum(Fit$Fast_Fit$Effects_df$padj[Fit$Fast_Fit$Effects_df$XF <= 500] < 0.05)/sum(Fit$Fast_Fit$Effects_df$padj < 0.05)
sim_fn <- sim$sim_list$Fn_rep_sim
sim_fn <- sim_fn[sim_fn$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Fn_Estimates$logit_fn, sim_fn$Logit_fn)
sim_L2FC <- sim$sim_list$Effect_sim
sim_L2FC <- sim_L2FC[sim_L2FC$Feature_ID %in% unique(Fit$Fast_Fit$Effects_df$XF),]
plot(Fit$Fast_Fit$Fn_Estimates$logit_fn, sim_fn$Logit_fn)
plot(Fit$Fast_Fit$Effects_df$L2FC_kdeg, sim_L2FC$L2FC_kdeg)
devtools::load_all()
sim <- Simulate_bakRData(10000)
?cBprocess
test <- bakR::cBprocess(sim$bakRData)
test$times
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
test$times
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
test$times
check_cB <- test$Fast_df
check_fast <- test$Fast_df
rm(check_cB)
check_Stan <- test$Stan_data
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
test$times
anti_join(check_fast, test$Fast_df)
dplyr::anti_join(check_fast, test$Fast_df)
dplyr::anti_join(check_Stan$sdf, test$Stan_data$sdf)
names(check_fast)
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
?cBprocess
library(data.table)
#### Set parameters
obj <- sim$bakRData
high_p <- 0.2
totcut <- 50
Ucut <- 0.25
AvgU <- 4
Stan <- TRUE
Fast <- TRUE
FOI <- c()
concat <- TRUE
## Check obj
if(class(obj) != "bakRData"){
stop("obj must be of class bakRData")
}
## Check high_p
if(!is.numeric(high_p)){
stop("high_p must be numeric")
}else if( (high_p < 0) | (high_p > 1) ){
stop("high_p must be between 0 and 1")
}else if (high_p < 0.01){
warning("high_p is abnormally low (< 0.01); many features will by pure chance have a higher mutation rate than this in a -s4U control and thus get filtered out")
}
## Check totcut
if(!is.numeric(totcut)){
stop("totcut must be numeric")
}else if( totcut < 0 ){
stop("totcut must be greater than 0")
}else if(totcut > 5000){
warning("totcut is abnormally high (> 5000); many features will not have this much coverage in every sample and thus get filtered out.")
}
## Check Ucut
if(!is.numeric(Ucut)){
stop("Ucut must be numeric")
}else if( Ucut < 0 ){
stop("Ucut must be greater than 0")
}else if(Ucut > 0.5 ){
warning("Ucut is abnormally high; you are allowing > 50% of reads to have 2 or less Us.")
}
## Check AvgU
if(!is.numeric(AvgU)){
stop("AvgU must be numeric")
}else if(AvgU < 0){
stop("AvgU must be greater than or equal to 0")
}else if (AvgU > 50){
warning("AvgU is abnormally high; you are requiring an average number of Us greater than 50")
}else if(AvgU < 4){
warning("AvgU is abnormally low; you are allowing an average of less than 4 Us per read, which may model convergence issues.")
}
## Check Stan
if(!is.logical(Stan)){
stop("Stan must be logical (TRUE or FALSE)")
}
## Check Fast_prep
if(!is.logical(Fast)){
stop("Fast must be logical (TRUE or FALSE")
}
## Check FOI
if(!is.null(FOI)){
if(typeof(obj$cB$XF) != typeof(FOI)){
warning("FOI should be the same data type as cB$XF in the bakRData object; if it is not none of the feature of interest will be found
in the cB.")
}
}else{
if(concat == FALSE){
stop("concat cannot be FALSE if FOI is null; this would cause no features to make it past filtering")
}
}
## Check concat
if(!is.logical(concat)){
stop("concat must be logical (TRUE or FALSE)")
}
start_1 <- Sys.time()
cB <- obj$cB
metadf <- obj$metadf
samp_list <- unique(cB$sample)
c_list <- rownames(metadf[metadf$tl == 0,])
s4U_list <- samp_list[!(samp_list %in% c_list)]
type_list <- ifelse(metadf[samp_list, "tl"] == 0, 0, 1)
mut_list <- metadf[samp_list, "Exp_ID"]
rep_list <- metadf[samp_list,] %>% dplyr::mutate(ctl = ifelse(tl == 0, 0, 1)) %>%
dplyr::group_by(ctl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id)
rep_list <- rep_list$r_id
metadf <- metadf[samp_list, ] %>% dplyr::mutate(ctl = ifelse(tl == 0, 0, 1)) %>%
dplyr::group_by(ctl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup()
names(type_list) <- samp_list
names(mut_list) <- samp_list
names(rep_list) <- samp_list
nreps <- max(rep_list)
# Helper function:
getType <- function(s) type_list[paste(s)]
getMut <- function(s) mut_list[paste(s)]
getRep <- function(s) rep_list[paste(s)]
end_1 <- Sys.time()
start_2 <- Sys.time()
# Get reliable features:
if(concat == TRUE | is.null(FOI)){
message("Finding reliable Features")
reliables <- bakR::reliableFeatures(obj, high_p = high_p, totcut = totcut, Ucut = Ucut, AvgU = AvgU)
keep <- c(FOI, reliables[!(reliables %in% FOI)])
}else{
keep <- FOI
}
if((length(keep) == 0) | (is.null(keep))){
stop("No features made it past filtering.Try increasing the read count or -s4U background mutation rate cutoffs.")
}
end_2 <- Sys.time()
start_3 <- Sys.time()
message("Filtering out unwanted or unreliable features")
cB <- cB %>% dplyr::ungroup() %>%
dplyr::filter(XF %in% keep)
cB <- data.table::setDT(cB)
ranked_features_df <- cB[, .N, by = .(XF)]
ranked_features_df <- ranked_features_df %>%
dplyr::mutate(fnum = order(XF)) %>%
dplyr::arrange(fnum) %>%
dplyr::select(XF, fnum)
names(ranked_features_df)[names(ranked_features_df) == "N"] <- "n"
ranked_features_df
end_3 <- Sys.time()
start_4 <- Sys.time()
message("Processing data...")
Counts_df <- cB[, .N, by = .(XF, sample)]
Counts_df <- Counts_df %>%
dplyr::right_join(ranked_features_df, by = 'XF') %>% dplyr::ungroup()
Counts_df
names(Counts_df)[names(Counts_df) == "N"] <- "n"
Counts_df
end_4 <- Sys.time()
start_5 <- Sys.time()
# Make count matrix
Cnt_mat <- matrix(0, ncol = length(samp_list), nrow = length(unique(Counts_df$XF)))
for(s in seq_along(samp_list)){
Cnt_mat[,s] <- Counts_df$n[Counts_df$sample == samp_list[s]]
}
rownames(Cnt_mat) <- Counts_df$XF[Counts_df$sample == samp_list[1]]
colnames(Cnt_mat) <- samp_list
rm(Counts_df)
sdf_Utmp <- cB[, .N, by = .(sample, XF, TC, nT)]
names(sdf_Utmp)[names(sdf_Utmp) == "N"] <- "n"
sdf_U < sdf_Utmp %>%
dplyr::right_join(ranked_features_df, by = 'XF') %>%
dplyr::ungroup()
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
test$times
anti_join(check_fast, test$Fast_df)
dplyr::anti_join(check_fast, test$Fast_df)
test$Fast_df
check_fast
test$Fast_df
nrow(test$Fast_df)
test <- bakR::cBprocess(sim$bakRData)
dplyr::anti_join(check_fast, test$Fast_df)
devtools::load_all()
test <- bakR::cBprocess(sim$bakRData)
dplyr::anti_join(check_fast, test$Fast_df)
set.seed(123)
sim <- Simulate_bakRData(3000)
devtools::load_all()
set.seed(123)
sim2 <- Simulate_bakRData(3000)
dplyr::anti_join(sim$bakRData$cB, sim2$bakRData$cB)
library(tidyverse)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
setwd("C:/Users/isaac/Documents/Simon_Lab/bakR/")
devtools::load_all()
###
sim <- Simulate_bakRData(200, nreps = 2)
Fit <- bakRFit(sim$bakRData, pnew = rep(0.05, times = 4), pold = 0.001)
setwd("C:/Users/isaac/Documents/Simon_Lab/")
safefit <- stan(file = "Mutrate_est.stan",
data = Fit$Data_lists$Stan_data)
###
sim <- Simulate_bakRData(50, nreps = 2)
Fit <- bakRFit(sim$bakRData, pnew = rep(0.05, times = 4), pold = 0.001)
setwd("C:/Users/isaac/Documents/Simon_Lab/")
safefit <- stan(file = "Mutrate_est.stan",
data = Fit$Data_lists$Stan_data)
fit_summary <- as.data.frame(summary(fit)$summary)
fit_summary <- as.data.frame(summary(safefit)$summary)
fit_summary
fit_summary$parameter <- row.names(fit_summary)
fit_summary <- as_tibble(fit_summary)
fit_summary
kdeg_summary <- fit_summary[grep("kd_rep", fit_summary$parameter),]
kdeg_summary
nrep <- Fit$Data_lists$Stan_data$nrep
nMT <- Fit$Data_lists$Stan_data$nMT
kdeg_summary$FN <- rep(1:nrow(kdeg_summary)/(nreps*nMT), each = nreps*nMT)
kdeg_summary$MT <- rep(rep(1:nMT, each = nreps), times = nrow(kdeg_sumary)/(nreps*nMT))
nreps <- Fit$Data_lists$Stan_data$nrep
nMT <- Fit$Data_lists$Stan_data$nMT
kdeg_summary$FN <- rep(1:nrow(kdeg_summary)/(nreps*nMT), each = nreps*nMT)
kdeg_summary$MT <- rep(rep(1:nMT, each = nreps), times = nrow(kdeg_sumary)/(nreps*nMT))
nrow(kdeg_summary)
Fit$Data_lists$Stan_data$NF*4
1:nrow(kdeg_summary)/(nreps*nMT)
nreps
nMT
kdeg_summary$FN <- rep(1:(nrow(kdeg_summary)/(nreps*nMT)), each = nreps*nMT)
kdeg_summary$MT <- rep(rep(1:nMT, each = nreps), times = nrow(kdeg_sumary)/(nreps*nMT))
kdeg_summary$MT <- rep(rep(1:nMT, each = nreps), times = nrow(kdeg_summary)/(nreps*nMT))
kdeg_summary <- kdeg_summary %>% group_by(FN, MT) %>%
sumarise(avg_mean = stats::weighted.mean(mean, weights = 1/sd),
avg_sd = sqrt(1/sum(1/(var(mean) + sd^2 ) ) ))
kdeg_summary <- kdeg_summary %>% group_by(FN, MT) %>%
summarise(avg_mean = stats::weighted.mean(mean, weights = 1/sd),
avg_sd = sqrt(1/sum(1/(var(mean) + sd^2 ) ) ))
kdeg_summary
L2FC_kdeg <- kdeg_summary %>% group_by(FN) %>%
summarise(L2FC = avg_mean[MT == 2] - avg_mean[MT == 1],
se = sqrt(sum(avg_sd^2))) %>% ungroup() %>%
mutate(pval = 2*dnorm(-abs(L2FC/se)),
padj = stats::p.adjust(pval, method = "BH"))
L2FC_kdeg
hist(L2FC_kdeg$L2FC[L2FC_kdeg$FN > 500])
hist(L2FC_kdeg$L2FC[L2FC_kdeg$FN > 25])
hist(L2FC_kdeg$L2FC)
getwd()
### Fit with Stan
safefit <- stan(file = "Ole_reliable.stan",
data = Fit$Data_lists$Stan_data)
### Summarise fit
fit_summary <- as.data.frame(summary(safefit)$summary)
### Add parameter column
fit_summary$parameter <- row.names(fit_summary)
### Make tibble because I like tibbles
fit_summary <- as_tibble(fit_summary)
### Extract log(kdeg) estimates
kdeg_summary <- fit_summary[grep("log_kd_rep", fit_summary$parameter),]
nreps <- Fit$Data_lists$Stan_data$nrep
nMT <- Fit$Data_lists$Stan_data$nMT
### Add feature number of experimental ID information
kdeg_summary$FN <- rep(1:(nrow(kdeg_summary)/(nreps*nMT)), each = nreps*nMT)
kdeg_summary$MT <- rep(rep(1:nMT, each = nreps), times = nrow(kdeg_summary)/(nreps*nMT))
### Average log(kdeg) over replicates
kdeg_summary <- kdeg_summary %>% group_by(FN, MT) %>%
summarise(avg_mean = stats::weighted.mean(mean, weights = 1/sd),
avg_sd = sqrt(1/sum(1/(var(mean) + sd^2 ) ) ))
### Calcualte L2FC(kdeg)
L2FC_kdeg <- kdeg_summary %>% group_by(FN) %>%
summarise(L2FC = avg_mean[MT == 2] - avg_mean[MT == 1],
se = sqrt(sum(avg_sd^2))) %>% ungroup() %>%
mutate(pval = 2*dnorm(-abs(L2FC/se)),
padj = stats::p.adjust(pval, method = "BH"))
hist(L2FC_kdeg$L2FC)
devtools::load_all()
setwd("C:/Users/isaac/Documents/Simon_Lab/bakR/")
devtools::load_all()
simdat <- Simulate_bakRData(500, nreps = 2)
simdat$bakRData$metadf
metadf <- simdat$bakRData$metadf
metadf[,7] <- c(60, 2)
old_metadf <- simdat$bakRData$metadf
metadf <- data.frame(tl = c(metadf$tl, 60),
Exp_ID = c(metadf$Exp_ID, 2))
metadf
samp_list <- 1:nrow(metadf)
rep_list <- metadf[samp_list,] %>% dplyr::mutate(ctl = ifelse(tl == 0, 0, 1)) %>%
dplyr::group_by(ctl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup() %>% dplyr::select(r_id)
rep_list
rep_list <- rep_list$r_id
metadf <- metadf[samp_list, ] %>% dplyr::mutate(ctl = ifelse(tl == 0, 0, 1)) %>%
dplyr::group_by(ctl, Exp_ID) %>% dplyr::mutate(r_id = 1:length(tl)) %>% dplyr::ungroup()
metadf
simdat <- Simulate_bakRData(500, nreps = 3)
simdat <- Simulate_bakRData(500, nreps = 3)
simbakR <- simdat$bakRData
simcB <- simbakR$cB
unique(simcB$sample)
simbakR$metadf
row.names(simbakR$metadf)
## Remove sample "1"
simcB <- simcB[simcB$sample != "1",]
simmeta <- simbakR$metadf[2:8,]
simmeta
newbakR <- bakRData(simcB, simmeta)
dataprocess <- cBprocess(newbakR)
dataprocess$Stan_data
c(2, 3)
reps <- c(2, 3)
seq(from = 1, to = c(2, 3), by = 1)
c(sapply(reps, function(x) seq(1, x)))
unlist(sapply(reps, function(x) seq(1, x)))
?sapply
seq(from = 1, to = 2, each = reps)
rep(1:2, times = reps)
setwd("C:/Users/isaac/Documents/Simon_Lab/bakR/")
devtools::load_all()
devtools::load_all()
Fit <- bakRFit(newbakR)
devtools::load_all()
Fit <- bakRFit(newbakR)
plotVolcano(Fit$Fast_Fit)
Fit$Fast_Fit$Regularized_ests
Fit$Fast_Fit$Fn_Estimates
simdat
simdat$sim_list$Fn_rep_sim
Fnsim <- simdat$sim_list$Fn_rep_sim
Fnsim
Fnsim <- Fnsim[!(Fnsim$Exp_ID ==1 & Fnsim$Replicate == 1),]
plot(Fnsim$Logit_fn, Fit$Fast_Fit$Fn_Estimates$logit_fn)
nrow(Fnsim)
nrow(Fit$Fast_Fit$Fn_Estimates)
Fnsim
Fnsim <- Fnsim[Fnsim$Feature_ID %in% Fit$Fast_Fit$Effects_df$XF,]
plot(Fnsim$Logit_fn, Fit$Fast_Fit$Fn_Estimates$logit_fn)
abline(0,1)
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 7)
warnings()
test1 <- data.frame(pnew = c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05), R = rep(1:3, times = 2), E = rep(1:2, each = 3))
test1
test2 <- data.frame(R = c(1, 2, 1, 2, 3), E = c(1, 1, 2, 2, 2))
left_join(test1, test2)
dplyr::left_join(test1, test2)
dplyr::right_join(test1, test2)
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 7)
devtools::load_all()
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 7)
warnings()
devtools::load_all()
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 7)
devtools::load_all()
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 10)
?right_join
devtools::load_all()
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 10)
plot(Fnsim$Logit_fn, Fit$Fast_Fit$Fn_Estimates$logit_fn)
abline(0,1)
### Testing edited Hybrid analysis
Fit <- bakRFit(Fit, HybridFit = TRUE)
plotVolcano(Fit$Hybrid_Fit)
plot(Fit$Fast_Fit$Effects_df$effect/Fit$Fast_Fit$Effects_df$se,
Fit$Hybrid_Fit$Effects_df$effect/Fit$Hybrid_Fit$Effects_df$se)
abline(0,1)
test1 <- data.frame(a = c(1, 2, 3), b = c(1, 1, 2, 2, 2), c = c(1, 2, 1, 2, 3))
test1 <- data.frame(a = c(1, 2, 3, 4, 5), b = c(1, 1, 2, 2, 2), c = c(1, 2, 1, 2, 3))
test1
test1 <- data.frame(a = c(1, 2, 3, 4, 5), b = c(1, 1, 1, 1, 2), c = c(1, 1, 2, 2, 1))
test1
test2 <- data.frame(b = 1, c = 1)
right_join(test1, test2)
dplyr::right_join(test1, test2, by = c("b", "c"))
devtools::load_all()
devtools::load_all()
### Testing edited Hybrid analysis
Fit <- bakRFit(Fit, HybridFit = TRUE)
simdat <- Simulate_bakRData(250, nreps = 3)
simbakR <- simdat$bakRData
simcB <- simbakR$cB
## Remove sample "1"
simcB <- simcB[simcB$sample != "1",]
simmeta <- simbakR$metadf[2:8,]
newbakR <- bakRData(simcB, simmeta)
dataprocess <- cBprocess(newbakR)
dataprocess$Stan_data
Fit <- bakRFit(newbakR)
## What if I use StanRateEst
Fit <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE, RateEst_size = 7)
devtools::load_all()
Fit$Data_lists$Stan_data$nrep_vect
### Testing edited Hybrid analysis
Fit <- bakRFit(Fit, HybridFit = TRUE)
plotVolcano(Fit$Hybrid_Fit)
plot(Fit$Fast_Fit$Effects_df$effect/Fit$Fast_Fit$Effects_df$se,
Fit$Hybrid_Fit$Effects_df$effect/Fit$Hybrid_Fit$Effects_df$se)
abline(0,1)
plot(Fit$Fast_Fit$Fn_Estimates$logit_fn, Fit$Hybrid_Fit$Fn_Estimates$logit_fn)
abline(0,1)
### Testing MCMC analysis
Fit <- bakRFit(Fit, StanFit = TRUE)
simdat <- Simulate_bakRData(250, nreps = 3, pnew = 0.02)
simbakR <- simdat$bakRData
simcB <- simbakR$cB
## Remove sample "1"
simcB <- simcB[simcB$sample != "1",]
simmeta <- simbakR$metadf[2:8,]
newbakR <- bakRData(simcB, simmeta)
dataprocess <- cBprocess(newbakR)
dataprocess$Stan_data
Fit <- bakRFit(newbakR)
Fit$Fast_Fit
Fit <- bakRFit(newbakR)
# Check accuracy
Fnsim <- simdat$sim_list$Fn_rep_sim
Fnsim <- Fnsim[!(Fnsim$Exp_ID ==1 & Fnsim$Replicate == 1),]
Fnsim <- Fnsim[Fnsim$Feature_ID %in% Fit$Fast_Fit$Effects_df$XF,]
plot(Fnsim$Logit_fn, Fit$Fast_Fit$Fn_Estimates$logit_fn)
abline(0,1)
newbakR
devtools::load_all()
