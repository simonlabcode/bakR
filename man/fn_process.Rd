% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cBprocessing.R
\name{fn_process}
\alias{fn_process}
\title{Curate data in bakRFnData object for statistical modeling}
\usage{
fn_process(obj, totcut = 50, Chase = FALSE, FOI = c())
}
\arguments{
\item{obj}{An object of class bakRFnData}

\item{totcut}{Numeric; Any transcripts with less than this number of sequencing reads in any sample are filtered out}

\item{Chase}{Boolean; if TRUE, pulse-chase analysis strategy is implemented}

\item{FOI}{Features of interest; character vector containing names of features to analyze}

\item{concat}{Boolean; If TRUE, FOI is concatenated with output of reliableFeatures}
}
\value{
returns list of objects that can be passed to \code{TL_stan} and/or \code{fast_analysis}. Those objects are:
\itemize{
\item Stan_data; list that can be passed to \code{TL_stan} with Hybrid_Fit = TRUE. Consists of metadata as well as data that
\code{Stan} will analyze. Data to be analyzed consists of equal length vectors. The contents of Stan_data are:
\itemize{
\item NE; Number of datapoints for 'Stan' to analyze (NE = Number of Elements)
\item NF; Number of features in dataset
\item TP; Numerical indicator of s4U feed (0 = no s4U feed, 1 = s4U fed)
\item FE; Numerical indicator of feature
\item num_mut; Number of U-to-C mutations observed in a particular set of reads
\item MT; Numerical indicator of experimental condition (Exp_ID from metadf)
\item nMT; Number of experimental conditions
\item R; Numerical indicator of replicate
\item nrep; Number of replicates (maximum across experimental conditions)
\item nrep_vect; Vector of number of replicates in each experimental condition
\item tl; Vector of label times for each experimental condition
\item Avg_Reads; Standardized log10(average read counts) for a particular feature in a particular condition, averaged over
replicates
\item sdf; Dataframe that maps numerical feature ID to original feature name. Also has read depth information
\item sample_lookup; Lookup table relating MT and R to the original sample name
}
\item Fn_est; A data frame containing fraction new estimates:
\itemize{
\item sample; Original sample name
\item XF; Original feature name
\item fn; Fraction new estimate
\item n; Number of reads
\item Feature_ID; Numerical ID for each feature
\item Replicate; Numerical ID for each replicate
\item Exp_ID; Numerical ID for each experimental condition
\item tl; s4U label time
\item logit_fn; logit of fraction new estimate
\item kdeg; degradation rate constant estimate
\item log_kdeg; log of degradation rate constant estimate
\item logit_fn_se; Uncertainty of logit(fraction new) estimate
\item log_kd_se; Uncertainty of log(kdeg) estimate
}
\item Count_Matrix; A matrix with read count information. Each column represents a sample and each row represents a feature.
Each entry is the raw number of read counts mapping to a particular feature in a particular sample. Column names are the corresponding
sample names and row names are the corresponding feature names.
}
}
\description{
\code{cBprocess} creates the data structures necessary to analyze nucleotide recoding RNA-seq data with the
MLE and Hybrid implementations in \code{bakRFit}. The input to \code{Fnprocess} must be an object of class
\code{bakRFnData}.
}
\details{
The 1st step executed by \code{cBprocess} is to find the names of features which are deemed "reliable". A reliable feature is one with
sufficient read coverage in every single sample (i.e., > totcut reads in all samples) and limited mutation content in all -s4U
control samples (i.e., < high_p mutation rate in all samples lacking s4U feeds). This is done with a call to \code{reliableFeatures}.
The 2nd step is to extract only reliableFeatures from the cB dataframe in the \code{bakRData} object. During this process, a numerical
ID is given to each reliableFeature, with the numerical ID corresponding to the order in which each feature is found in the original cB
(this might typically be alphabetical order).

The 3rd step is to prepare a dataframe where each row corresponds to a set of n identical reads (that is they come from the same sample
and have the same number of mutations and Us). Part of this process involves assigning an arbitrary numerical ID to each replicate in each
experimental condition. The numerical ID will correspond to the order the sample appears in metadf. The outcome of this step is multiple
dataframes with variable information content. These include a dataframe with information about read counts in each sample, one which logs
the U-contents of each feature, one which is compatible with \code{fast_analysis} and thus groups reads by their number of mutations as
well as their number of Us, and one which is compatible with \code{TL_stan} with StanFit == TRUE and thus groups ready by only their number
of mutations. At the end of this step, two other smaller data structures are created, one which is an average count matrix (a count matrix
where the ith row and jth column corresponds to the average number of reads mappin to feature i in experimental condition j, averaged over
all replicates) and the other which is a sample lookup table that relates the numerical experimental and replicate IDs to the original
sample name.

If FOI is non-null and concat == TRUE, the features listed in FOI will be included in the list of reliable features that make it past
filtering. If FOI is non-null and concat == FALSE, the features listed in FOI will be the only reliable features that make it past filtering.
If FOI is null and concat == FALSE, an error will be thrown.
}
\examples{
\donttest{

# Load cB
data("cB_small")

# Load metadf
data("metadf")

# Create bakRData
bakRData <- bakRData(cB_small, metadf)

# Preprocess data
data_for_bakR <- cBprocess(obj = bakRData)
}
}
