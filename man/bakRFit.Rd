% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Fitting_Models.R
\name{bakRFit}
\alias{bakRFit}
\title{Estimating kinetic parameters from nucleotide recoding RNA-seq data}
\usage{
bakRFit(
  obj,
  StanFit = FALSE,
  HybridFit = FALSE,
  high_p = 0.2,
  totcut = 50,
  Ucut = 0.25,
  AvgU = 4,
  FastRerun = FALSE,
  Stan_prep = TRUE,
  Fast_prep = TRUE,
  FOI = c(),
  concat = TRUE,
  StanRateEst = FALSE,
  RateEst_size = 25,
  low_reads = 1000,
  high_reads = 5000,
  chains = 1,
  NSS = FALSE,
  BDA_model = FALSE,
  ...
)
}
\arguments{
\item{obj}{bakRData object produced by \code{bakRData} or a bakRFit object produced by \code{bakRFit}}

\item{StanFit}{Logical; if TRUE, then Fully Bayesian Hierarchical model is implemented to estimate fraction news and pool information
across the dataset}

\item{HybridFit}{Logical; if TRUE, then a Fully Bayesian Hierarchical model is run using
estimates for the fraction new and fraction new uncertainty obtained via the efficient
statistical model.}

\item{high_p}{Numeric; Any transcripts with a mutation rate (number of mutations / number of Ts in reads) higher than this in any no s4U control
samples are filtered out}

\item{totcut}{Numeric; Any transcripts with less than this number of sequencing reads in any sample are filtered out}

\item{Ucut}{Numeric; All transcripts must have a fraction of reads with 2 or less Us less than this cutoff in all samples}

\item{AvgU}{Numeric; All transcripts must have an average number of Us greater than this cutoff in all samples}

\item{FastRerun}{Logical; only matters if a bakRFit object is passed to \code{bakRFit()}. If TRUE, then the Stan-free
model implemented in \code{fast_analysis} is rerun on data, foregoing fitting of either of the Stan models.}

\item{Stan_prep}{Logical; if TRUE, then data_list that can be passed to Stan is curated}

\item{Fast_prep}{Logical; if TRUE, then dataframe that can be passed to fast_analysis() is curated}

\item{FOI}{Features of interest; character vector containing names of features to analyze}

\item{concat}{Logical; If TRUE, FOI is concatenated with output of reliableFeatures}

\item{StanRateEst}{Logical; if TRUE, a simple Stan model is used to estimate mutation rates for fast_analysis; this may add a couple minutes
to the runtime of the analysis.}

\item{RateEst_size}{Numeric; if StanRateEst is TRUE, then data from RateEst_size genes are used for mutation rate estimation. This can be as low
as 1 and should be kept low to ensure maximum efficiency}

\item{low_reads}{Numeric; if StanRateEst is TRUE, then only features with more than low_reads reads in all samples will be used for mutation rate estimation}

\item{high_reads}{Numeric; if StanRateEst is TRUE, then only features with less than high_read reads in all samples will be used for mutation rate estimation.
A high read count cutoff is as important as a low read count cutoff in this case because you don't want the fraction labeled of chosen features to be
extreme (e.g., close to 0 or 1), and high read count features are likely low fraction new features.}

\item{chains}{Number of Markov chains to sample from. 1 should suffice since these are validated models. Running more chains is generally
preferable, but memory constraints can make this unfeasible.}

\item{NSS}{Logical; if TRUE, logit(fn)s are directly compared to avoid assuming steady-state}

\item{BDA_model}{Logical; if TRUE, variance is regularized with scaled inverse chi-squared model. Otherwise a log-normal
model is used.}

\item{...}{Arguments passed to either \code{fast_analysis} (if a bakRData object)
or \code{TL_Stan} and \code{Hybrid_fit} (if a bakRFit object)}
}
\value{
bakRFit object with results from statistical modeling and data processing. Objects possibly included are:
\itemize{
\item Fast_Fit; Always will be present. Output of \code{fast_analysis}
\item Hybrid_Fit; Only present if HybridFit = TRUE. Output of \code{TL_stan}
\item Stan_Fit; Only present if StanFit = TRUE. Output of \code{TL_stan}
\item Data_lists; Always will be present. Output of \code{cBprocess} with Fast and Stan == TRUE
}
}
\description{
\code{bakRFit} analyzes nucleotide recoding RNA-seq data to estimate
kinetic parameters relating to RNA stability and changes in RNA
stability induced by experimental perturbations. Several statistical
models of varying efficiency and accuracy can be used to fit data.
}
\details{
If \code{bakRFit} is run on a bakRData object, \code{cBprocess}
and then \code{fast_analysis} will always be called. The former will generate the processed
data that can be passed to the model fitting functions (\code{fast_analysis}
and \code{TL_Stan}). The call to \code{fast_analysis} will generate a list of dataframes
containing information regarding the \code{fast_analysis} fit. \code{fast_analysis} is always
called because its output is required for both \code{Hybrid_fit} and \code{TL_Stan}.

If \code{bakRFit} is run on a bakRFit object, \code{cBprocess} will not be called again,
as the output of \code{cBprocess} will already be contained in the bakRFit object. Similarly,
\code{fast_analysis} will not be called again unless bakRFit is rerun on the bakRData object.
or if \code{FastRerun} is set to TRUE. If you want to generate model fits using different parameters for cBprocess,
you will have to rerun \code{bakRFit} on the bakRData object.

See the documentation for the individual fitting functions for details regarding how they analyze nucleotide
recoding data. What follows is a brief overview of how each works

\code{fast_analysis} either estimates mutation rates from + and - s4U samples or uses mutation rate estimates
provided by the user to perform maximum likelihood estimation (MLE) of the fraction of RNA that is labeled for each
replicate of nucleotide recoding data provided. Uncertainties for each replicate's estimate are approximated using
asymptotic results involving the Fisher Information and assuming known mutation rates. Replicate data
is pooled using an approximation to hierarchical modeling that relies on analytic solutions to simple Bayesian models.
Linear regression is used to estimate the relationship between read depths and replicate variability for uncertainty
estimation regularization, again performed using analytic solutions to Bayesian models.

\code{Hybrid_fit} takes as input estimates of the logit(fraction new) and uncertainty provided by \code{fast_analysis}.
It then uses Stan on the backend to implement a hierarchical modeling that pools data across replicates and the dataset
to estimate effect sizes (L2FC(kdeg)) and uncertainties. Replicate variability information is pooled across each experimental
condition to regularize variance estimates using a hierarchical linear regression model.

\code{TL_Stan} uses Stan on the back end to implement a model similar to \code{Hybrid_fit}. The difference is that while
\code{Hybrid_fit} requires fraction new estimates from \code{fast_analysis}, \code{TL_Stan} implements a U-content exposure
adjusted Poisson model to estimate fraction news while also using hierarchical modeling to partially pool information across
replicates and the entire dataset.
}
