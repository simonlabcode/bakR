[{"path":"https://simonlabcode.github.io/bakR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Isaac Vock Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Differential-Synth.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Differential synthesis analysis with bakR and DESeq2","text":"Welcome! vignette discusses perform differential synthesis analysis. involves combining output bakR differential expression analysis software. assumption point worked “Differential kinetic analysis bakR” vignette, succinct alternative. case, highly suggest starting coming back ’re familiar standard use cases bakR. packages going install load order everything presented vignette:","code":"library(bakR)  # Packages that are NOT automatically installed when bakR is installed library(DESeq2) #> Loading required package: S4Vectors #> Loading required package: stats4 #> Loading required package: BiocGenerics #>  #> Attaching package: 'BiocGenerics' #> The following object is masked from 'package:bakR': #>  #>     plotMA #> The following objects are masked from 'package:stats': #>  #>     IQR, mad, sd, var, xtabs #> The following objects are masked from 'package:base': #>  #>     anyDuplicated, aperm, append, as.data.frame, basename, cbind, #>     colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, #>     get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, #>     match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, #>     Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort, #>     table, tapply, union, unique, unsplit, which.max, which.min #>  #> Attaching package: 'S4Vectors' #> The following object is masked from 'package:utils': #>  #>     findMatches #> The following objects are masked from 'package:base': #>  #>     expand.grid, I, unname #> Loading required package: IRanges #> Loading required package: GenomicRanges #> Loading required package: GenomeInfoDb #> Loading required package: SummarizedExperiment #> Loading required package: MatrixGenerics #> Loading required package: matrixStats #>  #> Attaching package: 'MatrixGenerics' #> The following objects are masked from 'package:matrixStats': #>  #>     colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, #>     colCounts, colCummaxs, colCummins, colCumprods, colCumsums, #>     colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, #>     colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, #>     colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, #>     colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, #>     colWeightedMeans, colWeightedMedians, colWeightedSds, #>     colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, #>     rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, #>     rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, #>     rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, #>     rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, #>     rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, #>     rowWeightedMads, rowWeightedMeans, rowWeightedMedians, #>     rowWeightedSds, rowWeightedVars #> Loading required package: Biobase #> Welcome to Bioconductor #>  #>     Vignettes contain introductory material; view with #>     'browseVignettes()'. To cite Bioconductor, see #>     'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. #>  #> Attaching package: 'Biobase' #> The following object is masked from 'package:MatrixGenerics': #>  #>     rowMedians #> The following objects are masked from 'package:matrixStats': #>  #>     anyMissing, rowMedians  # Packages which are installed when bakR is installed library(dplyr)  #>  #> Attaching package: 'dplyr' #> The following object is masked from 'package:Biobase': #>  #>     combine #> The following object is masked from 'package:matrixStats': #>  #>     count #> The following objects are masked from 'package:GenomicRanges': #>  #>     intersect, setdiff, union #> The following object is masked from 'package:GenomeInfoDb': #>  #>     intersect #> The following objects are masked from 'package:IRanges': #>  #>     collapse, desc, intersect, setdiff, slice, union #> The following objects are masked from 'package:S4Vectors': #>  #>     first, intersect, rename, setdiff, setequal, union #> The following objects are masked from 'package:BiocGenerics': #>  #>     combine, intersect, setdiff, union #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(magrittr)  #>  #> Attaching package: 'magrittr' #> The following object is masked from 'package:GenomicRanges': #>  #>     subtract library(ggplot2)  library(stats)  # Set the seed for reproducibility set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/Differential-Synth.html","id":"intro-to-differential-synthesis-analysis","dir":"Articles","previous_headings":"","what":"Intro to differential synthesis analysis","title":"Differential synthesis analysis with bakR and DESeq2","text":"claim bakR tool performing differential kinetic analysis, coming “Differential kinetic analysis bakR” vignette might think misnomer. showed vignette differential stability analysis. Full-fledged differential kinetic analysis means performing differential synthesis analysis well, let’s talk can bakR. bakR won’t able accomplish task alone. reason assessing changes synthesis means assessing changes RNA stability RNA expression. Therefore, need perform differential expression analysis conjunction differential stability analysis. theory, implemented differential expression analysis bakR, many popular software tools currently existence perform task, seemed pointlessly redundant. also gives freedom use whatever differential expression analysis tool used using, perform whatever kind DE analysis like independent bakR.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Differential-Synth.html","id":"differential-synthesis-rate-analysis-with-bakr-deseq2","dir":"Articles","previous_headings":"","what":"Differential synthesis rate analysis with bakR + DESeq2","title":"Differential synthesis analysis with bakR and DESeq2","text":"show perform differential synthesis analysis, using DESeq2 purpose differential expression analysis. ? like DESeq2. ’s nice model, ’s good piece software, early source inspiration PhD. Also, ’ll see output bakR specifically designed DESeq2 mind, facilitate process performing differential expression analysis bit. First things first, let’s simulate data! ’ll simulate 1000 genes, 200 observing differential synthesis changes stability. Let’s also run efficient bakR implementation . second step perform differential expression analysis. alluded , bakR makes bit easier, way providing count matrix formatted just DESeq2 likes ! DESeq2 also requires one input, dataframe provides information covariates (things distinguish samples). code produce necessary inputs make sure correctly mapped samples experimental conditions colData object, can create sweet sweet DESeqDataObject invite read DESeq2 documentation need help understanding call DESeqDataSetFromMatrix. short though, first entry count matrix, second colData object, final entry design matrix. Limma’s documentation (another differential expression analysis software) great introduction design matrices, one simple. means want group samples together value conditions factor colData object. “ref” samples grouped together “exp” samples grouped together. DESeq2 compare different groups, means compare “exp” “ref” samples case. Now can fit DESeq2 extract differential expression analysis results: sake, going use two columns reso object: log2FoldChange lfcSE. column names pretty self-explanatory, completeness sake, log2FoldChange log base-2 fold change RNA expression, lfcSE standard error log2FoldChange. , need perform differential synthesis analysis! may ask? Well, population cells performed RNA-seq steady-state (.e., cells actively responding perturbation treating metabolic label), following relationship holds \\(ksyn\\) (RNA synthesis rate) \\(kdeg\\) (RNA degradation rate) \\([RNA]\\) (RNA concentration): \\[ [RNA] = \\frac{ksyn}{kdeg} \\] Therefore, log2 fold change \\([RNA]\\) (\\(L2FC(RNA)\\)) : \\[ \\begin{align} L2FC(RNA) &= log_2(\\frac{[RNA_{exp}]}{[RNA_{ref}]}) \\\\           &= log_2(\\frac{ksyn_{exp}*kdeg_{ref}}{ksyn_{ref}*kdeg_{exp}}) \\\\           &= log_2(\\frac{ksyn_{exp}}{ksyn_{ref}}) - log_2(\\frac{kdeg_{exp}}{kdeg_{ref}}) \\\\           &= L2FC(ksyn) - L2FC(kdeg) \\end{align} \\] Therefore, key conclusion performing differential synthesis analysis : \\[ L2FC(ksyn) = L2FC(RNA) + L2FC(kdeg) \\] bakR provides \\(L2FC(kdeg)\\) DESeq2 provides \\(L2FC(RNA)\\), everything need calculate \\(L2FC(ksyn)\\). Let’s make data.frame information: missing one key component though: uncertainty (standard error). can get bakR DESeq2? Well easiest conservative thing assume independence \\(L2FC(RNA)\\) \\(L2FC(kdeg)\\). ’s variances independent random variables add, : \\[ \\begin{align} \\text{Var}[L2FC(ksyn)] &= \\text{Var}[L2FC(kdeg) + L2FC(RNA)] \\\\ &= \\text{Var}[L2FC(kdeg)] + \\text{Var}[L2FC(RNA)] \\end{align} \\] \\(\\text{Var}[X]\\) variance random variable \\(X\\). can calculate standard error square root variance, meaning: \\[ \\text{se}[L2FC(ksyn)] = \\sqrt{se[L2FC(kdeg)]^2 + se[L2FC(RNA)]^2} \\] using non-standard notation \\(\\text{se}[X]\\) mean standard error \\(X\\). , can fill final component L2FC(ksyn) dataframe: se Effects_df log base-e fold change \\(kdeg\\), use fact : \\[ \\text{Var}[*X] = ^2*\\text{Var}[X] \\] constant . case, \\(log_2(e)\\) multiplicative factor necessary convert log base-2 log base-e. Now left calculate p-value multiple-test adjust (going use Benjamini-Hochberg multiple test adjustment bakR DESeq2 use). can now make \\(L2FC(ksyn)\\) volcano plot visualize final conclusions!  simulation features number 1-800 non-differentially synthesized RNA features 801-1000 200 differentially synthesized RNA. Therefore, can also see analysis performed  FP false positive, FN false negative, TP true positive, TN true negative. , ’d say went pretty well! now know perform differential synthesis analysis bakR + DEseq2. NOTE: version 1.0.0 bakR, DissectMechanism function bakR implement analysis strategy . See vignette mechanistic dissection details.","code":"# Simulate a nucleotide recoding dataset sim_data <- Simulate_bakRData(1000,                          num_kd_DE = c(0, 0),                          num_ks_DE = c(0, 200))   # This will simulate 500 features, 2 experimental conditions   # and 3 replicates for each experimental condition   # See ?Simulate_bakRData for details regarding tunable parameters  # Extract simulated bakRData object bakRData <- sim_data$bakRData  # Extract simualted ground truths sim_truth <- sim_data$sim_list  ## Run the efficient model # We'll tell it what the mutation rates are just for efficiency's sake Fit <- bakRFit(bakRData, pnew = rep(0.05, times = 6), pold = 0.001) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Using provided pnew estimates #> Using provided pold estimate #> Estimated pnews and polds for each sample are: #>   mut reps pnew  pold #> 1   1    1 0.05 0.001 #> 2   1    2 0.05 0.001 #> 3   1    3 0.05 0.001 #> 4   2    1 0.05 0.001 #> 5   2    2 0.05 0.001 #> 6   2    3 0.05 0.001 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Get the count matrix from bakR Counts <- Fit$Data_lists$Count_Matrix  # Experimental conditions for each sample # There are 6 s4U treated samples (3 replicates of each condition) # In addition, there are 2 -s4U control samples (1 for each condition)  ## s4U conditions # 1st three samples are reference (ref) samples # Next three samples are experimental (exp) samples conditions_s4U <- as.factor(rep(c(\"ref\", \"exp\"), each = 3))  ## -s4U control conditions # 1st sample is reference, next is experimental conditions_ctl <- as.factor(c(\"ref\", \"exp\"))  # Combined s4U and -s4U control conditions conditions <- c(conditions_s4U, conditions_ctl)  # Make the colData input for DESeq2 colData <- data.frame(conditions = conditions) rownames(colData) <- colnames(Counts)  # Take a look at the colData object print(t(colData)) dds <- DESeqDataSetFromMatrix(countData = Counts,                               colData = colData,                               design = ~conditions) #> converting counts to integer mode ddso <- DESeq(dds) #> estimating size factors #> estimating dispersions #> gene-wise dispersion estimates #> mean-dispersion relationship #> final dispersion estimates #> fitting model and testing  # Extract results of experimental vs. reference comparison reso <- results(ddso, contrast = c(\"conditions\", \"exp\", \"ref\"))  # Look at the column names of the reso object colnames(as.data.frame(reso)) #> [1] \"baseMean\"       \"log2FoldChange\" \"lfcSE\"          \"stat\"           #> [5] \"pvalue\"         \"padj\" ksyn_df <- data.frame(L2FC = reso$log2FoldChange + Fit$Fast_Fit$Effects_df$L2FC_kdeg,                       Gene = Fit$Fast_Fit$Effects_df$XF) ksyn_df$se <- sqrt(reso$lfcSE^2 + (Fit$Fast_Fit$Effects_df$se*log2(exp(1)))^2 ) # Calculate p-value using asymptotic Wald test ksyn_df <- ksyn_df %>%   mutate(pval = 2*pnorm(-abs(L2FC/se)),          padj = p.adjust(pval, method = \"BH\")) # Add conclusion at 0.01 FDR control ksyn_df <- ksyn_df %>%   mutate(conclusion = as.factor(ifelse(padj < 0.01,                               ifelse(L2FC < 0, \"Decreased txn\", \"Increased txn\"),                              \"Not sig.\")))  # Make volcano plot ksyn_volc <- ggplot(ksyn_df, aes(x = L2FC, y = -log10(padj), color = conclusion)) +    theme_classic() +    geom_point(size = 1) +    xlab(\"L2FC(ksyn)\") +    ylab(\"-log10(padj)\") +    scale_color_manual(values = c(\"blue\", \"orange\", \"gray\"))  # Observe volcano plot ksyn_volc # Add conclusion at 0.01 FDR control ksyn_df <- ksyn_df %>%   mutate(result = as.factor(ifelse(padj < 0.01,                               ifelse(as.integer(Gene) <= 800, \"FP\", \"TP\"),                              ifelse(as.integer(Gene) <= 800, \"TN\", \"FN\"))))  # Make volcano plot ksyn_results <- ggplot(ksyn_df, aes(x = L2FC, y = -log10(padj), color = result)) +    theme_classic() +    geom_point(size = 1) +    xlab(\"L2FC(ksyn)\") +    ylab(\"-log10(padj)\") +    scale_color_manual(values = c(\"black\", \"gray\", \"forestgreen\", \"blue\"))  # Observe volcano plot ksyn_results"},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"necessary-setup","dir":"Articles","previous_headings":"","what":"Necessary Setup","title":"Correcting for dropout","text":"bakR version 1.0.0 later necessary run vignette.","code":"library(bakR) set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"a-brief-tutorial-on-dropout-correction-in-bakr","dir":"Articles","previous_headings":"","what":"A Brief Tutorial on Dropout Correction in bakR","title":"Correcting for dropout","text":"bakR new simulation strategy version 1.0.0 allows accurate simulation dropout: Dropout cause bakR underestimate true fraction new. addition, low fraction new features receive read counts dropout existed (vice versa high fraction new features). biases can corrected single line code: Dropout lead correlation fraction new difference +s4U -s4U read counts. trend model fit can visualized follows:  can assess impact dropout correction comparing known simulated truth fraction new estimates, dropout correction. correction:  correction:","code":"# Simulate a nucleotide recoding dataset sim_data <- Simulate_relative_bakRData(1000, depth = 1000000, nreps = 2,                                        p_do = 0.4)   # This will simulate 500 features, 500,000 reads, 2 experimental conditions   # and 2 replicates for each experimental condition.   # 40% dropout is simulated.   # See ?Simulate_relative_bakRData for details regarding tunable parameters  # Run the efficient model Fit <- bakRFit(sim_data$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0497 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     2     1 0.0499 0.00100 #> 4     2     2 0.0497 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Correct dropout-induced biases Fit_c <- CorrectDropout(Fit) #> Estimated rates of dropout are: #>   Exp_ID Replicate       pdo #> 1      1         1 0.4013715 #> 2      1         2 0.3841179 #> 3      2         1 0.2627656 #> 4      2         2 0.3242958 #> Mapping sample name to sample characteristics #> Filtering out low coverage features #> Processing data... #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.   # You can also overwite the existing bakRFit object.   # I am creating a separate bakRFit object to make comparisons later in this vignette. # Correct dropout-induced biases Vis_DO <- VisualizeDropout(Fit) #> Estimated rates of dropout are: #>   Exp_ID Replicate       pdo #> 1      1         1 0.4013715 #> 2      1         2 0.3841179 #> 3      2         1 0.2627656 #> 4      2         2 0.3242958  # Visualize dropout for 1st replicate of reference condition Vis_DO$ExpID_1_Rep_1 # Extract simualted ground truths sim_truth <- sim_data$sim_list  # Features that made it past filtering XFs <- unique(Fit$Fast_Fit$Effects_df$XF)  # Simulated logit(fraction news) from features making it past filtering true_fn <- sim_truth$Fn_rep_sim$Logit_fn[sim_truth$Fn_rep_sim$Feature_ID %in% XFs]  # Estimated logit(fraction news) est_fn <- Fit$Fast_Fit$Fn_Estimates$logit_fn  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\") abline(0, 1, col = \"red\") # Features that made it past filtering XFs <- unique(Fit_c$Fast_Fit$Effects_df$XF)  # Simulated logit(fraction news) from features making it past filtering true_fn <- sim_truth$Fn_rep_sim$Logit_fn[sim_truth$Fn_rep_sim$Feature_ID %in% XFs]  # Estimated logit(fraction news) est_fn <- Fit_c$Fast_Fit$Fn_Estimates$logit_fn  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\") abline(0, 1, col = \"red\")"},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"rna-dropout-and-bakrs-correction-strategy","dir":"Articles","previous_headings":"","what":"RNA dropout and bakR’s correction strategy","title":"Correcting for dropout","text":"discussed Abstract vignette, dropout refers loss metabolically labeled RNA, reads said RNA. Dropout correction context bakR specifically designed address biases due loss metabolically labeled RNA library preparation. bakR’s strategy correcting dropout involves formalizing model dropout, using model infer parametric relationship biased fraction new estimate ratio +s4U -s4U read counts feature, fitting model data nonlinear least squares. bakR’s model dropout makes several simplifying assumptions ensure tractability parameter estimation still capturing important features process: average number reads come RNA feature related fraction sequenced RNA molecules derived feature. labeled RNA equally likely get lost library preparation, probability losing molecule labeled RNA referred pdo. assumptions lead following expressions expected number sequencing reads coming feature (index ) +s4U -s4U NR-seq data: \\[ \\begin{align} \\text{E[reads feature +s}^{\\text{4}}\\text{U sample]} &= \\frac{\\text{number molecules feature }}{\\text{total number molecules +s}^{\\text{4}}\\text{U sample}}*\\text{R}_{\\text{+s}^{\\text{4}}\\text{U}} \\\\                                               &= \\frac{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) + \\text{n}_{\\text{}}*(1 - \\theta_{\\text{}}) }{\\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}*\\theta_{\\text{j}}*(1 - \\text{pdo}) + \\text{n}_{\\text{j}}*(1 - \\theta_{\\text{j}}) }*\\text{R}_{\\text{+s}^{\\text{4}}\\text{U}} \\\\                                               \\\\                                               \\\\ \\text{E[reads feature -s}^{\\text{4}}\\text{U sample]} &= \\frac{\\text{number molecules feature }}{\\text{total number molecules -s}^{\\text{4}}\\text{U sample}}*\\text{R}_{\\text{-s}^{\\text{4}}\\text{U}} \\\\                                               &= \\frac{\\text{n}_{\\text{}}}{\\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}}*\\text{R}_{\\text{-s}^{\\text{4}}\\text{U}} \\end{align}                                   \\] parameters defined follows: \\[ \\begin{align} \\text{n}_{\\text{}} &= \\text{Number molecules feature } \\\\ \\theta_{\\text{}} &= \\text{True fraction new feature } \\\\ \\text{pdo} &= \\text{Probability labeled RNA molecule preferentially lost library prep} \\\\ \\text{NF} &= \\text{Total number RNA features contribute sequencable molecules} \\\\ \\text{R} &= \\text{Total number sequencing reads.} \\end{align} \\] Defining “dropout” ratio RPM normalized expected read counts yields following relationship “dropout”, fraction new, rate dropout: \\[ \\begin{align} \\text{Dropout} &= \\frac{\\text{E[reads feature +s}^{\\text{4}}\\text{U sample]/}\\text{R}_{\\text{+s}^{\\text{4}}\\text{U}}}{\\text{E[reads feature -s}^{\\text{4}}\\text{U sample]/}\\text{R}_{\\text{-s}^{\\text{4}}\\text{U}}} \\\\ \\\\                &= \\frac{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) + \\text{n}_{\\text{}}*(1 - \\theta_{\\text{}}) }{\\text{n}_{\\text{}}}*\\frac{\\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}}{ \\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}*\\theta_{\\text{j}}*(1 - \\text{pdo}) + \\text{n}_{\\text{j}}*(1 - \\theta_{\\text{j}})  } \\\\                \\\\                &= [\\theta_{\\text{}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{}})]*\\text{scale} \\\\                &= [1 - \\theta_{\\text{}}*\\text{pdo}]*\\text{scale} \\end{align} \\] \\(\\text{scale}\\) constant scale factor represents factor difference number sequencable molecules without dropout. Currently, relationship quantification dropout \\(\\text{pdo}\\) includes \\(\\theta_{\\text{}}\\), true, unbiased fraction new. Unfortunately, presence dropout means access quantify. Rather, estimate dropout biased fraction sequencing reads new (\\(\\theta_{\\text{}}^{\\text{}}\\)), average represent underestimation \\(\\theta_{\\text{}}\\). Therefore, need relate quantity estimate (\\(\\theta_{\\text{}}^{\\text{}}\\)) parameter wish estimate (\\(\\text{pdo}\\)) \\(\\theta_{\\text{}}\\). context model, relationship can derived follows: \\[ \\begin{align} \\theta_{\\text{}}^{\\text{}} &= \\frac{\\text{number new sequencable molecules}}{\\text{total number sequencable molecules}} \\\\ \\theta_{\\text{}}^{\\text{}}                               &= \\frac{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) }{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) + \\text{n}_{\\text{}}*(1-\\theta_{\\text{}})} \\\\ \\theta_{\\text{}}^{\\text{}}                              &= \\frac{\\theta_{\\text{}}*(1 - \\text{pdo}) }{\\theta_{\\text{}}*(1 - \\text{pdo}) + (1-\\theta_{\\text{}})} \\\\ \\theta_{\\text{}}^{\\text{}}*[1 - \\theta_{\\text{}}*\\text{pdo}] &= \\theta_{\\text{}}*(1 - \\text{pdo}) \\\\ \\theta_{\\text{}}^{\\text{}} &= \\theta_{\\text{}}*(1 - \\text{pdo}) + \\theta_{\\text{}}*\\theta_{\\text{}}^{\\text{}}*\\text{pdo} \\\\ \\frac{\\theta_{\\text{}}^{\\text{}}}{(1 - \\text{pdo}) + \\theta_{\\text{}}^{\\text{}}*\\text{pdo}} &= \\theta_{\\text{}} \\end{align} \\] can use relationship substite \\(\\theta_{\\text{}}\\) function \\(\\theta_{\\text{}}^{\\text{}}\\) \\(\\text{pdo}\\) dropout quantification equation: \\[ \\begin{align} \\text{Dropout} &= [1 - \\theta_{\\text{}}*\\text{pdo}]*\\text{scale}\\\\ \\text{Dropout} &= \\text{scale} - \\frac{\\text{scale}*\\text{pdo}*\\theta_{\\text{}}^{\\text{}}}{(1 - \\text{pdo}) + \\theta_{\\text{}}^{\\text{}}*\\text{pdo}} \\end{align} \\] bakR’s CorrectDropout function fits predicted relationship ratio +s4U -s4U reads (\\(\\text{Dropout}\\)) uncorrected fraction new estimates (\\(\\theta_{\\text{}}^{\\text{}}\\)) infer \\(pdo\\). Corrected fraction new estimates can inferred relationship \\(\\theta_{\\text{}}^{\\text{}}\\), \\(\\text{pdo}\\), \\(\\theta_{\\text{}}\\). Finally, bakR redistributes read counts according estimated relative proportions feature dropout existed. key insight : \\[ \\begin{align} \\frac{\\text{E[number reads without dropout]}}{\\text{E[number reads dropout]}} &= \\text{Dropout}\\\\ &= \\frac{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) + \\text{n}_{\\text{}}*(1 - \\theta_{\\text{}}) }{\\text{n}_{\\text{}}}*\\frac{\\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}}{ \\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}*\\theta_{\\text{j}}*(1 - \\text{pdo}) + \\text{n}_{\\text{j}}*(1 - \\theta_{\\text{j}})  } \\\\ &= \\frac{\\theta_{\\text{}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{}}) }{1}*\\frac{\\text{N}}{\\text{N}*\\theta_{\\text{G}}*(1-\\text{pdo}) + \\text{N}*(1 - \\theta_{\\text{G}})}\\\\ &= \\frac{\\theta_{\\text{}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{}}) }{1}*\\frac{1}{\\theta_{\\text{G}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{G}}) } \\\\ \\\\ &= \\frac{\\text{fraction feature molecules remaining dropout}}{\\text{fraction total molecules remaining dropout}} \\\\ \\end{align} \\] Getting 2nd line third line involved bit algebraic trickery (multiplying 1) defining “global fraction new” (\\(\\theta_{\\text{G}}\\)), fraction sequenced molecules new (\\(\\text{N}\\) total number sequenced molecules none lost due dropout). \\(\\theta_{\\text{G}}\\) can calculated weighted average dropout biased fraction news feature, weighted uncorrected number reads feature , dropout correcting: \\[ \\begin{align} \\theta_{\\text{G}}^{\\text{}} &= \\frac{\\sum_{\\text{j=1}}^{\\text{NF}}\\theta_{\\text{j}}^{\\text{}}*\\text{nreads}_{\\text{j}} }{\\sum_{\\text{j=1}}^{\\text{NF}}\\text{nreads}_{\\text{j}}} \\\\ \\theta_{\\text{G}} &= \\frac{\\theta_{\\text{G}}^{\\text{}}}{(1 - \\text{pdo}) + \\theta_{\\text{G}}^{\\text{}}*\\text{pdo}} \\end{align} \\] Thus, dropout corrected read counts can obtained follows: \\[ \\begin{align} \\text{Corrected read count feature } &= \\text{nreads}_{\\text{}}*\\frac{\\theta_{\\text{}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{}})}{\\theta_{\\text{G}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{G}})} \\end{align} \\]","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"differences-between-bakr-and-grandrs-strategies","dir":"Articles","previous_headings":"","what":"Differences between bakR and grandR’s strategies","title":"Correcting for dropout","text":"Florian Erhard’s group first implement strategy dropout correction NR-seq analysis tool (R package grandR). strategy used grandR discussed . short, dropout rate (\\(\\text{pdo}\\)) assumed related Spearman correlation (\\(\\rho\\)) rank feature’s fraction new(referred new--total ratio, NTR) log dropout metric discussed (ratio +s4U -s4U read counts) follows: \\[ \\begin{align} \\text{pdo} &= \\frac{\\rho}{\\rho + 1} \\end{align} \\] note definition model derived sets artificial upper bound \\(\\text{pdo}\\) 0.5. estimated number sequencing reads new RNA multiplied factor (\\(\\text{f}\\)) defined follows: \\[ \\text{f} = \\frac{1}{1 - \\text{pdo}} \\] corrected fraction new estimated using adjusted new RNA read counts. bit algebra shows relationship inferred \\(\\text{pdo}\\) corrected fraction new identical derived model : \\[ \\begin{align} \\theta_{\\text{}} &= \\frac{\\text{f}*(\\text{number reads new RNA})}{\\text{f}*(\\text{number reads new RNA}) + (\\text{number reads old RNA})} \\\\ &= \\frac{\\text{f}*\\theta_{\\text{}}^{\\text{}}*\\text{nreads}_{\\text{}}}{\\text{f}*\\theta_{\\text{}}^{\\text{}}*\\text{nreads}_{\\text{}} + (1 - \\theta_{\\text{}}^{\\text{}})*\\text{nreads}_{\\text{}}} \\\\ &= \\frac{\\frac{\\theta_{\\text{}}^{\\text{}}}{(1 - \\text{pdo})}}{\\frac{\\theta_{\\text{}}^{\\text{}}}{(1 - \\text{pdo})} + (1 - \\theta_{\\text{}}^{\\text{}})} \\\\ &= \\frac{\\theta_{\\text{}}^{\\text{}}}{(1 - \\text{pdo}) + \\theta_{\\text{}}^{\\text{}}*\\text{pdo}} \\end{align} \\] Thus, grandR implicitly making assumptions similar laid model used bakR. Notable differences bakR grandR’s dropout correction approaches : bakR defines explicit model dropout derives strategy estimate dropout rate data. grandR defines ad hoc relationship fraction new vs. dropout correlation coefficient dropout rate. correcting read counts, grandR seems use different correction strategy derived model . details bit scant, appears reads added features proportion fraction new, higher fraction new features given extra reads account dropout-induced underrepresentation. bakR hand redistributes read counts, thus preserving total library size. bakR fits explicit parametric model derived assumptions made either explicitly implicitly grandR bakR. allows users assess quality model fit thus likelihood assumptions valid given dataset.","code":""},{"path":[]},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"a1-algebraic-aside","dir":"Articles","previous_headings":"Appendix","what":"A1: Algebraic aside","title":"Correcting for dropout","text":"One potentially non-obvious step derivations determining correct read counts. section, following set relationships: \\[ \\begin{align} \\frac{\\text{E[number reads without dropout]}}{\\text{E[number reads dropout]}} &= \\text{Dropout}\\\\ &= \\frac{\\text{n}_{\\text{}}*\\theta_{\\text{}}*(1 - \\text{pdo}) + \\text{n}_{\\text{}}*(1 - \\theta_{\\text{}}) }{\\text{n}_{\\text{}}}*\\frac{\\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}}{ \\sum_{\\text{j}=1}^{\\text{NF}}\\text{n}_{\\text{j}}*\\theta_{\\text{j}}*(1 - \\text{pdo}) + \\text{n}_{\\text{j}}*(1 - \\theta_{\\text{j}})  } \\\\ &= \\frac{\\theta_{\\text{}}*(1 - \\text{pdo}) + (1 - \\theta_{\\text{}}) }{1}*\\frac{\\text{N}}{\\text{N}*\\theta_{\\text{G}}*(1-\\text{pdo}) + \\text{N}*(1 - \\theta_{\\text{G}})} \\\\ &=\\text{...} \\end{align} \\] : \\[ \\begin{align} \\text{N} &= \\sum_{\\text{j=1}}^{\\text{NF}}{\\text{n}_{\\text{j}}} \\\\ \\theta_{\\text{G}} &= \\frac{\\sum_{\\text{j=1}}^{\\text{NF}}\\text{n}_{\\text{j}}*\\theta_{\\text{}}}{\\sum_{\\text{j=1}}^{\\text{NF}}\\text{n}_{\\text{j}}} \\end{align} \\] algebraic trick get line 2 line 3 multiply 1 (rather \\(\\text{N}\\)/\\(\\text{N}\\)): \\[ \\begin{align} \\sum_{\\text{j=1}}^{\\text{NF}}\\text{n}_{\\text{}}*\\theta_{\\text{j}} &= \\sum_{\\text{j=1}}^{\\text{NF}}{\\text{n}_{\\text{j}}}*\\frac{\\sum_{\\text{j=1}}^{\\text{NF}}\\text{n}_{\\text{}}*\\theta_{\\text{j}}}{\\sum_{\\text{j=1}}^{\\text{NF}}{\\text{n}_{\\text{j}}}} \\\\ &= \\text{N}*\\theta_{\\text{G}} \\end{align} \\]","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Dropout.html","id":"a2-u-content-dependence","dir":"Articles","previous_headings":"Appendix","what":"A2: U-content dependence","title":"Correcting for dropout","text":"Given hypotheses dropout arises, may expect extent dropout correlated U-content RNA feature. fact, seem case real datasets. bakR currently attempt account correlation reasons: U-content typically correlated estimated fraction new. Thus, U-content dropout biases often evenly represented throughout fraction new vs. dropout trend. means influence add scatter data perturbing mean trend. rigorous empirical relationship U-content dropout difficult derive first principles given existing data. ad hoc correction factor can added, far found minimal impact dropout rate estimation.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Getting-Started.html","id":"necessary-setup","dir":"Articles","previous_headings":"","what":"Necessary Setup","title":"Differential kinetic analysis with bakR","text":"course want load bakR package vignette; instructions can found link. Also, ’ll want set seed ensure results get reproduce presented vignette.","code":"library(bakR) set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/Getting-Started.html","id":"step-1-creating-a-bakrdata-object","dir":"Articles","previous_headings":"","what":"Step 1: Creating a bakRData Object","title":"Differential kinetic analysis with bakR","text":"1st step using bakR create bakRData object. bakRData object consists two components: cB data frame metadf data frame. cB stands counts binomial contains information mutations seen sequencing reads sample sequenced. metadf stands metadata data frame contains important information experimental details sample (.e., long metabolic label feed , samples reference samples, experimental samples). Lets get idea cB looks like taking peak example: One key aspect cB dataframe keep mind row corresponds set reads providing identical data. help make sense, understand information cB tracks, let’s go contents column: sample: name sample reads described row originated. Usually sort character vector defined. TC: Number U--C mutations (assuming using s4U metabolic label). Called TC technically data T--C mutations reverse-transcribed RNA nT: Number Ts (Us RNA) sequencing read(s) XF stands “exonic feature”, since cases considering reads map definitively exonic locations. Introns typically rapidly turned thus highly labeled species bias estimates mature transcript stability. n: Number reads identical data 4 columns. example, n = 3 2nd row means 3 reads sample WT_cntl (WT cells treated s4U) mapped XF ENSG00000100242 (SUN2), 0 T C mutations, 11 Ts. structure cB file closely reflects output pipeline analyzing nucleotide recoding RNA-seq data developed Simon lab (available Snakemake reimplementation ). Now let’s look corresponding metadf dataframe: transpose metadf displayed save space (columns depicted rows metadf, vice versa). Metadf significantly less information cB data frame, ’s crucial information. One extremely important feature metadf row names (column names depicted ). Examine row names compare sample names ’re , !! row metadf corresponds sample, order sample names appear row names metadf MUST correspond order appear cB sample column. (NOTE: bakR version 1.0.0 longer case; sample names cB just appear metadf order). Keeping mind row represents sample, content columns : tl: length metabolic labeling feed. can units (simulated data puts terms minutes), s4U fed sample, tl must 0 sample. technically necessary run bakR, always highly suggest including -s4U controls. want compare two experimental samples, can done output models, though require bit post-hoc work end. two data frames correctly constructed, can create bakRData object one line code.","code":"# Load small example cB data(\"cB_small\")  # Observe contents of cB head(cB_small) # Load metadf data frame; will be loaded as metadf in global environment data(\"metadf\")  # Print the transpose of metadf # Rows will be the columns and columns will be the rows print(t(metadf)) # metadf row names print(rownames(metadf)) #> [1] \"WT_ctl\" \"WT_2\"   \"WT_1\"   \"KO_ctl\" \"KO_2\"   \"KO_1\"   # cB sample names print(unique(cB_small$sample)) #> [1] \"WT_ctl\" \"WT_2\"   \"WT_1\"   \"KO_ctl\" \"KO_2\"   \"KO_1\" # Create bakRData object bakRData <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/articles/Getting-Started.html","id":"step-2-fitting-the-efficient-model","dir":"Articles","previous_headings":"","what":"Step 2: Fitting the Efficient Model","title":"Differential kinetic analysis with bakR","text":"bakR implements several blends fundamentally similar statistical models perform differential kinetic analysis. matter intentions though, must first fit data efficient model available. model (implemented fast_analysis() function, see ?fast_analysis details) estimates mutation rates finds maximum likelihood estimate (MLE) fraction sequencing reads new RNA (new meaning RNA synthesized start metabolic labeling) feature s4U fed sample. reason run model part output used every model can run bakR. later though; first, let’s create simulated dataset fit bakR’s model efficient implementation. Using simulated dataset allow us compare results ground truth validate accuracy. bakRFit() used wrapper two functions bakR: cBprocess() fast_analysis(). cBprocess() extract properly format information needed statistical models bakRData object fast_analysis() perform efficient analysis. take minute run. Messages printed along way keep updated progress analysis. One important messages regarding estimated pnews pold. pnews estimated mutation rates reads new RNAs (new meaning RNAs synthesized start s4U labeling) sample (muts = Exp_ID, reps = numerical replicate ID corresponds order replicates appear cB), pold global estimate background mutation rate used analyses. simulated mutation rates 0.05 new reads 0.001 old reads samples simulation, estimates pretty darn close. can also input mutation rate estimates elsewhere (say run full Stan model implemented bakR) bakRFit(): Since ’ve already run fast_analysis , can speed analysis passing Fit object first run rather bakRData object. allows bakR skip time consuming pre-processing steps. Just make sure set FastRerun TRUE. run problems default mutation rate strategy (e.g., mutation rate estimates don’t seem make sense) another slightly less efficient solution use MCMC implemented Stan estimate mutation rates. idea fit binomial mixture model small subset features sufficient sequencing depth model enough data work still running reasonable amount time: “Troubleshooting” vignette details certain mutation rate estimation strategies preferable. matter decide run fast model, might wonder well worked. mentioned earlier, one benefit using simulated data can easily answer question comparing simulated parameters (e.g., fraction new) model’s estimates:  Looks pretty good ! Note, key assumption common make analyzing NR-seq data population cells analyzing steady-state. means RNA levels constant label time, .e., cells actively responding perturbation metabolic labeling. case, fraction new (\\(\\theta\\)) degradation rate constant related follows: \\[ k_{\\text{deg}} = -\\frac{\\text{ln}(1 - \\theta)}{\\text{tl}} \\] run heavier, trustworthy models, just rerun bakRFit() Fit object, either StanFit HybridFit parameters set true. might rightfully ask makes models “trustworthy”? Didn’t just show logit(fn) estimates fast model pretty good? bother computationally expensive models?? answer lot magic happens level uncertainty quantification. models going agree pretty well estimates kinetic parameters, won’t necessarily agree uncertain estimates . fastest model takes lot shortcuts uses lot approximations make fast also make uncertainty quantification less rigorous. like say fast model used initial investigations data, rapid means satisfy desire dive whatever exciting biology might exploring. sense promising data want analyze, switch heavier models. give peace mind allow comfortably dig little deeper datasets prepare stunning presentations groundbreaking papers. Hybrid implementation (HybridFit = TRUE) usually go-, particularly challenging analyze datsets (e.g., low new read mutation rates) can benefit full MCMC implementation (StanFit = TRUE). Fit objects contain lists pertaining fits models. possible contents include: Fast_Fit: Result initial fitting bakRData object. learn contents, see ?fast_analysis() Data_lists: Processed data can passed statistical models Hybrid_Fit: Result running bakRFit() Fit object HybridFit = TRUE. learn contents, see ?TL_stan(). Stan_Fit: Result running bakRFit() Fit object StanFit = TRUE. general contents identical Hybrid_Fit, even though models different.","code":"# Simulate a nucleotide recoding dataset sim_data <- Simulate_bakRData(500)   # This will simulate 500 features, 2 experimental conditions   # and 3 replicates for each experimental condition   # See ?Simulate_bakRData for details regarding tunable parameters  # Extract simulated bakRData object bakRData <- sim_data$bakRData  # Extract simualted ground truths sim_truth <- sim_data$sim_list  # Run the efficient model Fit <- bakRFit(bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 6 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0502 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     1     3 0.0501 0.00100 #> 4     2     1 0.0501 0.00100 #> 5     2     2 0.0500 0.00100 #> 6     2     3 0.0503 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Run efficient model with known mutation rates # Pass the Fit object rather than the bakRData object and set FastRerun to TRUE Fit <- bakRFit(Fit,                      FastRerun = TRUE,                      pnew = rep(0.05, times = 6),                       pold = 0.001) #> Using provided pnew estimates #> Using provided pold estimate #> Estimated pnews and polds for each sample are: #>   mut reps pnew  pold #> 1   1    1 0.05 0.001 #> 2   1    2 0.05 0.001 #> 3   1    3 0.05 0.001 #> 4   2    1 0.05 0.001 #> 5   2    2 0.05 0.001 #> 6   2    3 0.05 0.001 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Set StanRateEst to TRUE to use Stan to estimate rates # low_reads and high_reads defines the read count cutoffs used to select features   # default = between 1000 and 5000 reads # RateEst_size determines the number of features to use (default = 30) Fit <- bakRFit(Fit,                      FastRerun = TRUE,                      StanRateEst = TRUE) # Features that made it past filtering XFs <- unique(Fit$Fast_Fit$Effects_df$XF)  # Simulated logit(fraction news) from features making it past filtering true_fn <- sim_truth$Fn_rep_sim$Logit_fn[sim_truth$Fn_rep_sim$Feature_ID %in% XFs]  # Estimated logit(fraction news) est_fn <- Fit$Fast_Fit$Fn_Estimates$logit_fn  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\") abline(0, 1, col = \"red\") # Load options that will make running models more efficient rstan::rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores())   # Run Hybrid model (This might take several minutes to run) Fit <- bakRFit(Fit, HybridFit = TRUE)  # Run Full model (This might take ~10-30 minutes to run) Fit <- bakRFit(Fit, StanFit = TRUE)"},{"path":"https://simonlabcode.github.io/bakR/articles/Getting-Started.html","id":"step-3-visualizing-the-results","dir":"Articles","previous_headings":"","what":"Step 3: Visualizing the Results","title":"Differential kinetic analysis with bakR","text":"bakR provides variety easy use functions beginning investigate data. visualizations particularly aimed revealing trends RNA stabilization destabilization. Analyzing changes RNA synthesis rate require pairing output bakR differential expression analysis tool, like DESeq2, edgeR, limma. “Differential synthesis analysis” vignette. One visualization powered bakR L2FC(kdeg) MA plot. point plots represent feature-condition combination. x-axis average number sequencing reads mapping feature, averaging replicates experimental reference condition. y-axis difference stability reference experimental condition, quantified log2-fold change (L2FC) degradation rate constant (kdeg). Positive values L2FC(kdeg) represent features less stable (higher kdeg) experimental condition relative reference condition. Negative values thus represent features stable experimental condition. plotMA function bakR allows make plot two inputs, bakRFit object model fit use (MLE, Hybrid, MCMC):  one experimental condition, can choose plot comparisons just subset interested. See Exps Exp_shape parameters ?plotMA help file details. Another common plot make bakR fits volcano plot. x-axis volcano plot y-axis MA plot (L2FC kinetic parameter), y-axis measure statistical significance (e.g., FDR adjusted p-value), usually -log10 scale. plotVolcano function help one , containing many parameters plotMA:  volcano MA plots great visualizing results bakR’s model fits, another important class plots detect anomalies. Sometimes, high-throughput sequencing datasets plagued batch effects, biases effect one samples. can lead inflated false discovery rates /reduced power thus important look . One simple way see large-scale biases present samples perform principle component analysis (PCA), dimension reduction algorithm project high-dimensional sequencing data onto dimensions. bakR specifically implements novel fraction new PCA, high-dimensional object compressed matrix fraction new estimates, column matrix corresponding sample row feature (e.g., transcript). replicates don’t cluster together 2D PCA plot produced bakR’s FnPCA, indicate presence batch effects:  case, replicates separate fairly well, promising difference red point lower left upper left significant enough cause concern.","code":"## MA Plot with Fast Fit bakR::plotMA(Fit, Model = \"MLE\") ## Volcano Plot with Fast Fit; significance assessed relative to an FDR control of 0.05 plotVolcano(Fit$Fast_Fit) ## 2D PCA plot with replicate fraction news   # The equivalent function prior to version 1.0.0 is FnPCA, now deprecated in    # favor of FnPCA2. FnPCA2(Fit, Model = \"MLE\")"},{"path":"https://simonlabcode.github.io/bakR/articles/Getting-Started.html","id":"step-4-where-to-go-from-here","dir":"Articles","previous_headings":"","what":"Step 4: Where to go from here","title":"Differential kinetic analysis with bakR","text":"hope vignette provided useful introduction using bakR nucleotide recoding RNA-seq datasets. Inevitably, questions answered Getting-Started vignette. remaining quandaries may challenging problems specific exciting research, unavoidable roadblocks science eventually conquer, little help documentation dream writing. said, can still imagine many important implementation questions addressed . Therefore, number additional vignettes exist discuss: Performing differential synthesis rate analyses bakR. Providing fraction new estimates input rather cB data frame (version 1.0.0). Correcting disproportionate loss metabolic label containing RNA/reads. Dissecting mechanisms gene expression regulation relaxing steady-state assumption. General advice troubleshooting analyses NR-seq datasets. addition, ’s possible run warnings r_hats n_eff running heavier Stan models. case, suggest checking great documentation written Stan team. short though, warnings Stan sign model converge. possible cause anomalies data. challenges come across lead warnings include: analyze mix technical biological replicates? Technical replicates much less replicate replicate variability biological replicates, confuse crash models. s4U label time abnormally long short? getting warnings running MLE implementation logit(fn)s lower upper bounds, case. means extreme mutational data (e.g., 0 mutations sequencing read) make analysis MCMC implementation difficult. Try filtering extreme transcripts rerunning bakR case. extreme batch effects. Check FnPCA2 plot; extreme differences replicates also break models. analyzing short sequencing reads? bakR yet fully validated short sequencing read nucleotide recoding RNA-seq data (e.g., read lengths less 50 nucleotides), exercise caution analyzing kind data bakR. Mutation rate estimation can also pose challenge bakR case. get around problems, try using mutation rate estimates MCMC implementation (found accurate even model convergence issue) MLE implementation. Sometimes, small warnings Stan (like max treedepth warnings ) cause concern. know whether serious problem though? suggest comparing output Hybrid/MCMC implementation MLE implementation. particular, check correlation L2FC(kdeg) estimates. correlation good, probably nothing worry . estimates handful transcripts differ wildly implementations though, strong evidence convergence issues serious one anomalies mentioned afflicting data.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Steady-state quasi-independent mechanistic investigations","text":"packages going install load order everything presented vignette:","code":"library(bakR)  # Packages that are NOT automatically installed when bakR is installed library(DESeq2) #> Loading required package: S4Vectors #> Loading required package: stats4 #> Loading required package: BiocGenerics #>  #> Attaching package: 'BiocGenerics' #> The following object is masked from 'package:bakR': #>  #>     plotMA #> The following objects are masked from 'package:stats': #>  #>     IQR, mad, sd, var, xtabs #> The following objects are masked from 'package:base': #>  #>     anyDuplicated, aperm, append, as.data.frame, basename, cbind, #>     colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, #>     get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, #>     match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, #>     Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort, #>     table, tapply, union, unique, unsplit, which.max, which.min #>  #> Attaching package: 'S4Vectors' #> The following object is masked from 'package:utils': #>  #>     findMatches #> The following objects are masked from 'package:base': #>  #>     expand.grid, I, unname #> Loading required package: IRanges #> Loading required package: GenomicRanges #> Loading required package: GenomeInfoDb #> Loading required package: SummarizedExperiment #> Loading required package: MatrixGenerics #> Loading required package: matrixStats #>  #> Attaching package: 'MatrixGenerics' #> The following objects are masked from 'package:matrixStats': #>  #>     colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, #>     colCounts, colCummaxs, colCummins, colCumprods, colCumsums, #>     colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, #>     colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, #>     colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, #>     colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, #>     colWeightedMeans, colWeightedMedians, colWeightedSds, #>     colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, #>     rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, #>     rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, #>     rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, #>     rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, #>     rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, #>     rowWeightedMads, rowWeightedMeans, rowWeightedMedians, #>     rowWeightedSds, rowWeightedVars #> Loading required package: Biobase #> Welcome to Bioconductor #>  #>     Vignettes contain introductory material; view with #>     'browseVignettes()'. To cite Bioconductor, see #>     'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. #>  #> Attaching package: 'Biobase' #> The following object is masked from 'package:MatrixGenerics': #>  #>     rowMedians #> The following objects are masked from 'package:matrixStats': #>  #>     anyMissing, rowMedians library(pheatmap)  # Packages which are installed when bakR is installed library(dplyr)  #>  #> Attaching package: 'dplyr' #> The following object is masked from 'package:Biobase': #>  #>     combine #> The following object is masked from 'package:matrixStats': #>  #>     count #> The following objects are masked from 'package:GenomicRanges': #>  #>     intersect, setdiff, union #> The following object is masked from 'package:GenomeInfoDb': #>  #>     intersect #> The following objects are masked from 'package:IRanges': #>  #>     collapse, desc, intersect, setdiff, slice, union #> The following objects are masked from 'package:S4Vectors': #>  #>     first, intersect, rename, setdiff, setequal, union #> The following objects are masked from 'package:BiocGenerics': #>  #>     combine, intersect, setdiff, union #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(magrittr)  #>  #> Attaching package: 'magrittr' #> The following object is masked from 'package:GenomicRanges': #>  #>     subtract library(ggplot2)  library(stats)  # Set the seed for reproducibility set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"key-takeaways-from-this-vignette","dir":"Articles","previous_headings":"","what":"Key takeaways from this vignette","title":"Steady-state quasi-independent mechanistic investigations","text":"discussion DissectMechanism presented bit involved. Thus, like start brief summary hope understand use DissectMechanism caveats analysis strategy: DissectMechanism’s analysis strategy “quasi-steady-state-independent”. specifically, assumes least one population cells comparing steady-state. population can far away steady-state, things get much complicated populations compared dynamically regulating RNA levels experiment. bakR_cutoff closer 1 (’s maximum value; setting higher number identical setting 1) yield post-transcriptional false positives. Lower bakR_cutoff values yield transcriptional false positives. case discussed end vignette great detail. looking high confidence instances post-transcriptional regulation? bakR_cutoff 0.05 lower good choice avoid post-transcriptional false positives. looking high confidence instances transcriptional regulation? Increasing bakR_cutoff 0.5 higher probably good idea. equally happy flag either type regulation? bakR_cutoff’s default value 0.3 work well. DissectMechanism part original bakR publication. developed analysis strategy collaboration previous undergraduate Simon lab (Matthew Saenz) back, recently implemented modified version original idea bakR. Thus, questions reading vignette, best course action post Issues page bakR Github email directly (isaac.vock@yale.edu) since public material topic. analyzing non-steady-state data, DissectMechanism work best label times (length time cells metabolically labeled ) datasets compared. DissectMechanism can normalize label time differences, strategy 100% rigorous steady-state case.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"mechanistic-dissections-of-gene-expression-regulation-with-bakr-deseq2","dir":"Articles","previous_headings":"","what":"Mechanistic dissections of gene expression regulation with bakR + DESeq2","title":"Steady-state quasi-independent mechanistic investigations","text":"goal DissectMechanism function discussed vignette identify major kinetic mechanism differential expression observed. analysis strategy follows: Compare NR-seq bakR Perform differential expression analysis Use DissectMechanism() function bakR combine results come mechanistic conclusion. Simple enough! usual, let’s start simulating data. simulate two separate datasets, one exclusively transcriptional regulation one exclusively post-transcriptional regulation. allow us see DissectMechanism performs two different regimes: Next, can perform differential expression analysis just described differential synthesis analysis vignette: ’re almost ready use bakR’s special DissectMechanism() function. DissectMechanism() two required inputs: bakR fit object data frame containing differential expression analysis results particular, differential expression data frame must contain five columns named follows: XF: Name feature (gene, exon, etc.) read comes . L2FC_RNA: L2FC(RNA) estimated differential expression analysis. DE_score: Differential expression z-score. DE_se: L2FC(RNA) standard error. DE_pval: P-value differential expression analysis. DE_padj: Multiple test adjusted p-value differential expression analysis. Conveniently, DESeq2 results object information need! can make differential expression data frame like : ready perform mechanistic dissection now! See ?DissectMechanism information additional parameters can specified. importantly, bakRModel parameter, tells DissectMechanism fit use bakRFit model, multiple exist. default setting just use MLE fit, always . output DissectMechanism two data frames: Heatmap_df: data frame meant facilitate visualization results heatmap. Mechanism_df: data frame statistical assessments likely mechanisms observed differential expression. Heatmap_df three following columns: bakR_score: logit(fraction new) change z-score bakR DE_score: L2FC(RNA) z-score DESeq2 Mech_score: mechanism z-score quantifies extent significant changes gene expression synthesis degradation driven. Synthesis driven = positive numbers; degradation driven = negative numbers. can quickly make heatmap using lovely pheatmap package:   row data frame output DissectMechanism corresponds feature differentially expressed experimental condition. Differential expression defined DE_padj less DE_cutoff parameter DissectMechanism. features highest confidence observed regulation, thus ones likely interested assessing mechanism regulation. Mechanism_df provides information present Heatmap_df, , features, even “significantly differentially expressed”. columns Mechanism_df follows: XF: Feature name bakR_score: bakR z-score kdeg difference L2FC_kdeg: L2FC(kdeg) estimated bakR bakR_pval: P-value L2FC(kdeg) estimated bakR bakR_padj: bakR’s multiple test adjusted p value L2FC_RNA: L2FC([RNA]) estimated differential expression analysis (DEA) tool DE_score: L2FC([RNA]) z-score DEA tool DE_pval: P-value differential expression DE_padj: Multiple test adjusted p-value differential expression mech_stat: Mechansism assignment test statistic mech_pval: P-value mechanism assignment mech_padj: Multiple test adjusted p-value mechanism assignment meta_pval: P-value either bakR DEA z-score non-null (.e., bakR + DEA meta analysis p-value) meta_padj: Multiple test adjusted meta analysis p-value L2FC_ksyn: L2FC(ksyn) estimated discussed differential synthesis analysis vignette. ksyn_score: L2FC(ksyn) z-score estimated discusssed differential synthesis analysis vignette. ksyn_pval: L2FC(ksyn) p-value estimated discussed differential synthesis analysis vignette. ksyn_padj: Multiple test adjusted L2FC(ksyn) p-value. f_deg: Fraction L2FC(RNA) attributable L2FC(kdeg). Equals -L2FC(kdeg)/L2FC(RNA) (ceiling 1 floor 0), old steady-state dependent metric lab used. Values greater 0.5 represent degradation driven regulation; values less 0.5 represent synthesis driven regulation. first nine columns things provided DissectMechanism. next five columns important output DissectMechanism’s statistical analysis. analysis really consists two separate analyses: discussed , positive values mech_stat represent transcriptional (.e., synthesis-driven) regulation. Negative values represent post-transcriptional (.e., stability-driven) regulation. , Fisher’s method used combine DEA bakR p-values assess probability obtaining duo p-values like differential expression differential fraction new signal null. next 4 columns output differential synthesis analysis conducted described vignette topic. details, check vignette. Finally, last column metric lab used past assess mechanisms observed regulation. valid population cells steady-state, relies relationship arises assumption: L2FC(RNA) = L2FC(ksyn) - L2FC(kdeg). One thing like look combination estimated L2FC(RNA) L2FC(kdeg) give rise mechanism statistic. Let’s look dataset exclusively transcriptional regulation:  next dataset exclusively post-transcriptional regulation  take closer look heatmap scatter plot, couple things might stick : case differential expression driven transcriptional regulation, false positives. DissectMechanism correctly classified instances differential expression transcriptionally driven. case differential expression driven RNA stability regulation, patch false positives (features identified transcriptionally regulated). Still, DissectMechanism decent job, though say challenges analysis next section. Higher L2FC(RNA) L2FC(kdeg) yields higher mechanism scores, possible high, positive mechanism score absence large L2FC(kdeg). scoring function discussed detail next section, check interested.","code":"### Only differential synthesis  # Simulate a nucleotide recoding dataset sim_data <- Simulate_relative_bakRData(1000, 1000000,                          num_ks_DE = c(0, 300),                          num_kd_DE = c(0, 0))   # This will simulate 1000 features, 1 million reads, 2 experimental conditions   # and 3 replicates for each experimental condition. 300 features will be differentially   # transcribed, and there will be no differential stability   # See ?Simulate_bakRData for details regarding tunable parameters  # Extract simulated bakRData object bakRData <- sim_data$bakRData  ## Run the efficient model Fit_s <- bakRFit(bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 6 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0499 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     1     3 0.0499 0.00100 #> 4     2     1 0.0500 0.00100 #> 5     2     2 0.0500 0.00100 #> 6     2     3 0.0500 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.   ### Only differential stability  # Simulate a nucleotide recoding dataset sim_data <- Simulate_relative_bakRData(1000, 1000000,                          num_ks_DE = c(0, 0),                          num_kd_DE = c(0, 300))   # This will simulate 1000 features, 1 million reads, 2 experimental conditions   # and 3 replicates for each experimental condition. 300 features will be differentially   # transcribed, and there will be no differential stability   # See ?Simulate_bakRData for details regarding tunable parameters  # Extract simulated bakRData object bakRData <- sim_data$bakRData  ## Run the efficient model Fit_d <- bakRFit(bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 6 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0500 0.000999 #> 2     1     2 0.0500 0.000999 #> 3     1     3 0.0499 0.000999 #> 4     2     1 0.0500 0.000999 #> 5     2     2 0.0502 0.000999 #> 6     2     3 0.0501 0.000999 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. ### Only differential synthesis dataset  # Get the count matrix from bakR Counts <- Fit_s$Data_lists$Count_Matrix  # Experimental conditions for each sample # There are 6 s4U treated samples (3 replicates of each condition) # In addition, there are 2 -s4U control samples (1 for each condition)  ## s4U conditions # 1st three samples are reference (ref) samples # Next three samples are experimental (exp) samples conditions_s4U <- as.factor(rep(c(\"ref\", \"exp\"), each = 3))  ## -s4U control conditions # 1st sample is reference, next is experimental conditions_ctl <- as.factor(c(\"ref\", \"exp\"))  # Combined s4U and -s4U control conditions conditions <- c(conditions_s4U, conditions_ctl)  # Make the colData input for DESeq2 colData <- data.frame(conditions = conditions) rownames(colData) <- colnames(Counts)  # Make DESeq2 data object dds_s <- DESeqDataSetFromMatrix(countData = Counts,                               colData = colData,                               design = ~conditions) #> converting counts to integer mode  # Fit DESeq2 model ddso_s <- DESeq(dds_s) #> estimating size factors #> estimating dispersions #> gene-wise dispersion estimates #> mean-dispersion relationship #> final dispersion estimates #> fitting model and testing  # Extract results of experimental vs. reference comparison reso_s <- results(ddso_s, contrast = c(\"conditions\", \"exp\", \"ref\"))   ### Only differential stability dataset  # Get the other count matrix from bakR Counts <- Fit_d$Data_lists$Count_Matrix  # Make DESeq2 data object dds_d <- DESeqDataSetFromMatrix(countData = Counts,                               colData = colData,                               design = ~conditions) #> converting counts to integer mode  # Fit DESeq2 model ddso_d <- DESeq(dds_d) #> estimating size factors #> estimating dispersions #> gene-wise dispersion estimates #> mean-dispersion relationship #> final dispersion estimates #> fitting model and testing  # Extract results of experimental vs. reference comparison reso_d <- results(ddso_d, contrast = c(\"conditions\", \"exp\", \"ref\")) ### Only differential synthesis:   # Convert to data frame reso_s <- as.data.frame(reso_s)  # Make data frame DE_df_s <- data.frame(XF = row.names(reso_s),                     L2FC_RNA = reso_s$log2FoldChange,                     DE_score = reso_s$stat,                     DE_se = reso_s$lfcSE,                     DE_pval = reso_s$pval,                     DE_padj = reso_s$padj)   ### Only differential degradation:  # Convert to data frame reso_d <- as.data.frame(reso_d)  # Make data frame DE_df_d <- data.frame(XF = row.names(reso_d),                     L2FC_RNA = reso_d$log2FoldChange,                     DE_score = reso_d$stat,                     DE_se = reso_d$lfcSE,                     DE_pval = reso_d$pval,                     DE_padj = reso_d$padj) # Decreasing sims parameter to speed up; wouldn't normally suggest this if you # want higher precision mechanism p-values, discussed later Mechs_s <- DissectMechanism(Fit_s, DE_df_s,                           sims = 1000000) #> Combining bakR and DE analyses #> Calculating mechanism p-value. This could take several minutes... #> Assessing differential synthesis #> Constructing Heatmap_df  Mechs_d <- DissectMechanism(Fit_d, DE_df_d,                           sims = 1000000) #> Combining bakR and DE analyses #> Calculating mechanism p-value. This could take several minutes... #> Assessing differential synthesis #> Constructing Heatmap_df # Nice red to blue color gradient   # Feel free to use any coloring your heart desires col <- c(\"#053061\", \"#2166AC\", \"#4393C3\", \"#92C5DE\",           \"#D1E5F0\", \"#F7F7F7\", \"#FDDBC7\", \"#F4A582\",           \"#D6604D\", \"#B2182B\", \"#67001F\")  # Heatmap for differential synthesis only dataset pheatmap(Mechs_s$Heatmap_df, cluster_cols = FALSE, show_rownames = FALSE, color = col) # Heatmap for differential degradation only dataset pheatmap(Mechs_d$Heatmap_df, cluster_cols = FALSE, show_rownames = FALSE, color = col) # Scatter plot of L2FC(kdeg) vs. L2FC(RNA) colored by mechanism test stat   # Gotta transform the mech_stat because it spans many orders of magnitude ggplot(Mechs_s$Mechanism_df, aes(x = L2FC_kdeg, y = L2FC_RNA, color = log10(abs(mech_stat) + 1)*sign(mech_stat))) +   geom_point() +    theme_classic() +    scale_color_viridis_c() +    xlab(\"L2FC(kdeg) from bakR\") +    ylab(\"L2FC(RNA) from DESeq2\") +   labs(color = \"Mechanism\") # Scatter plot of L2FC(kdeg) vs. L2FC(RNA) colored by mechanism test stat   # Gotta transform the mech_stat because it spans many orders of magnitude ggplot(Mechs_d$Mechanism_df, aes(x = L2FC_kdeg, y = L2FC_RNA, color = log10(abs(mech_stat) + 1)*sign(mech_stat))) +   geom_point() +    theme_classic() +    scale_color_viridis_c() +    xlab(\"L2FC(kdeg) from bakR\") +    ylab(\"L2FC(RNA) from DESeq2\") +   labs(color = \"Mechanism\")"},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"going-beyond-the-steady-state-assumption","dir":"Articles","previous_headings":"","what":"Going beyond the steady-state assumption","title":"Steady-state quasi-independent mechanistic investigations","text":"may noticed assumption continually crops analyses presented bakR vignettes: steady-state. Getting-Started vignette, necessary part relating fraction new biologically relevant \\(kdeg\\). differential synthesis analysis vignette key part assessing synthesis kinetics. therefore underlies differential kinetic analysis discussed far. happens bad assumption? “Dogs cats living together! Mass hysteria!”? Well Dr. Venkman, certainly complicates things, DissectMechanism best curtail issues. section, discuss many nitty-gritty details DissectMechanism working. ’s analysis strategy heavily inspired task assessing kinetic mechanisms observed differential expression steady-state-independent manner. Accomplishing means generalizing differences fraction new NR-seq experiment can relate differences degradation synthesis away steady-state.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"violating-the-steady-state-assumption","dir":"Articles","previous_headings":"Going beyond the steady-state assumption","what":"Violating the steady-state assumption","title":"Steady-state quasi-independent mechanistic investigations","text":"talk steady-state assumption questionable, ’s worth briefly mentioning steady-state assumption worth throwing . Assuming steady-state RNA dynamics means assuming rate RNA synthesized rate degraded. “Wait, mean assuming \\(ksyn = kdeg\\)?” . degradation rate constant \\(kdeg\\) rate degradation. rate degradation (.e., number RNA molecules degraded per unit time) depends \\(kdeg\\) amount RNA present. steady-state actually means \\(ksyn = kdeg*[RNA]\\). context NR-seq experiments, assuming steady-state means assuming relationship holds throughout entire metabolic label feed time. Therefore, another way phrase assumption say assuming population cells aren’t actively responding stimulus regulating \\(ksyn\\) /\\(kdeg\\). RNA levels remain constant experiment. ’s fun question: cells ever steady-state? Yes . individual cell almost never steady-state. Gene expression constantly regulated cell progresses cell cycle performs biochemical functions necessary stay alive. , bakR designed analyze bulk nucleotide recoding RNA-seq data. means data comes population cells, single cell. Thus, say assuming steady-state, really mean assuming population average steady-state. population cells asynchronous (aren’t going exact cell cycle stages time) haven’t perturbed recently (e.g., treated drug), probably pretty solid assumption. Lots cool experiments done cells far steady-state though. using nucleotide recoding RNA-seq, increasingly popular perform rapid degradation protein interest, treatment specific drug, acute perturbation leading metabolic labeling. Therefore, need way analyze data without helpful steady-state assumption. challenging though, can’t assume steady-state, relate measure (fraction new) RNA metabolic kinetics care ? answer: keep non-parametric.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"analyzing-nr-seq-data-far-from-steady-state","dir":"Articles","previous_headings":"Going beyond the steady-state assumption","what":"Analyzing NR-seq data far from steady-state","title":"Steady-state quasi-independent mechanistic investigations","text":"using term non-parametric suggest getting away using explicit mathematical functions model RNA metabolism. Rather, can think generally effects changes RNA synthesis degradation kinetics can fraction new NR-seq experiment. Let’s say compare unperturbed, steady-state population cells cells treated drug interest. fraction new particular transcript higher drug treated cells untreated cells, come ? Well, generally speaking, two possibilities: RNA may destabilized drug treatment. explanation give change everything steady-state. synthesis rate RNA may ramped following drug treatment. intuitive explanation surprisingly possible away steady-state. steady-state, changes synthesis kinetics affect amount new old RNA equally, leading change fraction new. key realization: two possibilities different impacts LEVELS RNA. synthesis increasing upon drug treatment, amount transcript also increase. transcript destabilized though, less around end experiment. Therefore, combining differential expression differential fraction new analyses reveals kinetic differences. generally, diagram covers range possible kinetic mechanisms conclusions (\\(\\theta\\) fraction new): Diagram NR-seq NSS analysis strategy.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"the-statistics-of-dissectmechanism","dir":"Articles","previous_headings":"Going beyond the steady-state assumption","what":"The statistics of DissectMechanism","title":"Steady-state quasi-independent mechanistic investigations","text":"DissectMechanism attempts formalize analysis discussed last section. combines differential fraction new test statistic differential expression test statistic. differential fraction new test statistic just L2FC(kdeg) z-score output bakR. Isn’t invalidated violations steady-state assumption? Yes . true bakR’s estimated L2FC(kdeg) may longer truly represent change degradation rate constant, still represent accurate assessment change fraction new. kdeg estimated : \\[ k_{\\text{deg}} = -\\text{ln}(1 - fn)/\\text{tl} \\] tl label time. transformation right expression may longer represent degradation rate constant away steady-state, simply monotonic transformation fraction new. Thus, differences bakR’s estimated “kdeg” can still interpreted differences fraction new, assuming label times conditions compared . label times differ, also represents naive (though somewhat inaccurate non-steady-state case) normalization differences. mechanism test statistic used DissectMechanism quite simple. ’s just: \\[ \\text{mech_stat} = [\\text{L2FC(kdeg) z-score}]*[\\text{L2FC(RNA) z-score}] \\] reasonable test-statistic choice best demonstrated via visualization function:  plot, dark blue represents high confidence post-transcriptional regulation bright yellow represents high confidence transcriptional regulation. four somewhat asymetric quadrants plot: Top-left: Fraction new went expression levels went . stabilization. Top-right: Fraction new went expression levels went . transcriptional upregulation. Bottom-left: Fraction new went expression went . Transcriptional downregulation must play Bottom-right: Fraction new went expression went . RNA destabilized. particular function admittedly bit arbitrary, lot trends want function attempting formalize strategy discussed last section: quadrants described match mechanistic conclusions schematic shown last section. Low confidence differential fraction new differential expression can balanced high confidence . Moderate confidence good high confidence one lower confidence another. keeping possibility steady-state dynamics, differential expression can transcriptionally driven without strong fraction new signal. next section discuss vertical dividing lines determine just strong fraction new signal qualify “real” signal.","code":"## Grid to plot on  # Grid size in each axis n <- 300  # DE z-scores DE_score <- rep(seq(from = -10, to = 10, length.out = n), times = n)  # bakR z-scores bakR_score <- rep(seq(from = -10, to = 10, length.out = n), each = n)  grid_df <- tibble(DE = DE_score,                   bakR = bakR_score)   # Mechanism score grid_df <- grid_df %>%   mutate(Mech = ifelse(DE > 0,                         (bakR + 2)*DE,                        (bakR - 2)*DE))  # Calculate p-value grid_df <- grid_df %>%   mutate(Mech_pval = stats::df(abs(Mech), df1 = 2, df2 = 2, ncp = 2))  # Visualize test statistic ggplot(grid_df, aes(x = bakR, y = DE, z = 0.03*Mech)) +    geom_contour_filled() +    theme_classic() +    xlab(\"bakR score\") +    ylab(\"DE score\")"},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"the-assymetry-of-the-mechanism-score","dir":"Articles","previous_headings":"Going beyond the steady-state assumption","what":"The assymetry of the mechanism score","title":"Steady-state quasi-independent mechanistic investigations","text":"briefly alluded last section asymmetry mechanism score function. x-axis (0 differential expression) represents one dividing line, two separate vertical dividing lines? reason transcriptional regulation can yield fraction new signal. Thus, low confidence changes fraction new interpreted change fraction new. change fraction new accompanied differential expression, likely transcriptional regulation. locations vertical lines set bakR_cutoff parameter DissectMechanism. bakR_cutoff represents bakR_padj cutoff calling change fraction new “significant”. DissectMechanism determines z-score necessary yield padj (since multiple-test adjustment makes relationship padj z-score bit difficult predict priori) uses vertical dividing lines. reliance statistical confidence important shortcoming DissectMechanism’s analysis strategy. low confidence L2FC(kdeg) result large changes fraction new, also result low statistical power. words, may strong post-transcriptional regulation lurking region vertical dividing lines, coverage number replicates may low assess confidently. consequence bakR_cutoff tunes kind false positives likely crop : bakR_cutoff small, large fraction new z-scores going called significant. low confidence fraction new changes accompanied differential expression called transcriptional regulation. Thus, small bakR_cutoff’s yield transcriptional false positives. end spectrum, bakR_cutoff close 1 cause small change fraction new interpreted real change. Thus, direction fraction new differences opposite direction differential expression, DissectMechanism call post-transcriptional regulation, matter inconsequential fraction new shift. Thus, large bakR_cutoff’s yield post-transcriptional false positives. conclusion: wary. discussed summary top vignette, bakR_cutoff chosen way limit false positives likely lead astray.","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/NSS.html","id":"the-mechanism-p-value","dir":"Articles","previous_headings":"Going beyond the steady-state assumption","what":"The mechanism p-value","title":"Steady-state quasi-independent mechanistic investigations","text":"last wrinkle DissectMechanism calculation mechanism score’s p-value. Multiple test adjusted p-values nice give clear sense confident can given set mechanistic assignments accurate. Without , can difficult interpret mechanism scores. turns though nature mechanism score null model makes difficult calculate p-values great precision. Work bit mathematical statistics ’ll find null hypothesis distribution esoteric “doubly non-central scaled F-distribution”. aptly named sadist R package implements functions working little known distributions, even accomodates unscaled version distribution. one R package exists calculate integrals doubly non-central scaled F-distribution, precision estimates good able shakily code . Therefore, went forward home brew Monte Carlo approach p-value calculation. short, simulate null model bunch times (number set sims parameter DissectMechanism), calculate p-value fraction time simulated mechanism score larger magnitude given mechanism score. means precision p-value set sims parameter. default, set 10 million, means minimum meaningful p-value can estimate 1/10,000,000, 1e-7. vignette, decreased order base-10 magnitude speed runtime, can take 10 seconds collect many draws null. can get precision increasing sims, ’s going cost heavily runtime. NOTE: 0 draws null extreme particular mechanism score, mechanism score assigned p-value 0.5/sims. , relative ordering mechanism scores perfectly preserved relative ordering p-values. Thus, attempting generate ordered lists high confidence mechanistic assignments, order mech_score, mech_pval!!","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"necessary-setup","dir":"Articles","previous_headings":"","what":"Necessary Setup","title":"Troubleshooting analyses of NR-seq data with bakR","text":"Load bakR! Version 1.0.0 later required run code vignette reproduce results presented. ggplot2 corrplot (latter automatically installed bakR) also used figures shown .","code":"library(bakR) library(ggplot2) library(corrplot) #> corrplot 0.92 loaded set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"the-qc_checks-function","dir":"Articles","previous_headings":"","what":"The QC_checks() function","title":"Troubleshooting analyses of NR-seq data with bakR","text":"Version 0.4.0 bakR introduced function takes input bakRFit object assesses number aspects model fit raw data: QC_checks assesses four aspects data bakR’s model fit: Raw mutation rates Inferred new old read mutation rates Average fraction new Fraction new estimate replicate correlation","code":"# Simulate a nucleotide recoding dataset sim_data <- Simulate_relative_bakRData(1000, depth = 1000000,                                        nreps = 2)   # This will simulate 1000 features, 1000000 reads, 2 experimental conditions,   # and 2 replicates for each experimental condition   # See ?Simulate_relative_bakRData for details regarding tunable parameters  # Run the efficient model Fit <- bakRFit(sim_data$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0499 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     2     1 0.0498 0.00100 #> 4     2     2 0.0498 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Quality control checks QC <- QC_checks(Fit) #> Mutation rates in new reads looks good! #> Background mutation rate looks good! #> Average fraction news for each sample are: #> # A tibble: 4 × 3 #> # Groups:   Exp_ID [2] #>   Exp_ID Replicate avg_fn #>    <int>     <dbl>  <dbl> #> 1      1         1  0.312 #> 2      1         2  0.315 #> 3      2         1  0.325 #> 4      2         2  0.321 #> The average fraction news in all samples are between 0.2 and 0.8,  #>               suggesting an appropriate label time! #> logit(fn) correlations for each pair of replicates are: #>   Exp_ID Rep_ID1 Rep_ID2 correlation #> 1      1       1       2   0.8961197 #> 2      2       1       2   0.9262164 #> logit(fn) correlations are high, suggesting good reproducibility! #> I suggest running the Hybrid implementation next. This can be done  #>               with bakRFit(Fit, HybridFit = TRUE), where Fit is your bakRFit object."},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"raw-mutation-rates","dir":"Articles","previous_headings":"The QC_checks() function","what":"Raw mutation rates","title":"Troubleshooting analyses of NR-seq data with bakR","text":"first thing QC_checks() assesses average mutation rate sequencing reads analyzed samples. High quality data characterized mutation rates higher +s4U samples -s4U samples. addition, first order approximation higher mutation rates +s4U samples lower mutation rates -s4U samples, better. One output QC_checks convenient plot raw mutation rates see look like data:  simulated data, can see +s4U raw mutation rates consistenly much higher -s4U mutation rates. barplot also provides quasi-arbitrary guide good +s4U -s4U mutation rates .","code":"# Barplots of raw mutation rates QC$raw_mutrates"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"inferred-mutation-rates","dir":"Articles","previous_headings":"The QC_checks() function","what":"Inferred mutation rates","title":"Troubleshooting analyses of NR-seq data with bakR","text":"second thing QC_checks() assesses mutation rate new old reads, inferred bakR. difference inferred raw mutation rates can cause confusion new NR-seq data. raw mutation rates average proportion Ts mutated sequencing reads given sample. means raw mutation rates average mutation rates new reads (.e., reads derived RNA synthesized metabolic labeling) old reads (.e., synthesized prior metabolic labeling). inferred mutation rates estimated mutation rates old new reads separately. Higher inferred mutation rates yield higher raw mutation rates, distinct quantities. particular, raw mutation rate depends new old read mutation rates, fraction sequencing reads new fraction old. Like raw mutation rates, higher new read mutation rates lower old read mutation rates better. QC_checks() outputs helpful visualization mutation rates:  , simulated data looks good!","code":"# Barplots of inferred mutation rates QC$conversion_rates"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"average-fraction-news","dir":"Articles","previous_headings":"The QC_checks() function","what":"Average fraction news","title":"Troubleshooting analyses of NR-seq data with bakR","text":"third thing QC_checks() assesses average estimated fraction new. ability accurately infer degradation kinetics particular RNA feature highly dependent relationship length metabolic labeling half-life feature. specifically, really nice work Dieterich lab shown degradation rate constant estimates accurate features half-lives closer metabolic labeling time. label time much longer (shorter) feature’s half-live, feature almost completely labeled (unlabeled). relationship fraction new degradation rate constant makes extreme fraction news (close 0 1), rate constant estimate sensitive exact fraction new estimate. means fraction news close 0 1 yield uncertain kinetic parameter estimates. QC_checks() output message average estimated fraction new +s4U sample. can also visualize distribution fraction new estimates follows:  Note, density plot showing fraction news logit scale. Logit function takes input numbers bounded 0 1 outputs unbounded number. logit(fraction new) 0 means fraction new 0.5. logit(fraction new) -2 (2) fraction new ~0.1 (~0.9) Similar log-transforming RNA-seq read count data, logit transforming fraction news can useful visualizing data ranges multiple orders magnitude.","code":"# Barplots of inferred mutation rates ggplot(Fit$Fast_Fit$Fn_Estimates, aes(x = logit_fn, color = as.factor(sample))) +    geom_density() +    theme_classic() +   scale_color_viridis_d() +    xlab(\"logit(fn) estimates\") +    ylab(\"density\")"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"fraction-new-estimate-replicate-correlation","dir":"Articles","previous_headings":"The QC_checks() function","what":"Fraction new estimate replicate correlation","title":"Troubleshooting analyses of NR-seq data with bakR","text":"Finally, QC_checks() assesses extent fraction new estimates correlate replicates experimental condition. Better correlation means less variable data, means easier identify differences kinetic parameters experimental conditions. QC_checks output message regarding replicate--replicate correlation, also provides number correlation plots can inspect:  addition, QC_checks outputs correlation matrix allow convenient visualization sample--sample correlations:","code":"# Barplots of inferred mutation rates   # Numerical indices are ordered as they appear in QC_checks() output message   # So this is for replicate 1 and 2 of experimental ID 1 QC$correlation_plots[[1]] # Using function from corrplot package corrplot.mixed(QC$correlation_matrix,                 upper = \"square\", lower = \"number\",                 addgrid.col = \"black\", tl.col = \"black\")"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"challenge-to-be-aware-of-inaccurate-pnew-and-pold-estimates","dir":"Articles","previous_headings":"","what":"Challenge to be aware of: inaccurate pnew and pold estimates","title":"Troubleshooting analyses of NR-seq data with bakR","text":"QC_checks designed identify flag challenges bakR run analyzing data. experience, single important thing check robustness new old read mutation rate estimates (pnew pold). default, bakR fits simple binomial mixture method maximum likelihood estimate pnew. -s4U data, bakR uses average mutation rate data global pold estimate. Otherwise, default pold estimation strategy pnew. strategy can go astray reads data either new old. Intuitively, new (old) reads, difficult model infer mutation rate new (old) reads . example, analysis simulated data 98% reads old: pnew estimates one experimental conditions alright, estimates condition massive underestimates. Running QC_checks provides suggestion though Note message says “suggest rerunning bakRFit FastRerun StanRateEst = TRUE, particularly estimated mutation rates oddly low (< 0.01) subset samples”. bakR second pnew pold estimation strategy ’s sleeve, accessible via StanRateEst parameter. Setting TRUE causes bakR resort using fully Bayesian approach probabilistic programming language Stan working back end fit mixture model. approach take bit longer run, can provide accurate pnew pold estimates: ’s incredibly difficult get perfect pnew estimates dataset, strategy certainly lot better! can compare resulting fraction new estimates troublesome samples:   Perhaps alternative strategy estimating pnew, fairly confident mutation rate new reads data . case, estimates can passed directly bakR questions asked. can either pass vector pnews sample (ordered appear bakRFit pnew/pold estimate message, ordered Experimental ID Replicate ID), just single pnew think samples: expected, improves estimate accuracy, though much setting StanRateEst = TRUE :","code":"# Seed for reproducibility set.seed(321)  # Simulate a nucleotide recoding dataset sim_data <- Simulate_bakRData(1000, nreps = 2, fn_mean = -4)   # This will simulate 1000 features, 2 experimental conditions,   # and 2 replicates for each experimental condition   # The average logit(fn) will be -4, which corresponds to an average fn of just under 0.02.  # Run the efficient model   # Check the pnew estimates, which should all be around 0.05 Fit <- bakRFit(sim_data$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps    pnew    pold #>   <int> <dbl>   <dbl>   <dbl> #> 1     1     1 0.0505  0.00101 #> 2     1     2 0.0493  0.00101 #> 3     2     1 0.00221 0.00101 #> 4     2     2 0.00223 0.00101 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Run QC_checks and read messages QC <- QC_checks(Fit) #> Warning in QC_checks(Fit): Mutation rates in new reads are below 0.7% in one or more samples.  #>               It is very difficult to identify kinetic differences with such low #>               mutation rates. #> Background mutation rate looks good! #> Average fraction news for each sample are: #> # A tibble: 4 × 3 #> # Groups:   Exp_ID [2] #>   Exp_ID Replicate avg_fn #>    <int>     <dbl>  <dbl> #> 1      1         1 0.0468 #> 2      1         2 0.0478 #> 3      2         1 0.533  #> 4      2         2 0.531 #> Warning in assess_fn_cor(Fit, Bad_data = Bad_data, bakRFn = FALSE): The average fraction news are extremely low (less than 0.05) in  #>               one or more samples, suggesting your label time was too short.  #>               It will be difficult for bakR to identify any kinetic differences. #> Low fraction news impair bakR's default mutation rate estimation  #>                 strategy. I suggest rerunning bakRFit with FastRerun and  #>                 StanRateEst = TRUE, particularly if some of the estimated  #>                 mutation rates are oddly low (< 0.01) in a subset of samples. #> logit(fn) correlations for each pair of replicates are: #>   Exp_ID Rep_ID1 Rep_ID2 correlation #> 1      1       1       2   0.8533296 #> 2      2       1       2   0.7852611 #> logit(fn) correlations are high, suggesting good reproducibility! #> Some aspects of your data may limit bakR's ability to detect  #>               differential kinetics. Check warning messages for details. # Rerun with Stan-based pnew estimation   # This will take a couple minutes to run Fit_s <- bakRFit(Fit, FastRerun = TRUE, StanRateEst = TRUE) #>  #> SAMPLING FOR MODEL 'Mutrate_est' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000545 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 5.45 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 12.381 seconds (Warm-up) #> Chain 1:                6.565 seconds (Sampling) #> Chain 1:                18.946 seconds (Total) #> Chain 1: #> Estimating pnew with Stan output #> Estimating unlabeled mutation rate with Stan output #> Estimated pnews and polds for each sample are: #>   mut reps       pnew         pold #> 1   1    1 0.04221830 0.0009098713 #> 2   1    2 0.04332409 0.0009098713 #> 3   2    1 0.04003344 0.0009098713 #> 4   2    2 0.03945663 0.0009098713 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Simulated ground truth sim_truth <- sim_data$sim_list  # Features that made it past filtering XFs <- unique(Fit$Fast_Fit$Effects_df$XF)  # Simulated logit(fraction news) from features making it past filtering true_fn <- sim_truth$Fn_rep_sim$Logit_fn[sim_truth$Fn_rep_sim$Feature_ID %in% XFs &                                            sim_truth$Fn_rep_sim$Exp_ID == 2]  # Estimated logit(fraction news) est_fn <- Fit$Fast_Fit$Fn_Estimates$logit_fn[Fit$Fast_Fit$Fn_Estimates$Exp_ID == 2]  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\",      main = \"Default pnew estimation\",      xlim = c(-8, 6),      ylim = c(-8, 6)) abline(0, 1, col = \"red\") # Estimated logit(fraction news) est_fn <- Fit_s$Fast_Fit$Fn_Estimates$logit_fn[Fit_s$Fast_Fit$Fn_Estimates$Exp_ID == 2]  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\",      main = \"Alternative pnew estimation\",      xlim = c(-8, 6),      ylim = c(-8, 6)) abline(0, 1, col = \"red\") # Rerun with Stan-based pnew estimation   # This will take a couple minutes to run Fit_u <- bakRFit(Fit, FastRerun = TRUE, pnew = 0.05) #> Using provided pnew estimates #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #>   mut reps pnew        pold #> 1   1    1 0.05 0.001006472 #> 2   1    2 0.05 0.001006472 #> 3   2    1 0.05 0.001006472 #> 4   2    2 0.05 0.001006472 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Estimated logit(fraction news) est_fn <- Fit_u$Fast_Fit$Fn_Estimates$logit_fn[Fit_u$Fast_Fit$Fn_Estimates$Exp_ID == 2]  # Compare estimate to truth plot(true_fn, est_fn, xlab = \"True logit(fn)\", ylab = \"Estimated logit(fn)\",      main = \"User provided pnew\",      xlim = c(-8, 6),      ylim = c(-8, 6)) abline(0, 1, col = \"red\")"},{"path":"https://simonlabcode.github.io/bakR/articles/Troubleshooting.html","id":"experimental-suggestions","dir":"Articles","previous_headings":"","what":"Experimental suggestions","title":"Troubleshooting analyses of NR-seq data with bakR","text":"Sometimes solution challenges might face analyzing NR-seq data bakR can overcome alternative bakR settings. Sometimes though, experimental optimization can make much bigger difference. general suggestions consider designing next NR-seq experiment: surprised much cell line cell line variability readiness metabolic label uptake. one end spectrum HeLa cells uptake label ferociously often can use lower normal s4U concentrations avoid cytotoxic effects still maintaining high incorporation rates. end spectrum though, neuronal cell lines often uptake label much lower rate. TAMRA dot blot assays one way lab inspects incorporation rate new cell line. incorporation rates low, test using higher concentration metabolic label, looking signs cytotoxicity tendency treat NR-seq experiments like transcriptional assays. thinking goes “label short enough time amount new RNA influenced synthesis kinetics”. fraught many reasons. one, “short” label time NR-seq experiment still often means hour mammalian cell lines, enough RNA labeled allow robust detection without enrichment labeled species. plenty degradation new RNA time frame though, meaning amount new RNA function degradation synthesis kinetics. addition, restricting analysis new RNA, throwing vast majority reads significantly underpowering analyses. Note, evidence literature differential new RNA expression analysis can provide insights missed differential total RNA expression analysis, extent generally true questionable. Evidence favor conclusion stem inadequate normalization total RNA-seq data, causing global effects perturbation missed. Finally, one benefit analyzing fraction reads new rather raw number reads new former “internally normalized” fraction new ratio RNA feature’s new read counts sample ’s total read counts sample. Thus, scale factor need apply sample-wide feature-specific read counts cancel calculating ratio. Analyzing fraction news (e.g., relating degradation rate constants) thus avoids challenge normalizing RNA-seq read count data. upside eliminated performing differential expression analysis new RNA read counts, normalization must considered. Beware toxicity effects metabolic label though! Always include -s4U control can determine anything significantly different expression patterns s4U treated cells (e.g., activation stress response pathways). careful overinterpret effects like metabolic label containing RNA dropout (discussed “Correcting dropout” vignette) cytotoxicity effects! Correct read counts dropout (bakR’s CorrectDropout function) see still major expression differences clarity, pulse-chase = pulse s4U chase uridine; pulse-label = pulse s4U. Pulse-chase experimental designs suffer number shortcomings almost never necessary NR-seq experiments. many classic examples pulse-chase experimental designs used assess kinetics RNA metabolism. cases though, point pulse create species RNA whose dynamics completely driven degradation kinetics RNA. example, pioneering studies Parker lab elucidating mechanisms RNA degradation involved pulsing particular nutrient stimulate transcription construct. chase washed nutrient shut transcription construct, meaning RNA produced exclusively degrade post-chase. pulse metabolic label like s4U though, already created species RNA whose dynamics completely degradation driven: unlabeled RNA. Following metabolic label pulse nucleotide chase thus redundant, switching degradation driven population unlabeled RNA labeled RNA. addition, pulse-chase experiments often necessitate extensive exposure cells metabolic label, increases possibility cytotoxic effects metabolic label. Finally, analysis pulse-chase experiments complicated pulse-label design. estimate kinetics degradation, need know fraction RNA feature interest labeled pulse. means estimating synthesis degradation kinetics requires two separate samples, RNA extracted pulse RNA extracted chase. pulse alone, can get information can get though!! want multiple time points? Just multiple pulses. Pulse-labels easier perform easier analyze pulse-chases. pulse-chase NR-seq data like analyze, can contact either posting Issue bakR Github emailing directly (isaac.vock@yale.edu). also repo created purpose can check .","code":""},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Fn.html","id":"necessary-setup","dir":"Articles","previous_headings":"","what":"Necessary Setup","title":"GRAND-SLAM output/fn estimates as bakR input","text":"Make sure version 1.0.0 bakR installed.","code":"library(bakR) set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Fn.html","id":"step-1-creating-a-bakrfndata-object","dir":"Articles","previous_headings":"","what":"Step 1: Creating a bakRFnData Object","title":"GRAND-SLAM output/fn estimates as bakR input","text":"1st step using bakR fraction new estimates input create bakRFnData object. bakRFnData object consists two components: fns data frame metadf data frame. fns stands “fraction new estimates” contains information regarding estimates fraction sequencing reads given feature new given sample. metadf stands metadata data frame contains important information experimental details sample (.e., long metabolic label feed , samples reference samples, experimental samples). Examples data structures available via calls data(\"fns\") data(\"metadf\"), fns data frame metadf respectively. fns data frame consists rows corresponding fraction new estimate information given feature. particular, 4 required (one optional) columns fns data frame: sample: name sample reads described row originated. Usually sort character vector defined. XF stands “exonic feature”, since cases considering reads map definitively exonic locations. Introns typically rapidly turned thus highly labeled species bias estimates mature transcript stability. fn: Estimate fraction new se (optional): Uncertainty fraction new estimate n: Number reads feature/sample combination represented row. metadf data frame described “bakR people hurry” “Differential kinetic analysis bakR” vignettes. One route obtain fns data frame via GRAND-SLAM, efficient user friendly tool developed Erhard lab implements binomial mixture model originally described lab. GRAND-SLAM outputs table named run_name.tsv (run_name whatever specified running GRAND-SLAM), can quickly converted fns data frame. can create bakRFnData object follows:","code":"# Load GRAND-SLAM table and metadf data(\"GS_table\") data(\"metadf\")  # Create fns data frame from GRAND-SLAM output fns <- GSprocessing(GS_table)   # Create bakRFnData object bfndo <- bakRFnData(fns, metadf)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Fn.html","id":"step-2-fitting-the-efficient-model","dir":"Articles","previous_headings":"","what":"Step 2: Fitting the Efficient Model","title":"GRAND-SLAM output/fn estimates as bakR input","text":"creating bakRFnData object, must first run bakR’s efficient implementation (MLE implementation bakR manuscript).: bakRFit() used wrapper two functions bakR: fn_process() fast_analysis(). details functions , run ?fn_process fast_analysis. using fraction new estimates input, one two highly powered implementations may used (Hybrid implementation bakR manuscript). can run follows: Fit objects contain lists pertaining fits models. possible contents include: Fast_Fit: Result initial fitting bakRData object. learn contents, see ?fast_analysis() Data_lists: Processed data can passed statistical models Hybrid_Fit: Result running bakRFit() Fit object HybridFit = TRUE. learn contents, see ?TL_stan().","code":"# Run the efficient model Fit <- bakRFit(bfndo) #> Mapping sample name to sample characteristics #> Filtering out low coverage features #> Processing data... #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Run Hybrid model (This might take several minutes to run) Fit <- bakRFit(Fit, HybridFit = TRUE)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Fn.html","id":"step-3-visualizing-the-results","dir":"Articles","previous_headings":"","what":"Step 3: Visualizing the Results","title":"GRAND-SLAM output/fn estimates as bakR input","text":"bakR provides variety easy use functions beginning investigate data. visualizations particularly aimed revealing trends RNA stabilization destabilization. include MA plots:  Volcano plots:  PCA plots:","code":"## MA Plot with Fast Fit bakR::plotMA(Fit, Model = \"MLE\") ## Volcano Plot with Fast Fit; significance assessed relative to an FDR control of 0.05 plotVolcano(Fit$Fast_Fit) ## 2D PCA plot with replicate fraction news FnPCA2(Fit, Model = \"MLE\")"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Fn.html","id":"step-4-where-to-go-from-here","dir":"Articles","previous_headings":"","what":"Step 4: Where to go from here","title":"GRAND-SLAM output/fn estimates as bakR input","text":"vignette provides minimal amount information get running bakR using fraction new estimates input. like thorough discussion step process, check long form version intro bakR vignette (“Differential kinetic analysis bakR”). addition, number vignettes cover various topics discussed intro vignettes: Differential synthesis rate analysis Correcting loss s4U RNA library preparation (.k.. dropout correction) Troubleshooting analyses NR-seq datasets Dissecting mechanisms gene expression regulation relaxing steady-state assumption.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Quickstart.html","id":"necessary-setup","dir":"Articles","previous_headings":"","what":"Necessary Setup","title":"bakR for people in a hurry","text":"Install load bakR run code vignette; instructions can found link. Also, ’ll want set seed ensure results get reproduce presented vignette.","code":"library(bakR) set.seed(123)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Quickstart.html","id":"step-1-creating-a-bakrdata-object","dir":"Articles","previous_headings":"","what":"Step 1: Creating a bakRData Object","title":"bakR for people in a hurry","text":"1st step using bakR create bakRData object. bakRData object consists two components: cB data frame metadf data frame. cB stands counts binomial contains information mutations seen sequencing reads sample sequenced. metadf stands metadata data frame contains important information experimental details sample (.e., long metabolic label feed , samples reference samples, experimental samples). Examples data structures available via calls data(\"cB_small\") data(\"metadf\"), cB metadf respectively. cB data frame consists rows corresponding groups reads identical data, data corresponds values following four variables: sample: name sample reads described row originated. Usually sort character vector defined. TC: Number U--C mutations (assuming using s4U metabolic label). Called TC technically data T--C mutations reverse-transcribed RNA. nT: Number Ts (Us RNA) sequencing read(s) XF stands “exonic feature”, since cases considering reads map definitively exonic locations. Introns typically rapidly turned thus highly labeled species bias estimates mature transcript stability. last column cB data frame n: Number reads identical data 4 columns. cB data frames easily obtained Snakemake implementation pipeline developed lab, called bam2bakR (available ). metadf two columns: tl: length metabolic labeling feed. can units (simulated data puts terms minutes), s4U fed sample, tl must 0 sample. -s4U controls play important role statistical models, crucial remember. technically necessary run bakR, always highly suggest including controls. Exp_ID: Stands “Experimental ID” numerical ID denotes samples reference condition (Exp_ID = 1) experimental samples belong “treatment” (Exp_IDs > 1). can one experimental sample, comparisons done respect one reference sample. metadf data frame must also row names corresponding sample name tl Exp_ID entries describe, sample name appears cB data frame. two data frames correctly constructed, can create bakRData object:","code":"# Load data data(\"cB_small\") data(\"metadf\")  # Create bakRData object bakRData <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Quickstart.html","id":"step-2-fitting-the-efficient-model","dir":"Articles","previous_headings":"","what":"Step 2: Fitting the Efficient Model","title":"bakR for people in a hurry","text":"bakR contains three different implementations statistical model NR-seq data. must always first run efficient implementation. two implementations can run using output implementation. show run efficient implementation using simulated data: bakRFit() used wrapper two functions bakR: cBprocess() fast_analysis(). details functions , run ?cBprocess fast_analysis. Alternatively, see highly detailed version vignette additional details. fast implementation running, outputted message regarding estimated pnews pold. pnews estimated mutation rates reads new RNAs (new meaning RNAs synthesized start s4U labeling) sample (muts = Exp_ID, reps = numerical replicate ID corresponds order replicates appear cB), polds estimates background mutation rate used analyses. details bakR estimates mutation rates alternative estimation strategies implemented bakR, see longer form version vignette well vignette troubleshooting analyses. run heavier, highly powered models, just rerun bakRFit() Fit object, either StanFit HybridFit parameters set true. Fit objects contain lists pertaining fits models. possible contents include: Fast_Fit: Result initial fitting bakRData object. learn contents, see ?fast_analysis() Data_lists: Processed data can passed statistical models Hybrid_Fit: Result running bakRFit() Fit object HybridFit = TRUE. learn contents, see ?TL_stan(). Stan_Fit: Result running bakRFit() Fit object StanFit = TRUE. general contents identical Hybrid_Fit, even though models different.","code":"# Simulate a nucleotide recoding dataset sim_data <- Simulate_bakRData(500)   # This will simulate 500 features, 2 experimental conditions   # and 3 replicates for each experimental condition   # See ?Simulate_bakRData for details regarding tunable parameters  # Extract simulated bakRData object bakRData <- sim_data$bakRData  # Extract simualted ground truths sim_truth <- sim_data$sim_list  # Run the efficient model Fit <- bakRFit(bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 6 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0502 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     1     3 0.0501 0.00100 #> 4     2     1 0.0501 0.00100 #> 5     2     2 0.0500 0.00100 #> 6     2     3 0.0503 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # Run Hybrid model (This might take several minutes to run) Fit <- bakRFit(Fit, HybridFit = TRUE)  # Run Full model (This might take ~10-30 minutes to run) Fit <- bakRFit(Fit, StanFit = TRUE)"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Quickstart.html","id":"step-3-visualizing-the-results","dir":"Articles","previous_headings":"","what":"Step 3: Visualizing the Results","title":"bakR for people in a hurry","text":"bakR provides variety easy use functions beginning investigate data. visualizations particularly aimed revealing trends RNA stabilization destabilization. include MA plots:  Volcano plots:  PCA plots:","code":"## MA Plot with Fast Fit bakR::plotMA(Fit, Model = \"MLE\") ## Volcano Plot with Fast Fit; significance assessed relative to an FDR control of 0.05 plotVolcano(Fit$Fast_Fit) ## 2D PCA plot with replicate fraction news   # The equivalent function prior to version 1.0.0 is FnPCA, now deprecated in    # favor of FnPCA2. FnPCA2(Fit, Model = \"MLE\")"},{"path":"https://simonlabcode.github.io/bakR/articles/bakR-Quickstart.html","id":"step-4-where-to-go-from-here","dir":"Articles","previous_headings":"","what":"Step 4: Where to go from here","title":"bakR for people in a hurry","text":"vignette provides minimal amount information get running bakR. like thorough discussion step process, check long form version vignette (“Differential kinetic analysis bakR”). addition, number vignettes cover various topics discussed intro vignettes: Differential synthesis rate analysis Correcting loss s4U RNA library prepartion (.k.. dropout correction) Troubleshooting analyses NR-seq datasets Mechanistic dissection differential expression Running bakR fraction new estimate input (e.g., GRAND-SLAM) Note, “Differential synthesis rate analysis” vignette fully compatible version 1.0.0 bakR. Update bakR necessary","code":""},{"path":"https://simonlabcode.github.io/bakR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Isaac Vock. Author, maintainer.","code":""},{"path":"https://simonlabcode.github.io/bakR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vock (2023). bakR: Analyze Compare Nucleotide Recoding RNA Sequencing Datasets. R package version 1.0.0, https://simonlabcode.github.io/bakR/.","code":"@Manual{,   title = {bakR: Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets},   author = {Isaac Vock},   year = {2023},   note = {R package version 1.0.0},   url = {https://simonlabcode.github.io/bakR/}, }"},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"brief-description-of-bakr-","dir":"","previous_headings":"","what":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"bakR (Bayesian analysis kinetics RNA) R package performing differential kinetics analysis nucleotide recoding high-throughput RNA sequencing (NR-seq) data. Kinetic parameter estimation statistical testing compatible mutational data enrichment free NR-seq method (e.g., TimeLapse-seq, SLAM-seq, TUC-seq, etc.).","code":""},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"version-100-is-out-now-06272023","dir":"","previous_headings":"","what":"Version 1.0.0 is out now! (06/27/2023)","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"lot functionality added, highly suggest users bakR update version. also many new vignettes discuss new features. bakR v1.0.0 currently process submitted CRAN, currently available installation Github, described . Two major changes/additions : 1. Ability use GRAND-SLAM output (fraction new estimates generally) bakR input 2. Strategy correcting metabolic label related biases kinetic parameter estimates read counts","code":""},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"why-use-bakr","dir":"","previous_headings":"","what":"Why use bakR?","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"Differential expression analysis RNA sequencing (RNA-seq) data can identify changes cellular RNA levels, determine kinetic mechanism underlying changes. Previously, lab others addressed shortcoming developing nucleotide-recoding RNA-seq methods (NR-seq; e.g., TimeLapse-seq) quantify changes RNA synthesis degradation kinetics. advanced statistical models implemented user-friendly software (e.g., DESeq2) ensured statistical rigor differential expression analyses, tools facilitate differential kinetic analysis NR-seq exist. address need, developed bakR, R package analyzes compares NR-seq datasets. Differential kinetics analysis bakR relies Bayesian hierarchical model NR-seq data increase statistical power sharing information across transcripts. bakR outperforms attempts use single sample analysis tools (e.g., pulseR GRAND-SLAM) differential kinetics analysis. Check manuscript RNA learn model extensive validation!","code":""},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"bakR now available CRAN! using Mac Windows OS means don’t need configure C++ compiler install use bakR. Mac Windows OS need first properly configure C++ compiler; see next paragraph details links describing . either case, (compiler necessary) ready, bakR can installed follows: install newest version bakR Github, need C++ compiler configured rstan’s (R interface probabilistic programming language Stan bakR uses backend) liking. best way follow Stan team’s helpful documentation installing rstan operating system. complete, can install bakR follows:","code":"install.packages(\"bakR\") install.packages(\"devtools\") # if you haven't installed devtools already devtools::install_github(\"simonlabcode/bakR\")"},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"currently seven vignettes help get speed using bakR: introductory vignette (title: Differential Kinetic Analysis bakR) walks basic bakR workflow simulated data. concise version introductory vignette get running bakR quickly (title: bakR people hurry). Particularly appropriate comfortable adopting new bioinformatic tools. Combining bakR differential expression analysis perform differential synthesis rate analysis (title: Differential synthesis analysis bakR DESeq2). use fraction new estimates (e.g., tool like GRAND-SLAM) input bakR, new feature introduced version 1.0.0 (title: GRAND-SLAM output/fn estimates bakR input). Correcting disproportionate loss s4U containing RNA (title: Correcting dropout). phenomenon, termed dropout, discussed two recent preprints, one lab one Erhard lab. identify deal problems can crop analyzing NR-seq data (title: Troubleshooting analyses NR-seq data bakR). Distinguishing transcriptional post-transcriptional regulation, even steady-state assumption partially violated (title: Steady-state quasi-independent mechanistic investigations). Describes new somewhat experimental function bakR, DissectMechanism. vignettes available bakR website Articles section. link bakR github well need help getting back github website.","code":""},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"obtaining-the-necessary-input","dir":"","previous_headings":"","what":"Obtaining the Necessary Input","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"discussed introductory vignette, bakR requires data form -called “cB”, counts binomial data frame. row cB data frame corresponds group reads identical mutational data, columns denote sample reads came, feature reads aligned , number mutations interest reads (e.g., T--C mutations), number mutable positions (e.g. Ts), number reads. reasonable wonder “supposed get information?” couple possibilities, perhaps easiest widely applicable bam2bakR, Snakemake implementation TimeLapse pipeline developed Simon lab. bam2bakR takes input aligned bam files produces, among things, cB file required bakR. Extensive documentation describing get bam2bakR running available GitHub repo. Snakemake greatly facilitates running pipeline almost computational infrastructure bam2bakR uses conda/mamba package manager make setting necessary dependencies breeze. version 1.0.0, bakR can also take input fraction new (sometimes referred new--total ratio, NTR) estimates. obtainable via tools like GRAND-SLAM, perhaps custom analysis pipeline developed working NR-seq datasets!","code":""},{"path":"https://simonlabcode.github.io/bakR/index.html","id":"bug-catching-and-further-questions","dir":"","previous_headings":"","what":"Bug Catching and Further Questions","title":"Analyze and Compare Nucleotide Recoding RNA Sequencing Datasets","text":"Post descriptions bugs simple reproducible example (possible) Issues section repo. fact, go Issues section question bakR, even helpful labels can append posts make nature request clear. email (Isaac Vock) question/concern/suggestion, direct Issues section. basic use questions, suggest going vignettes linked . answer question, post question Issues.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"Dropout name given phenomenon originally identified lab detailed two independent publications (Zimmer et al. (2023),  Berg et al. (2023)). Dropout -representation reads RNA containing metabolic label (4-thiouridine 6-thioguanidine commonly). Loss 4-thiouridine (s4U) containing RNA plastic surfaces RT dropoff caused modifications s4U introduced recoding chemistry attributed likely causes phenomenon. protocols can altered ways drastically reduce source dropout, may still datasets want analyze bakR collected suboptimal handling. CorrectDropout comes .","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"","code":"CorrectDropout(   obj,   scale_init = 1.05,   pdo_init = 0.3,   recalc_uncertainty = FALSE,   ... )"},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"obj bakRFit object scale_init Numeric; initial estimate -s4U/+s4U scale factor. factor difference RPM normalized read counts completely unlabeled transcripts (.e., highly stable transcript) +s4U -s4U samples. pdo_init Numeric; initial estimtae dropout rate. probability s4U labeled RNA molecule lost library prepartion. recalc_uncertainty Logical; TRUE, fraction new uncertainty recalculated using adjusted fn simple binomial model estimate uncertainty. provide slight underestimate fn uncertainty, far less biased low coverage features, samples low pnews. ... Additional (optional) parameters passed stats::nls()","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"bakRFit bakRFnFit object (type passed ). Fraction new estimates read counts Fast_Fit$Fn_Estimates (case bakRFnFit input) Data_lists$Fn_Estare dropout corrected. count matrix corrected read counts (Data_lists$Count_Matrix_corrected) also output, along data frame information dropout rate estimated sample (Data_lists$Dropout_df).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"CorrectDropout estimates percentage 4-thiouridine containing RNA lost library preparation (pdo). uses estimate pdo correct fraction new estimates read counts. corrections analytically derived rigorous generative model NR-seq data. Importantly, read count correction preserves total library size avoid artificially inflating read counts.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/CorrectDropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correcting for metabolic labeling induced RNA dropout — CorrectDropout","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates with 40% dropout sim <- Simulate_relative_bakRData(500, 100000, nreps = 2, p_do = 0.4)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0503 0.000992 #> 2     1     2 0.0502 0.000992 #> 3     2     1 0.0499 0.000992 #> 4     2     2 0.0500 0.000992 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Correct for dropout Fit <- CorrectDropout(Fit) #> Estimated rates of dropout are: #>   Exp_ID Replicate       pdo #> 1      1         1 0.2406242 #> 2      1         2 0.1904945 #> 3      2         1 0.2818575 #> 4      2         2 0.0000000 #> Mapping sample name to sample characteristics #> Filtering out low coverage features #> Processing data... #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"uses output bakR differential expression analysis software construct dataframe can passed pheatmap::pheatmap(). heatmap display result steady-state quasi-independent analysis NR-seq data.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"","code":"DissectMechanism(   bakRFit,   DE_df,   bakRModel = c(\"MLE\", \"Hybrid\", \"MCMC\"),   DE_cutoff = 0.05,   bakR_cutoff = 0.3,   Exp_ID = 2,   sims = 1e+07 )"},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"bakRFit bakRFit object DE_df dataframe required format differential expression analysis results. See -Analyses vignette details dataframe look like bakRModel Model fit bakR implementation used? Options MLE, Hybrid, MCMC DE_cutoff padj cutoff calling gene differentially expressed bakR_cutoff padj cutoff calling fraction new significantly changed. discussed mechanistic dissection vignette, best keep conservative (higher padj) typical. Thus, default 0.3 rather standard (though admittedly arbitrary) 0.05. Exp_ID Exp_ID experimental sample whose comparison reference sample want use. one reference vs. experimental sample comparison can used time sims Number simulation draws null distribution mechanism p value calculation","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"returns list data frames: heatmap_df NSS_stats. heatmap_dfdata frame can passed pheatmap::pheatmap(). NSS_stats data frame contains information passed NSS_stats well raw mechanism scores. also p values calculated mechanism z scores.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"Unlike NSSHeat, DissectMechanism uses mechanism scoring function discontinuous \"degradation driven\" vs. \"synthesis driven\" boundary. Instead, score approaches 0 function approaches boundary either side. addition, DissectMechanism now defines null model purpose p value calculation using mechanism score. null hypothesis, mechanism score product two normal distributions unit variance, one non-zero mean. Simulation used estimate integral distribution, number draws (determines precision p value estimate) determined sims parameter. DissectMechanism also provides \"meta-analysis p values\", can interpreted p-value particular RNA feature observing differential expression differential kinetics (). meta_pval estimated using Fisher's method meta analysis.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/DissectMechanism.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct heatmap for non-steady state (NSS) analysis with improved mechanism score — DissectMechanism","text":"","code":"# \\donttest{ # Simulate small dataset sim <- Simulate_bakRData(100, nreps = 2)  # Analyze data with bakRFit Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0502 0.00101 #> 2     1     2 0.0500 0.00101 #> 3     2     1 0.0505 0.00101 #> 4     2     2 0.0508 0.00101 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Number of features that made it past filtering NF <- nrow(Fit$Fast_Fit$Effects_df)  # Simulate mock differential expression data frame DE_df <- data.frame(XF = as.character(1:NF),                        L2FC_RNA = stats::rnorm(NF, 0, 2))  DE_df$DE_score <- DE_df$L2FC_RNA/0.5 DE_df$DE_se <- 0.5  DE_df$DE_pval <- 2*stats::dnorm(-abs(DE_df$DE_score)) DE_df$DE_padj <- 2*stats::p.adjust(DE_df$DE_pval, method = \"BH\")  # perform NSS analysis NSS_analysis <- DissectMechanism(bakRFit = Fit,                DE_df = DE_df,                bakRModel = \"MLE\") #> Combining bakR and DE analyses #> Calculating mechanism p-value. This could take several minutes... #> Assessing differential synthesis #> Constructing Heatmap_df  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Creating PCA plots with logit(fn) estimates — FnPCA","title":"Creating PCA plots with logit(fn) estimates — FnPCA","text":"function creates 2-component PCA plot using logit(fn) estimates. FnPCA deprecated favor FnPCA2. latter accepts full bakRFit input handles imbalanced replicates.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creating PCA plots with logit(fn) estimates — FnPCA","text":"","code":"FnPCA(obj, log_kdeg = FALSE)"},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creating PCA plots with logit(fn) estimates — FnPCA","text":"obj Object contained within output bakRFit. , either Fast_Fit (MLE implementation fit), Stan_Fit (MCMC implementation fit), Hybrid_Fit (Hybrid implementation fit) log_kdeg Boolean; TRUE, log(kdeg) estimates used PCA rather logit(fn). Currently compatible Fast_Fit","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creating PCA plots with logit(fn) estimates — FnPCA","text":"ggplot object.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creating PCA plots with logit(fn) estimates — FnPCA","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates sim <- Simulate_bakRData(500, nreps = 2)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0501 0.00100 #> 2     1     2 0.0500 0.00100 #> 3     2     1 0.0498 0.00100 #> 4     2     2 0.0499 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Fn PCA FnPCA2(Fit, Model = \"MLE\")   # log(kdeg) PCA FnPCA2(Fit, Model = \"MLE\", log_kdeg = TRUE)   # }"},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA2.html","id":null,"dir":"Reference","previous_headings":"","what":"Creating PCA plots with logit(fn) estimates — FnPCA2","title":"Creating PCA plots with logit(fn) estimates — FnPCA2","text":"function creates 2-component PCA plot using logit(fn) log(kdeg) estimates.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creating PCA plots with logit(fn) estimates — FnPCA2","text":"","code":"FnPCA2(obj, Model = c(\"MLE\", \"Hybrid\", \"MCMC\"), log_kdeg = FALSE)"},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creating PCA plots with logit(fn) estimates — FnPCA2","text":"obj bakRFit object Model String identifying implementation want generate PCA plot log_kdeg Boolean; TRUE, log(kdeg) estimates used PCA rather logit(fn). Currently compatible MLE implementation","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creating PCA plots with logit(fn) estimates — FnPCA2","text":"ggplot object.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/FnPCA2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creating PCA plots with logit(fn) estimates — FnPCA2","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates sim <- Simulate_bakRData(500, nreps = 2)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0501 0.00101 #> 2     1     2 0.0499 0.00101 #> 3     2     1 0.0500 0.00101 #> 4     2     2 0.0501 0.00101 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Fn PCA FnPCA2(Fit, Model = \"MLE\")   # log(kdeg) PCA FnPCA2(Fit, Model = \"MLE\", log_kdeg = TRUE)   # }"},{"path":"https://simonlabcode.github.io/bakR/reference/GS_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cB data frame — GS_table","title":"Example cB data frame — GS_table","text":"Subset GRAND-SLAM main output table anlaysis dataset published Luo et al. 2020. Data 300 randomly selected genes included keep file size small.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GS_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cB data frame — GS_table","text":"","code":"data(GS_table)"},{"path":"https://simonlabcode.github.io/bakR/reference/GS_table.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example cB data frame — GS_table","text":"dataframe 300 rows 63 variables; row corresponds GRAND-SLAM parameter estimates single gene 6 different samples (4 +s4U 2 -s4U). Description columns can found GRAND-SLAM wiki","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GS_table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Example cB data frame — GS_table","text":"Luo et al. (2020) Biochemistry. 59(42), 4121-4142","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GS_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example cB data frame — GS_table","text":"","code":"data(GS_table) data(metadf) fns <- GSprocessing(GS_table) bdfo <- bakRFnData(fns, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/GSprocessing.html","id":null,"dir":"Reference","previous_headings":"","what":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","title":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","text":"function creates fraction new estimate data frame can passed bakRFnData, using main .tsv file output GRAND-SLAM.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GSprocessing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","text":"","code":"GSprocessing(GS, use_symbol = FALSE)"},{"path":"https://simonlabcode.github.io/bakR/reference/GSprocessing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","text":"GS Table read counts NTR (fraction new) estimate parameters output GRAND-SLAM. Corresponds run_name.tsv file included GRAND-SLAM output use_symbol Logical; TRUE, Symbol column rather Gene column used feature column (XF) output data frame.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GSprocessing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","text":"data frame can passed fns parameter bakRFnData","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/GSprocessing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prep GRAND-SLAM output for bakRFnData — GSprocessing","text":"","code":"# Load GRAND-SLAM table data(\"GS_table\")   # Create bakRData object fns <- GSprocessing(GS_table)"},{"path":"https://simonlabcode.github.io/bakR/reference/Heatmap_kdeg.html","id":null,"dir":"Reference","previous_headings":"","what":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","title":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","text":"Heatmap_kdeg creates matrix column represents pair samples (reference experimental) row represents feature. entry ith row jth column L2FC(kdeg) feature comparing sample experimental ID j+1 reference sample","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Heatmap_kdeg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","text":"","code":"Heatmap_kdeg(obj, zscore = FALSE, filter_sig = FALSE, FDR = 0.05)"},{"path":"https://simonlabcode.github.io/bakR/reference/Heatmap_kdeg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","text":"obj Object outputted bakRFit zscore Logical; TRUE, matrix entry log-odds fold change fraction new (.k.effect size) divided uncertainty effect size filter_sig Logical; TRUE, features statistically significant L2FC(kdeg) least one comparison kept FDR Numeric; False discovery control filter_sig TRUE.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Heatmap_kdeg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","text":"matrix. Rows represent transcripts differentially expressed columns represent (left right) differential kinetics z-score, differential expression z-score, mechanism score positive represents synthesis driven negative degradation driven changes expression.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Heatmap_kdeg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creating a L2FC(kdeg) matrix that can be passed to heatmap functions — Heatmap_kdeg","text":"","code":"# \\donttest{ # Simulate data sim <- Simulate_bakRData(1000)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 6 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0501 0.000992 #> 2     1     2 0.0501 0.000992 #> 3     1     3 0.0499 0.000992 #> 4     2     1 0.0503 0.000992 #> 5     2     2 0.0500 0.000992 #> 6     2     3 0.0503 0.000992 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # L2FC(kdeg) heatmap matrix L2FC_kdeg_heat <- Heatmap_kdeg(Fit$Fast_Fit)  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/NSSHeat.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","title":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","text":"uses output bakR differential expression analysis software construct dataframe can passed pheatmap::pheatmap(). heatmap display result steady-state quasi-independent analysis NR-seq data.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/NSSHeat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","text":"","code":"NSSHeat(   bakRFit,   DE_df,   bakRModel = c(\"MLE\", \"Hybrid\", \"MCMC\"),   DE_cutoff = 0.05,   bakR_cutoff = 0.05,   Exp_ID = 2,   lid = 4 )"},{"path":"https://simonlabcode.github.io/bakR/reference/NSSHeat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","text":"bakRFit bakRFit object DE_df dataframe required format differential expression analysis results. See -Analyses vignette details dataframe look like bakRModel Model fit bakR implementation used? Options MLE, Hybrid, MCMC DE_cutoff padj cutoff calling gene differentially expressed bakR_cutoff padj cutoff calling fraction new significantly changed Exp_ID Exp_ID experimental sample whose comparison reference sample want use. one reference vs. experimental sample comparison can used time lid Maximum absolute value standardized score present output. improving aesthetics heatmap generated output.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/NSSHeat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","text":"returns data frame can passed pheatmap::pheatmap()","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/NSSHeat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct heatmap for non-steady state (NSS) analysis — NSSHeat","text":"","code":"# \\donttest{ # Simulate small dataset sim <- Simulate_bakRData(100, nreps = 2)  # Analyze data with bakRFit Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0502 0.00102 #> 2     1     2 0.0499 0.00102 #> 3     2     1 0.0497 0.00102 #> 4     2     2 0.0497 0.00102 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Number of features that made it past filtering NF <- nrow(Fit$Fast_Fit$Effects_df)  # Simulate mock differential expression data frame DE_df <- data.frame(XF = as.character(1:NF),                        L2FC_RNA = stats::rnorm(NF, 0, 2))  DE_df$DE_score <- DE_df$L2FC_RNA/0.5 DE_df$DE_se <- 0.5  DE_df$DE_pval <- 2*stats::dnorm(-abs(DE_df$DE_score)) DE_df$DE_padj <- 2*stats::p.adjust(DE_df$DE_pval, method = \"BH\")  # perform NSS analysis NSS_analysis <- DissectMechanism(bakRFit = Fit,                DE_df = DE_df,                bakRModel = \"MLE\") #> Combining bakR and DE analyses #> Calculating mechanism p-value. This could take several minutes... #> Assessing differential synthesis #> Constructing Heatmap_df  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/QC_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","title":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","text":"QC_checks takes input bakRFit bakRFnFit object uses Fast_Fit object assess data quality make suggestions implementation run next. QC_checks takes account mutation rates samples, fraction new distributions, reproducibility fraction new estimates, read lengths. outputs number diagnostic plots might alert users problems data. also outputs messages informing users implementation best used next.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QC_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","text":"","code":"QC_checks(obj)"},{"path":"https://simonlabcode.github.io/bakR/reference/QC_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","text":"obj bakRFit object","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QC_checks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","text":"list 3 components: raw_mutrates. plot raw T--C mutation rates samples analyzed bakR. includes horizontal lines reference considered \"low\" useful s4U fed samples. conversion_rates. plot estimated T--C mutation rates new old reads. Thus, bar represents probability U new/old read mutated. includes horizontal lines reference considered good mutation rates. correlation_plots. list ggplot objects. scatter plot comparing estimates fraction new one replicate another replicate experimental condition. y=x guide line included reveal estimation biases.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QC_checks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check data quality and make suggestions to user about what analyses to run. — QC_checks","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates sim <- Simulate_bakRData(500, nreps = 2)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0500 0.000997 #> 2     1     2 0.0500 0.000997 #> 3     2     1 0.0500 0.000997 #> 4     2     2 0.0500 0.000997 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Run QC QC <- QC_checks(Fit) #> Mutation rates in new reads looks good! #> Background mutation rate looks good! #> Average fraction news for each sample are: #> # A tibble: 4 × 3 #> # Groups:   Exp_ID [2] #>   Exp_ID Replicate avg_fn #>    <int>     <dbl>  <dbl> #> 1      1         1  0.498 #> 2      1         2  0.493 #> 3      2         1  0.486 #> 4      2         2  0.484 #> The average fraction news in all samples are between 0.2 and 0.8,  #>               suggesting an appropriate label time! #> logit(fn) correlations for each pair of replicates are: #>   Exp_ID Rep_ID1 Rep_ID2 correlation #> 1      1       1       2   0.9304098 #> 2      2       1       2   0.9401866 #> logit(fn) correlations are high, suggesting good reproducibility! #> I suggest running the Hybrid implementation next. This can be done  #>               with bakRFit(Fit, HybridFit = TRUE), where Fit is your bakRFit object.  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/QuantifyDropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit dropout model to quantify dropout frequency — QuantifyDropout","title":"Fit dropout model to quantify dropout frequency — QuantifyDropout","text":"QuantifyDropout estimates percentage 4-thiouridine containing RNA lost library preparation (pdo).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QuantifyDropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit dropout model to quantify dropout frequency — QuantifyDropout","text":"","code":"QuantifyDropout(   obj,   scale_init = 1.05,   pdo_init = 0.3,   keep_data = FALSE,   no_message = FALSE,   ... )"},{"path":"https://simonlabcode.github.io/bakR/reference/QuantifyDropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit dropout model to quantify dropout frequency — QuantifyDropout","text":"obj bakRFit object scale_init Numeric; initial estimate -s4U/+s4U scale factor. factor difference RPM normalized read counts completely unlabeled transcripts (.e., highly stable transcript) +s4U -s4U samples. pdo_init Numeric; initial estimtae dropout rate. probability s4U labeled RNA molecule lost library prepartion. keep_data Logical; TRUE, return list two elements. First element regular return (data frame dropout quantified), second element data frame used fitting dropout model. useful wanting visualize fit. See Return documetation details no_message Logical; TRUE, output message regarding estimated rates dropout sample ... Additional (optional) parameters passed stats::nls()","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QuantifyDropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit dropout model to quantify dropout frequency — QuantifyDropout","text":"keep_data FALSE, data frame dropout rate estimates (pdo) sample returned. keep_data TRUE, list two elements returned. One element pdo data frame always returned, second data frame containing information passed stats::nls pdo estimation.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/QuantifyDropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit dropout model to quantify dropout frequency — QuantifyDropout","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates with 40% dropout sim <- Simulate_relative_bakRData(500, depth = 100000,                                   nreps = 2, p_do = 0.4)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0502 0.000989 #> 2     1     2 0.0504 0.000989 #> 3     2     1 0.0496 0.000989 #> 4     2     2 0.0501 0.000989 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Quantify dropout Fit <- QuantifyDropout(Fit) #> Estimated rates of dropout are: #>   Exp_ID Replicate       pdo #> 1      1         1 0.3842015 #> 2      1         2 0.4075426 #> 3      2         1 0.4916991 #> 4      2         2 0.4463648  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulating nucleotide recoding data — Simulate_bakRData","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"Simulate_bakRData simulates bakRData object. output also includes simulated values kinetic parameters interest. number genes (ngene) set user, extensive list additional parameters can adjusted.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"","code":"Simulate_bakRData(   ngene,   num_conds = 2L,   nreps = 3L,   eff_sd = 0.75,   eff_mean = 0,   fn_mean = 0,   fn_sd = 1,   kslog_c = 0.8,   kslog_sd = 0.95,   tl = 60,   p_new = 0.05,   p_old = 0.001,   read_lengths = 200L,   p_do = 0,   noise_deg_a = -0.3,   noise_deg_b = -1.5,   noise_synth = 0.1,   sd_rep = 0.05,   low_L2FC_ks = -1,   high_L2FC_ks = 1,   num_kd_DE = c(0L, as.integer(rep(round(as.integer(ngene)/2), times =     as.integer(num_conds) - 1))),   num_ks_DE = rep(0L, times = as.integer(num_conds)),   scale_factor = 150,   sim_read_counts = TRUE,   a1 = 5,   a0 = 0.01,   nreads = 50L,   alpha = 25,   beta = 75,   STL = FALSE,   STL_len = 40,   lprob_U_sd = 0,   lp_sd = 0 )"},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"ngene Number genes simulate data num_conds Number experimental conditions (including reference condition) simulate nreps Number replicates simulate eff_sd Effect size; specifically, standard deviation normal distribution non-zero changes logit(fraction new) pulled . eff_mean Effect size mean; mean normal distribution non-zero changes logit(fraction new) pulled . Note, setting 0 mean significant effect sizes 0, exact integer impossible draw continuous random number generator. Setting 0 just means symmetric stabilization destabilization fn_mean Mean fraction news simulated transcripts reference condition. logit(fraction) RNA transcript metabolically labeled (new) drawn normal distribution mean fn_sd Standard deviation fraction news simulated transcripts reference condition. logit(fraction) RNA transcript metabolically labeled (new) drawn normal distribution sd kslog_c Synthesis rate constants drawn lognormal distribution meanlog = kslog_c - mean(log(kd_mean)) kd_mean determined fraction new simulated gene well label time (tl). kslog_sd Synthesis rate lognormal standard deviation; see kslog_c documentation details tl metabolic label feed time p_new metabolic label (e.g., s4U) induced mutation rate. Can vector length num_conds p_old background mutation rate read_lengths Total read length sequencing read (e.g., PE100 reads correspond read_lengths = 200) p_do Rate metabolic label containing reads lost due dropout; must 0 1 noise_deg_a Slope trend relating log10(standardized read counts) log(replicate variability) noise_deg_b Intercept trend relating log10(standardized read counts) log(replicate variability) noise_synth Homoskedastic variability L2FC(ksyn) sd_rep Variance lognormal distribution replicate variability drawn low_L2FC_ks negative L2FC(ksyn) can simulated high_L2FC_ks positive L2FC(ksyn) can simulated num_kd_DE Vector element represents number genes show significant change stability relative reference. 1st entry must 0 definition (since relative reference reference sample unchanged) num_ks_DE num_kd_DE significant changes synthesis rates. scale_factor Factor relating RNA concentration (arbitrary units) average number read counts sim_read_counts Logical; TRUE, read counts simulated coming heterodisperse negative binomial distribution a1 Heterodispersion 1/reads dependence parameter a0 High read depth limit negative binomial dispersion parameter nreads Number reads simulated sim_read_counts FALSE alpha shape1 parameter beta distribution U-contents (probability nucleotide read transcript U) drawn gene. beta shape2 parameter beta distribution U-contents (probability nucleotide read transcript U) drawn gene. STL logical; TRUE, simulation STL-seq rather standard TL-seq experiment. two big changes short read length required (< 60 nt) every read particular feature number Us. one read length simulated simplicity. STL_len Average length simulated STL-seq length. Since Pol II typically pauses 20-60 bases promoter, around 40 lprob_U_sd Standard deviation logit(probability nt U) sequencing read. number Us sequencing read drawn binomial distribution prob drawn logit-Normal distribution logit-sd. lp_sd Standard deviation logit(probability U mutated) U. number mutations given read sum nU Bernoulli random variables, nU number Us, p drawn logit-normal distribution lp_sd standard deviation logit scale.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"list containing simulated bakRData object well list simulated kinetic parameters interest. contents latter list : Effect_sim; Dataframe meant mimic formatting Effect_df part bakRFit(StanFit = TRUE), bakRFit(HybridFit = TRUE) bakRFit(bakRData object) output. Fn_mean_sim; Dataframe meant mimic formatting Regularized_ests part bakRFit(bakRData object) output. Contains information true fraction new simulated condition (mean normal distribution replicate fraction news simulated) Fn_rep_sim; Dataframe meant mimic formatting Fn_Estimates part \\codebakRFit(bakRData object) output. Contains information fraction new simulated feature replicate condition. L2FC_ks_mean; true L2FC(ksyn) feature experimental condition. -th column corresponds L2FC(ksyn) comparing -th condition reference condition (defined 1st condition) 1st column always 0s RNA_conc; average number normalized read counts expected feature sample.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"Simulate_bakRData simulates bakRData object using realistic generative model many adjustable parameters. Average RNA kinetic parameters drawn biologically inspired distributions. Replicate variability simulated drawing feature's fraction new given replicate logit-Normal distribution heteroskedastic variance term average magnitude given chosen read count vs. variance relationship. replicate, feature's ksyn drawn homoskedastic lognormal distribution. Read counts can either set value simulated features can simulated according heterodisperse negative binomial distribution. latter default number Us sequencing read drawn binomial distribution number trials equal read length probability nucleotide U drawn beta distribution. read assigned new old population according Bernoulli distribution p = fraction new. number mutations read drawn one two binomial distributions; read assigned population new RNA, number mutations drawn binomial distribution number trials equal number Us probability mutation = p_new; read assigned population old RNA, number mutations instead drawn binomial distribution number trials probability mutation = p_old. p_new must greater p_old mutations new RNA arise background mutations occur probability p_old well metabolic label induced mutations Simulated read counts treated spike-RPKM normalized, scale factor 1 can applied sample comparing sequencing reads (e.g., performing differential expression analysis). Function simulate bakRData object according realistic generative model","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_bakRData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulating nucleotide recoding data — Simulate_bakRData","text":"","code":"# \\donttest{ # 2 replicate, 2 experimental condition, 1000 gene simulation sim_2reps <- Simulate_bakRData(ngene = 1000, nreps = 2)  # 3 replicate, 2 experimental condition, 1000 gene simulation # with 100 instances of differential degradation kinetics sim_3reps <- Simulate_bakRData(ngene = 1000, num_kd_DE = c(0, 100))  # 2 replicates, 3 experimental condition, 1000 gene simulation # with 100 instances of differential degradation kinetics in the 1st # condition and no instances of differential degradation kinetics in the # 2nd condition sim_3es <- Simulate_bakRData(ngene = 1000,                              nreps = 2,                              num_conds = 3,                              num_kd_DE = c(0, 100, 0))  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"Simulate_relative_bakRData simulates bakRData object. output also includes simulated values kinetic parameters interest.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"","code":"Simulate_relative_bakRData(   ngene,   depth,   num_conds = 2L,   nreps = 3L,   eff_sd = 0.75,   eff_mean = 0,   kdlog_mean = -1.8,   kdlog_sd = 0.65,   kslog_mean = 1,   kslog_sd = 0.65,   tl = 2,   p_new = 0.05,   p_old = 0.001,   read_lengths = 200L,   p_do = 0,   noise_deg_a = -0.3,   noise_deg_b = -1.5,   noise_synth = 0.1,   sd_rep = 0.05,   low_L2FC_ks = -1,   high_L2FC_ks = 1,   num_kd_DE = c(0L, as.integer(rep(round(as.integer(ngene)/2), times =     as.integer(num_conds) - 1))),   num_ks_DE = rep(0L, times = as.integer(num_conds)),   sim_read_counts = TRUE,   a1 = 5,   a0 = 0.01,   nreads = 50L,   alpha = 25,   beta = 75,   STL = FALSE,   STL_len = 40,   lprob_U_sd = 0,   lp_sd = 0 )"},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"ngene Number genes simulate data depth Total number reads simulate num_conds Number experimental conditions (including reference condition) simulate nreps Number replicates simulate eff_sd Effect size; specifically, standard deviation normal distribution non-zero changes logit(fraction new) pulled . eff_mean Effect size mean; mean normal distribution non-zero changes logit(fraction new) pulled . Note, setting 0 mean significant effect sizes 0, exact integer impossible draw continuous random number generator. Setting 0 just means symmetric stabilization destabilization kdlog_mean Degradation rate constants drawn lognormal distribution logmean kdlog_sd Degradation rate constants drawn lognormal distribution logsd kslog_mean Synthesis rate constants drawn lognormal distribution mean kslog_sd Synthesis rate constants drawn lognormal distribution logsd tl metabolic label feed time p_new metabolic label (e.g., s4U) induced mutation rate. Can vector length num_conds p_old background mutation rate read_lengths Total read length sequencing read (e.g., PE100 reads correspond read_lengths = 200) p_do Rate metabolic label containing reads lost due dropout; must 0 1 noise_deg_a Slope trend relating log10(standardized read counts) log(replicate variability) noise_deg_b Intercept trend relating log10(standardized read counts) log(replicate variability) noise_synth Homoskedastic variability L2FC(ksyn) sd_rep Variance lognormal distribution replicate variability drawn low_L2FC_ks negative L2FC(ksyn) can simulated high_L2FC_ks positive L2FC(ksyn) can simulated num_kd_DE Vector element represents number genes show significant change stability relative reference. 1st entry must 0 definition (since relative reference reference sample unchanged) num_ks_DE num_kd_DE significant changes synthesis rates. sim_read_counts Logical; TRUE, read counts simulated coming heterodisperse negative binomial distribution a1 Heterodispersion 1/reads dependence parameter a0 High read depth limit negative binomial dispersion parameter nreads Number reads simulated sim_read_counts FALSE alpha shape1 parameter beta distribution U-contents (probability nucleotide read transcript U) drawn gene. beta shape2 parameter beta distribution U-contents (probability nucleotide read transcript U) drawn gene. STL logical; TRUE, simulation STL-seq rather standard TL-seq experiment. two big changes short read length required (< 60 nt) every read particular feature number Us. one read length simulated simplicity. STL_len Average length simulated STL-seq length. Since Pol II typically pauses 20-60 bases promoter, around 40 lprob_U_sd Standard deviation logit(probability nt U) sequencing read. number Us sequencing read drawn binomial distribution prob drawn logit-Normal distribution logit-sd. lp_sd Standard deviation logit(probability U mutated) U. number mutations given read sum nU Bernoulli random variables, nU number Us, p drawn logit-normal distribution lp_sd standard deviation logit scale.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"list containing simulated bakRData object well list simulated kinetic parameters interest. contents latter list : Effect_sim; Dataframe meant mimic formatting Effect_df part bakRFit(StanFit = TRUE), bakRFit(HybridFit = TRUE) bakRFit(bakRData object) output. Fn_mean_sim; Dataframe meant mimic formatting Regularized_ests part bakRFit(bakRData object) output. Contains information true fraction new simulated condition (mean normal distribution replicate fraction news simulated) Fn_rep_sim; Dataframe meant mimic formatting Fn_Estimates part \\codebakRFit(bakRData object) output. Contains information fraction new simulated feature replicate condition. L2FC_ks_mean; true L2FC(ksyn) feature experimental condition. -th column corresponds L2FC(ksyn) comparing -th condition reference condition (defined 1st condition) 1st column always 0s RNA_conc; average number normalized read counts expected feature sample.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"main difference Simulate_relative_bakRData Simulate_bakRData former requires number genes (ngene) total number reads (depth) set. latter, number genes set, number reads gene simulated matter many genes simulated, number reads given default parameters reflective seen 20,000,000 read human RNA-seq libraries. benefit Simulate_relative_bakRData easier test impact depth model performance. can theoretically done changing synthesis rate constant parameters Simulate_bakRData, relationship parameters sequencing depth unintuitive. benefit Simulate_bakRData fewer genes can simulated still yielding reasonable per-gene coverage without figuring total depth small gene subset . nice testing bakR analysis tools small datasets. Simulate_relative_bakRData realistic simulation better accounts relative nature RNA-seq read counts (.e., expected number reads given feature related proportion RNA molecules coming feature). Another difference Simulate_relative_bakRData Simulate_bakRData Simulate_relative_bakRData uses label time simulated degradation rate constants infer fraction new, whereas Simulate_bakRData uses simulated fraction news label time infer degradation rate constants. Thus, Simulate_relative_bakRData preferable assessing impact label time model performance (since realistic impact fraction new, distribution fraction news major impact model performance). Similarly, Simulate_bakRData preferable directly assessing impact fraction news model performance, without think label time simulated degradation rate constant distribution. investigating dropout, Simulate_relative_bakRData used, accurate simulation read counts function relative abundance RNA feature crucial accurately simulate dropout. Function simulate bakRData object according realistic generative model","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/Simulate_relative_bakRData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulating nucleotide recoding data with relative count data — Simulate_relative_bakRData","text":"","code":"# \\donttest{ # 2 replicate, 2 experimental condition, 1000 gene simulation sim_2reps <- Simulate_relative_bakRData(ngene = 1000, depth = 100000,                                nreps = 2)  # 3 replicate, 2 experimental condition, 1000 gene simulation # with 100 instances of differential degradation kinetics sim_3reps <- Simulate_relative_bakRData(ngene = 1000, depth = 100000,                                         num_kd_DE = c(0, 100))  # 2 replicates, 3 experimental condition, 1000 gene simulation # with 100 instances of differential degradation kinetics in the 1st # condition and no instances of differential degradation kinetics in the # 2nd condition sim_3es <- Simulate_relative_bakRData(ngene = 1000, depth = 100000,                              nreps = 2,                              num_conds = 3,                              num_kd_DE = c(0, 100, 0))  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/TL_stan.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","title":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","text":"TL_stan internal function analyze nucleotide recoding RNA-seq data fully Bayesian hierarchical model implemented PPL Stan. TL_stan estimates kinetic parameters differences kinetic parameters experimental conditions. assessing differences, single reference sample compared collection experimental samples provided.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/TL_stan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","text":"","code":"TL_stan(   data_list,   Hybrid_Fit = FALSE,   keep_fit = FALSE,   NSS = FALSE,   chains = 1,   ... )"},{"path":"https://simonlabcode.github.io/bakR/reference/TL_stan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","text":"data_list List pass 'Stan' form given cBprocess Hybrid_Fit Logical; TRUE, Hybrid 'Stan' model takes data output fast_analysis run. keep_fit Logical; TRUE, 'Stan' fit object included output; typically large file default FALSE. NSS Logical; TRUE, models directly compare logit(fn)s used avoid steady-state assumption chains Number Markov chains sample . default run single chain. Typical NR-seq datasets yield memory intensive analyses, running single chain decrease burden. reference, running MCMC implementation (Hybrid_Fit = FALSE) 3 chains NR-seq dataset 3 replicates 2 experimental conditions around 20 million raw (unmapped) reads per sample requires 100 GB RAM. single chain, burden drops around 20 GB. Due memory demands time constraints (runtimes MCMC implementation border likely around 1-2 days) means models usually run specialized High Performance Computing (HPC) system. ... Arguments passed rstan::sampling (e.g. iter, warmup, etc.).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/TL_stan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","text":"list objects: Effects_df; dataframe estimates effect size (change logit(fn)) comparing experimental condition reference sample feature. dataframe also includes p-values obtained moderated t-test. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) L2FC_kdeg; L2FC(kdeg) posterior mean L2FC_kd_sd; L2FC(kdeg) posterior sd effect; identical L2FC_kdeg (kept symmetry MLE fit output) se; identical L2FC_kd_sd (kept symmetry MLE fit output) XF; Feature name pval; p value obtained effect se + z-test padj; p value adjusted multiple testing using Benjamini-Hochberg procedure Kdeg_df; dataframe estimates kdeg (RNA degradation rate constant) feature, averaged across replicate data. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition kdeg; Degradation rate constant posterior mean kdeg_sd; Degradation rate constant posterior standard deviation log_kdeg; Log degradation rate constant posterior mean (version 1.0.0) log_kdeg_sd; Log degradation rate constant posterior standard deviation (version 1.0.0) XF; Original feature name Fn_Estimates; dataframe estimates logit(fraction new) feature replicate. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) Replicate; Numerical ID replicate logit_fn; Logit(fraction new) posterior mean logit_fn_se; Logit(fraction new) posterior standard deviation sample; Sample name XF; Original feature name Fit_Summary; outputted keep_fit == FALSE. Summary 'Stan' fit object row corresponding particular parameter. posterior point descriptions descriptions marginal posterior distribution parameter row. example, posterior mean average value parameter averaging parameter values. columns dataframe : mean; Posterior mean parameter given row name se_mean; Standard error posterior mean; essentially confident model estimates posterior mean posterior mean actually . depend number chains run number iterations chain run . sd; Posterior standard deviation 2.5%; 2.5th percentile posterior distribution. 2.5% posterior mass point 25%; 25th percentile posterior distribution 50%; 50th percentile posterior distribution 75%; 75th percentile posterior distribution 97.5%; 97.5th percentile posterior distribution n_eff; Effective sample size. larger better, though preferably around total number iterations (iter x chains). Small values represent poor model convergence Rhat; Describes well separate Markov chains mixed. preferably close 1 possible, values higher 1 represent poor model convergence Stan_Fit; outputted keep_fit == TRUE. full 'Stan' fit object, R6 object class stanfit Mutation_Rates; data frame information mutation rate estimates. columns Fit_Summary. row corresponds either background mutation rate (log_lambda_o) s4U induced mutation rate (log_lambda_n), denoted parameter column. bracketed portion parameter name contain two numbers. first corresponds Exp_ID second corresponds Replicate_ID. example, parameter name log_lambda_o[1,2] row corresponds background mutation rate second replicate experimental condition one. final point mention estimates log(avg. # mutations) scale. log_lambda_n 1 means average, estimated 2.72 (exp(1)) mutations reads new RNA (.e., RNA synthesized s4U labeling).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/TL_stan.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit 'Stan' models to nucleotide recoding RNA-seq data analysis — TL_stan","text":"Two implementations similar model can fit TL_stan: complete nucleotide recoding RNA-seq analysis hybrid analysis takes input results fast_analysis. complete analysis (referred bakR publication MCMC implementation), U--C mutations modeled coming Poisson distribution rate parameter adjusted empirical U-content feature analyzed. Features represent whatever user defined constructing bakR data object. Typical feature categories genes, exons, etc. Hierarchical modeling used pool data across replicates across features. specifically, replicate data feature partially pooled estimate feature-specific mean fraction news uncertainties. Feature means partially pooled estimate dataset-wide mean fraction news standard deviations. replicate variability feature also partially pooled determine condition-wide heteroskedastic relationship read depths replicate variability. Partial pooling reduces subjectivity determining priors allowing model determine priors make sense given data. Partial pooling also regularizes estimates, reducing estimate variability thus increasing estimate accuracy. particularly important replicate variability estimates, often rely replicates data per feature thus typically highly unstable. hybrid analysis (referred bakR publication Hybrid implementation) inherits hierarchical modeling structure complete analysis, reduces computational burden foregoing per-replicate--feature fraction new estimation uncertainty quantification. Instead, hybrid analysis takes data fraction new estimates approximate uncertainties fast_analysis. Runtimes hybrid analysis thus often order magnitude shorter complete analysis, loses accuracy relying point estimates uncertainty quantification valid limit large dataset sizes (dataset size per-replicate--feature fraction new estimate raw number sequencing reads mapping feature replicate). Users also option save discard Stan fit object. Fit objects can exceedingly large (> 10 GB) nucleotide recoding RNA-seq datasets. Therefore, want store large object, summary object saved instead, greatly reduces size output (~ 10-50 MB) still retaining much important information. addition, output TL_stan provides estimates uncertainties key parameters (L2FC(kdeg), kdeg, fraction new) likely interest. said, analyses possible original fit object saved. example, fit object contain samples posterior collected model fitting. Thus, new parameters (e.g., L2FC(kdeg)'s comparing two experimental samples) naturally generated model can estimated post-hoc. Still, often approximate estimates can obtained parameters rely full fit object. One analysis impossible without original fit object generating model diagnostic plots. include trace plots (show mixing efficient parameter space exploration Markov chains), pairs plots (show correlations parameters divergences occurred), visualizations can help users assess well model ran. models implemented TL_stan extensively validated, less likely diagnostics helpful, often anomalies data can lead poor model convergence, case assessing model diagnostics can help identify source problems data. Summary statistics describing well model able estimate parameter (n_eff rhat) provided fit summaries, can often obscure nuanced details model fitting.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/VisualizeDropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize dropout — VisualizeDropout","title":"Visualize dropout — VisualizeDropout","text":"VisualizeDropout fits dropout model QuantifyDropout, reports fit results, generates ggplot object showing data used infer fit well fitted nonlinear trend.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/VisualizeDropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize dropout — VisualizeDropout","text":"","code":"VisualizeDropout(obj, keep_data = FALSE, no_message = FALSE)"},{"path":"https://simonlabcode.github.io/bakR/reference/VisualizeDropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize dropout — VisualizeDropout","text":"obj bakRFit bakRFnFit object keep_data Logical; TRUE, return data used make plots along plots no_message Logical; TRUE, output message regarding estimated rates dropout sample","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/VisualizeDropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize dropout — VisualizeDropout","text":"keep_data FALSE, list ggplot objects returned, one +s4U sample. plots show relationship feature's fraction new difference +s4U -s4U read coverage. Nonlinear-least squares fit plotted top points blue line. keep_data TRUE, data used make plots returned addition list plots.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/VisualizeDropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize dropout — VisualizeDropout","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates with 40% dropout sim <- Simulate_relative_bakRData(500, 100000, nreps = 2, p_do = 0.4)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0512 0.000988 #> 2     1     2 0.0504 0.000988 #> 3     2     1 0.0506 0.000988 #> 4     2     2 0.0495 0.000988 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Quantify dropout DO_plots <- VisualizeDropout(Fit) #> Estimated rates of dropout are: #>   Exp_ID Replicate       pdo #> 1      1         1 0.2109700 #> 2      1         2 0.0000000 #> 3      2         1 0.3397387 #> 4      2         2 0.3394127  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/avg_and_regularize.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","title":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","text":"avg_and_regularize pools regularizes replicate estimates kinetic parameters. two key steps downstream analysis. 1st, uncertainty feature used fit linear ln(uncertainty) vs. log10(read depth) trend, uncertainties individual features shrunk towards regression line. uncertainty feature combination Fisher Information asymptotic uncertainty well amount variability seen estimates. Regularization uncertainty estimates performed using analytic results Normal distribution likelihood known mean unknown variance conjugate priors. prior parameters estimated regression amount variability regression line. strength regularization can tuned adjusting prior_weight parameter, larger numbers yielding stronger shrinkage towards regression line. 2nd step regularize average kdeg estimates. done using analytic results Normal distribution likelihood model unknown mean known variance conjugate priors. prior parameters estimated population wide kdeg distribution (using mean standard deviation mean standard deviation normal prior). 1st step, known mean assumed average kdeg, averaged across replicates weighted number reads mapping feature replicate. 2nd step, known variance assumed obtained following regularization uncertainty estimates.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/avg_and_regularize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","text":"","code":"avg_and_regularize(   Mut_data_est,   nreps,   sample_lookup,   feature_lookup,   nbin = NULL,   NSS = FALSE,   Chase = FALSE,   BDA_model = FALSE,   null_cutoff = 0,   Mutrates = NULL,   ztest = FALSE )"},{"path":"https://simonlabcode.github.io/bakR/reference/avg_and_regularize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","text":"Mut_data_est Dataframe fraction new estimation information. Required columns : fnum; numerical ID feature reps; numerical ID replicate mut; numerical ID experimental condition (Exp_ID) logit_fn_rep; logit(fn) estimate kd_rep_est; kdeg estimate log_kd_rep_est; log(kdeg) estimate logit_fn_se; logit(fn) estimate uncertainty log_kd_se; log(kdeg) estimate uncertainty nreps Vector number replicates experimental condition sample_lookup Dictionary mapping sample names various experimental details feature_lookup Dictionary mapping feature IDs original feature names nbin Number bins mean-variance relationship estimation. NULL, max 10 (number logit(fn) estimates)/100 used NSS Logical; TRUE, logit(fn)s compared rather log(kdeg) avoid steady-state assumption. Chase Logical; Set TRUE analyzing pulse-chase experiment. TRUE, kdeg = -ln(fn)/tl fn fraction reads s4U (properly referred fraction old context pulse-chase experiment) BDA_model Logical; TRUE, variance regularized scaled inverse chi-squared model. Otherwise log-normal model used. null_cutoff bakR test null hypothesis |effect size| < |null_cutoff| Mutrates List containing new old mutation rate estimates ztest TRUE; TRUE, z-test used p-value calculation rather conservative moderated t-test.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/avg_and_regularize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","text":"List dataframes providing information replicate-specific pooled analysis results. output includes: Fn_Estimates; dataframe estimates fraction new fraction new uncertainty feature replicate. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) Replicate; Numerical ID replicate logit_fn; logit(fraction new) estimate, unregularized logit_fn_se; logit(fraction new) uncertainty, unregularized obtained Fisher Information nreads; Number reads mapping feature sample estimates obtained log_kdeg; log degradation rate constant (kdeg) estimate, unregularized kdeg; degradation rate constant (kdeg) estimate log_kd_se; log(kdeg) uncertainty, unregularized obtained Fisher Information sample; Sample name XF; Original feature name Regularized_ests; dataframe average fraction new kdeg estimates, averaged across replicates regularized using priors informed entire dataset. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) avg_log_kdeg; Weighted average log(kdeg) replicate, weighted sample feature-specific read depth sd_log_kdeg; Standard deviation log(kdeg) estimates nreads; Total number reads mapping feature condition sdp; Prior standard deviation fraction new estimate regularization theta_o; Prior mean fraction new estimate regularization sd_post; Posterior uncertainty log_kdeg_post; Posterior mean log(kdeg) estimate kdeg; exp(log_kdeg_post) kdeg_sd; kdeg uncertainty XF; Original feature name Effects_df; dataframe estimates effect size (change logit(fn)) comparing experimental condition reference sample feature. dataframe also includes p-values obtained moderated t-test. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) L2FC(kdeg); Log2 fold change (L2FC) kdeg estimate change logit(fn) NSS TRUE effect; LFC(kdeg) se; Uncertainty L2FC_kdeg pval; P-value obtained using effect_size, se, z-test padj; pval adjusted multiple testing using Benjamini-Hochberg procedure XF; Original feature name Mut_rates; list two elements. 1st element dataframe s4U induced mutation rate estimates, mut column represents experimental ID rep column represents replicate ID. 2nd element single background mutation rate estimate used Hyper_Parameters; vector two elements, named b. hyperparameters estimated uncertainties feature, represent two parameters Scaled Inverse Chi-Square distribution. Importantly, number additional degrees freedom provided sharing uncertainty information across dataset, used moderated t-test. Mean_Variance_lms; linear model objects obtained uncertainty vs. read count regression model. One model run Exp_ID","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/avg_and_regularize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficiently average replicates of nucleotide recoding data and regularize — avg_and_regularize","text":"Effect sizes (changes kdeg) obtained difference log(kdeg) means reference experimental sample(s), log(kdeg)s assumed independent variance effect size sum log(kdeg) variances. P-values assessing significance effect size obtained using moderated t-test number degrees freedom determined uncertainty regression hyperparameters adjusted multiple testing using Benjamini- Hochberg procedure control false discovery rates (FDRs). cases, assumed ODE model RNA metabolism accurately model dynamics biological system analyzed. cases, best compare logit(fraction new)s directly rather converting fraction new log(kdeg). analysis strategy implemented NSS set TRUE. Comparing logit(fraction new) valid single metabolic label time used samples. example, label time 1 hour used NR-seq data WT cells 2 hour label time used KO cells, comparison longer valid differences logit(fraction new) stem differences kinetics label times.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'bakR' package. — bakR-package","title":"The 'bakR' package. — bakR-package","text":"DESCRIPTION PACKAGE","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakR-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The 'bakR' package. — bakR-package","text":"Stan Development Team (2020). RStan: R interface Stan. R package version 2.21.2. https://mc-stan.org","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakR Data object helper function for users — bakRData","title":"bakR Data object helper function for users — bakRData","text":"function creates object class bakRData","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakR Data object helper function for users — bakRData","text":"","code":"bakRData(cB, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/bakRData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakR Data object helper function for users — bakRData","text":"cB Dataframe columns corresponding feature ID, number Ts, number mutations, sample ID, number identical observations metadf Dataframe detailing s4U label time experimental ID sample","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"bakR Data object helper function for users — bakRData","text":"bakRData object. two components: data frame describing experimental details (metadf) data frame containing NR-seq data (cB).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bakR Data object helper function for users — bakRData","text":"","code":"# Load cB data(\"cB_small\")  # Load metadf data(\"metadf\")  # Create bakRData object bakRData <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"bakRFit analyzes nucleotide recoding RNA-seq data estimate kinetic parameters relating RNA stability changes RNA stability induced experimental perturbations. Several statistical models varying efficiency accuracy can used fit data.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"","code":"bakRFit(   obj,   StanFit = FALSE,   HybridFit = FALSE,   high_p = 0.2,   totcut = 50,   totcut_all = 10,   Ucut = 0.25,   AvgU = 4,   FastRerun = FALSE,   FOI = c(),   concat = TRUE,   StanRateEst = FALSE,   RateEst_size = 30,   low_reads = 100,   high_reads = 5e+05,   chains = 1,   NSS = FALSE,   Chase = FALSE,   BDA_model = FALSE,   multi_pold = FALSE,   Long = FALSE,   kmeans = FALSE,   ztest = FALSE,   Fisher = TRUE,   ... )"},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"obj bakRData object produced bakRData, bakRFit object produced bakRFit bakRFnData object produced bakRFnData, bakRFnFit object produced bakRFit. StanFit Logical; TRUE, MCMC implementation run. used obj bakRFit object HybridFit Logical; TRUE, Hybrid implementation run. used obj bakRFit object high_p Numeric; features mutation rate (number mutations / number Ts reads) higher -s4U control samples (.e., samples treated s4U) filtered totcut Numeric; features less number sequencing reads replicate experimental conditions filtered totcut_all Numeric; features less number sequencing reads sample filtered Ucut Numeric; features must fraction reads 2 less Us less cutoff samples AvgU Numeric; features must average number Us greater cutoff samples FastRerun Logical; matters bakRFit object passed bakRFit. TRUE, Stan-free model implemented fast_analysis rerun data, foregoing fitting either 'Stan' models. FOI Features interest; character vector containing names features analyze concat Logical; TRUE, FOI concatenated output reliableFeatures StanRateEst Logical; TRUE, simple 'Stan' model used estimate mutation rates fast_analysis; may add couple minutes runtime analysis. RateEst_size Numeric; StanRateEst TRUE, data RateEst_size genes used mutation rate estimation. can low 1 kept low ensure maximum efficiency low_reads Numeric; StanRateEst TRUE, features low_reads reads samples used mutation rate estimation high_reads Numeric; StanRateEst TRUE, features less high_read reads samples used mutation rate estimation. high read count cutoff important low read count cutoff case want fraction labeled chosen features extreme (e.g., close 0 1), high read count features likely low fraction new features. chains Number Markov chains sample . 1 suffice since validated models. Running chains generally preferable, memory constraints can make unfeasible. NSS Logical; TRUE, logit(fn)s directly compared avoid assuming steady-state Chase Logical; Set TRUE analyzing pulse-chase experiment. TRUE, kdeg = -ln(fn)/tl fn fraction reads s4U (properly referred fraction old context pulse-chase experiment). BDA_model Logical; TRUE, variance regularized scaled inverse chi-squared model. Otherwise log-normal model used. multi_pold Logical; TRUE, pold estimated sample rather use global pold estimate. Long Logical; TRUE, long read optimized fraction new estimation strategy used. kmeans Logical; TRUE, kmeans clustering read-specific mutation rates used estimate pnews pold. ztest Logical; TRUE MLE implementation used, z-test used p-value calculation rather conservative moderated t-test. Fisher Logical; TRUE, Fisher information used estimate logit(fn) uncertainty. Else, less conservative binomial model used, can preferable instances Fisher information strategy often drastically overestimates uncertainty (.e., low coverage low pnew). ... Arguments passed either fast_analysis (bakRData object) TL_Stan Hybrid_fit (bakRFit object)","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"bakRFit object results statistical modeling data processing. Objects possibly included : Fast_Fit; Always present. Output fast_analysis Hybrid_Fit; present HybridFit = TRUE. Output TL_stan Stan_Fit; present StanFit = TRUE. Output TL_stan Data_lists; Always present. Output cBprocess Fast Stan == TRUE","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"bakRFit run bakRData object, cBprocess fast_analysis always called. former generate processed data can passed model fitting functions (fast_analysis TL_Stan). call fast_analysis generate list dataframes containing information regarding fast_analysis fit. fast_analysis always called output required Hybrid_fit TL_Stan. bakRFit run bakRFit object, cBprocess called , output cBprocess already contained bakRFit object. Similarly, fast_analysis called unless bakRFit rerun bakRData object. FastRerun set TRUE. want generate model fits using different parameters cBprocess, rerun bakRFit bakRData object. bakRFit run bakRFnData object, fn_process avg_and_regularize always called. former generate processed data can passed model fitting functions (avg_and_regularize TL_Stan, latter HybridFit = TRUE). bakRFit run bakRFnFit object. fn_process called , output fn_process already contained bakRFnFit object. Similary, avg_and_regularize called unless bakRFit rerun bakRData object, FastRerun set TRUE. want generate model fits using different parameters fn_process, rerun bakRFit bakRData object. See documentation individual fitting functions details regarding analyze nucleotide recoding data. follows brief overview works fast_analysis (referred MLE implementation bakR paper) either estimates mutation rates + (available) - s4U samples uses mutation rate estimates provided user perform maximum likelihood estimation (MLE) fraction RNA labeled replicate nucleotide recoding data provided. Uncertainties replicate's estimate approximated using asymptotic results involving Fisher Information assuming known mutation rates. Replicate data pooled using approximation hierarchical modeling relies analytic solutions simple Bayesian models. Linear regression used estimate relationship read depths replicate variability uncertainty estimation regularization, performed using analytic solutions Bayesian models. TL_Stan Hybrid_Fit set TRUE (referred Hybrid implementation bakR paper) takes input estimates logit(fraction new) uncertainty provided fast_analysis. uses 'Stan' backend implement hierarchical model pools data across replicates dataset estimate effect sizes (L2FC(kdeg)) uncertainties. Replicate variability information pooled across experimental condition regularize variance estimates using hierarchical linear regression model. default behavior TL_Stan (referred MCMC implementation bakR paper) use 'Stan' back end implement U-content exposure adjusted Poisson mixture model estimate fraction news mutational data. Partial pooling replicate variability estimates performed Hybrid implementation.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating kinetic parameters from nucleotide recoding RNA-seq data — bakRFit","text":"","code":"# \\donttest{ # Simulate data for 1000 genes, 2 replicates, 2 conditions simdata <- Simulate_bakRData(1000, nreps = 2)  # You always must fit fast implementation before any others Fit <- bakRFit(simdata$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0500 0.000996 #> 2     1     2 0.0499 0.000996 #> 3     2     1 0.0501 0.000996 #> 4     2     2 0.0498 0.000996 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # }"},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFnData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakRFnData object helper function for users — bakRFnData","title":"bakRFnData object helper function for users — bakRFnData","text":"function creates object class bakRFnData","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFnData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakRFnData object helper function for users — bakRFnData","text":"","code":"bakRFnData(fns, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFnData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakRFnData object helper function for users — bakRFnData","text":"fns Dataframe columns corresponding sample names (sample), feature IDs (XF), fraction new estimates (fn), number sequencing reads (nreads). fns can optionally contain column fraction new estimate uncertainties (se). metadf Dataframe detailing s4U label time experimental ID sample. Identical bakRData input","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFnData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"bakRFnData object helper function for users — bakRFnData","text":"bakRFnData object. two components: data frame describing experimental details (metadf) data frame containing fraction new estimates (fns).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/bakRFnData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bakRFnData object helper function for users — bakRFnData","text":"","code":"### NEED TO ADD EXAMPLE DATA # Load cB data(\"cB_small\")  # Load metadf data(\"metadf\")  # Create bakRData object bakRData <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/cB_small.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cB data frame — cB_small","title":"Example cB data frame — cB_small","text":"Subset cB file DCP2 dataset published Luo et al. 2020. original file large (69 MB), example cB file downsampled contains 10 genes (rather 25012). columns described Getting_Started vignette.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cB_small.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cB data frame — cB_small","text":"","code":"data(cB_small)"},{"path":"https://simonlabcode.github.io/bakR/reference/cB_small.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example cB data frame — cB_small","text":"dataframe 5788 rows 5 variables; row corresponds group sequencing reads sample Sample name TC Number T--C mutations nT Number Ts XF Name feature group reads map; usually gene name n Number identical sequencing reads","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cB_small.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Example cB data frame — cB_small","text":"Luo et al. (2020) Biochemistry. 59(42), 4121-4142","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cB_small.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example cB data frame — cB_small","text":"","code":"data(cB_small) data(metadf) bakRdat <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Curate data in bakRData object for statistical modeling — cBprocess","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"cBprocess creates data structures necessary analyze nucleotide recoding RNA-seq data statistical model implementations bakRFit. input cBprocess must object class bakRData.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"","code":"cBprocess(   obj,   high_p = 0.2,   totcut = 50,   totcut_all = 10,   Ucut = 0.25,   AvgU = 4,   Stan = TRUE,   Fast = TRUE,   FOI = c(),   concat = TRUE )"},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"obj object class bakRData high_p Numeric; transcripts mutation rate (number mutations / number Ts reads) higher s4U control samples filtered totcut Numeric; transcripts less number sequencing reads replicate experimental conditions filtered totcut_all Numeric; transcripts less number sequencing reads sample filtered Ucut Numeric; transcripts must fraction reads 2 less Us less cutoff samples AvgU Numeric; transcripts must average number Us greater cutoff samples Stan Boolean; TRUE, data_list can passed 'Stan' curated Fast Boolean; TRUE, dataframe can passed fast_analysis() curated FOI Features interest; character vector containing names features analyze. FOI non-null concat TRUE, minimally reliable FOIs combined reliable features passing set filters (high_p, totcut, totcut_all, Ucut, AvgU). concat FALSE, minimally reliable FOIs kept. minimally reliable FOI one passes filtering minimally stringent parameters. concat Boolean; TRUE, FOI concatenated output reliableFeatures","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"returns list objects can passed TL_stan /fast_analysis. objects : Stan_data; list can passed TL_stan Hybrid_Fit = FALSE. Consists metadata well data 'Stan' analyze. Data analyzed consists equal length vectors. contents Stan_data : NE; Number datapoints 'Stan' analyze (NE = Number Elements) NF; Number features dataset TP; Numerical indicator s4U feed (0 = s4U feed, 1 = s4U fed) FE; Numerical indicator feature num_mut; Number U--C mutations observed particular set reads MT; Numerical indicator experimental condition (Exp_ID metadf) nMT; Number experimental conditions R; Numerical indicator replicate nrep; Number replicates (analysis requires number replicates conditions) num_obs; Number reads identical data (number mutations, feature origin, sample origin) tl; Vector label times experimental condition U_cont; Log2-fold-difference U-content feature sample relative average U-content sample Avg_Reads; Standardized log10(average read counts) particular feature particular condition, averaged replicates Avg_Reads_natural; Unstandardized average read counts particular feature particular condition, averaged replicates. Used plotMA sdf; Dataframe maps numerical feature ID original feature name. Also read depth information sample_lookup; Lookup table relating MT R original sample name Fast_df; data frame can passed fast_analysis. contents Fast_df : sample; Original sample name XF; Original feature name TC; Number T C mutations nT; Number Ts read n; Number identical observations fnum; Numerical indicator feature type; Numerical indicator s4U feed (0 = s4U feed, 1 = s4U fed) mut; Numerical indicator experimental condition (Exp_ID metadf) reps; Numerical indicator replicate Count_Matrix; matrix read count information. column represents sample row represents feature. entry raw number read counts mapping particular feature particular sample. Column names corresponding sample names row names corresponding feature names.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"1st step executed cBprocess find names features deemed \"reliable\". reliable feature one sufficient read coverage every single sample (.e., > totcut_all reads samples), sufficient read coverage replicates least one experimental condition (.e., > totcut reads replicates one experimental conditions) limited mutation content -s4U control samples (.e., < high_p mutation rate samples lacking s4U feeds). addition, analyzing short read sequencing data, two additional definitons reliable features become pertinent: fraction reads can 2 less Us sample (Ucut) minimum average number Us feature's reads sample (AvgU). done call reliableFeatures. 2nd step extract reliableFeatures cB dataframe bakRData object. process, numerical ID given reliableFeature, numerical ID corresponding order arranged using dplyr::arrange. 3rd step prepare dataframe row corresponds set n identical reads (come sample number mutations Us). Part process involves assigning arbitrary numerical ID replicate experimental condition. numerical ID correspond order sample appears metadf. outcome step multiple dataframes variable information content. include dataframe information read counts sample, one logs U-contents feature, one compatible fast_analysis thus groups reads number mutations well number Us, one compatible TL_stan StanFit == TRUE thus groups ready number mutations. end step, two smaller data structures created, one average count matrix (count matrix ith row jth column corresponds average number reads mappin feature experimental condition j, averaged replicates) sample lookup table relates numerical experimental replicate IDs original sample name.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/cBprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Curate data in bakRData object for statistical modeling — cBprocess","text":"","code":"# \\donttest{  # Load cB data(\"cB_small\")  # Load metadf data(\"metadf\")  # Create bakRData bakRData <- bakRData(cB_small, metadf)  # Preprocess data data_for_bakR <- cBprocess(obj = bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... # }"},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficiently analyze nucleotide recoding data — fast_analysis","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"fast_analysis analyzes nucleotide recoding data maximum likelihood estimation implemented stats::optim combined analytic solutions simple Bayesian models perform approximate partial pooling. Output includes kinetic parameter estimates replicate, kinetic parameter estimates averaged across replicates, log-2 fold changes degradation rate constant (L2FC(kdeg)). Averaging takes account uncertainties estimated using Fisher Information estimates regularized using analytic solutions fully Bayesian models. result kdegs shrunk towards population means uncertainties shrunk towards mean-variance trend estimated part analysis.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"","code":"fast_analysis(   df,   pnew = NULL,   pold = NULL,   no_ctl = FALSE,   read_cut = 50,   features_cut = 50,   nbin = NULL,   prior_weight = 2,   MLE = TRUE,   ztest = FALSE,   lower = -7,   upper = 7,   se_max = 2.5,   mut_reg = 0.1,   p_mean = 0,   p_sd = 1,   StanRate = FALSE,   Stan_data = NULL,   null_cutoff = 0,   NSS = FALSE,   Chase = FALSE,   BDA_model = FALSE,   multi_pold = FALSE,   Long = FALSE,   kmeans = FALSE,   Fisher = TRUE )"},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"df Dataframe form provided cB_to_Fast pnew Labeled read mutation rate; default 0 means model estimates rate s4U fed data. pnew provided user, must  vector length == number s4U fed samples. 1st element corresponds s4U induced mutation rate estimate 1st replicate 1st experimental condition; 2nd element corresponds s4U induced mutation rate estimate 2nd replicate 1st experimental condition, etc. pold Unlabeled read mutation rate; default 0 means model estimates rate -s4U fed data no_ctl Logical; TRUE, -s4U control used background mutation rate estimation read_cut Minimum number reads given feature-sample combo used mut rate estimates features_cut Number features estimate sample specific mutation rate nbin Number bins mean-variance relationship estimation. NULL, max 10 (number logit(fn) estimates)/100 used prior_weight Determines extent logit(fn) variance regularized mean-variance regression line MLE Logical; TRUE replicate logit(fn) estimated using maximum likelihood; FALSE conservative Bayesian hypothesis testing used ztest TRUE; TRUE, z-test used p-value calculation rather conservative moderated t-test. lower Lower bound MLE L-BFGS-B algorithm upper Upper bound MLE L-BFGS-B algorithm se_max Uncertainty given transcripts estimates upper lower bound sets. prevents downstream errors due abnormally high standard errors due transcripts extreme kinetics mut_reg MLE instabilities, empirical mut rate used estimate fn, multiplying pnew 1+mut_reg pold 1-mut_reg regularize fn p_mean Mean normal distribution used prior penalty MLE logit(fn) p_sd Standard deviation normal distribution used prior penalty MLE logit(fn) StanRate Logical; TRUE, simple 'Stan' model used estimate mutation rates fast_analysis; may add couple minutes runtime analysis. Stan_data List; StanRate TRUE, data passed 'Stan' model estimate mutation rates. using bakRFit wrapper fast_analysis, created automatically. null_cutoff bakR test null hypothesis |effect size| < |null_cutoff| NSS Logical; TRUE, logit(fn)s compared rather log(kdeg) avoid steady-state assumption. Chase Logical; Set TRUE analyzing pulse-chase experiment. TRUE, kdeg = -ln(fn)/tl fn fraction reads s4U (properly referred fraction old context pulse-chase experiment) BDA_model Logical; TRUE, variance regularized scaled inverse chi-squared model. Otherwise log-normal model used. multi_pold Logical; TRUE, pold estimated sample rather use global pold estimate. Long Logical; TRUE, long read optimized fraction new estimation strategy used. kmeans Logical; TRUE, kmeans clustering read-specific mutation rates used estimate pnews pold. Fisher Logical; TRUE, Fisher information used estimate logit(fn) uncertainty. Else, less conservative binomial model used, can preferable instances Fisher information strategy often drastically overestimates uncertainty (.e., low coverage low pnew).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"List dataframes providing information replicate-specific pooled analysis results. output includes: Fn_Estimates; dataframe estimates fraction new fraction new uncertainty feature replicate. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) Replicate; Numerical ID replicate logit_fn; logit(fraction new) estimate, unregularized logit_fn_se; logit(fraction new) uncertainty, unregularized obtained Fisher Information nreads; Number reads mapping feature sample estimates obtained log_kdeg; log degradation rate constant (kdeg) estimate, unregularized kdeg; degradation rate constant (kdeg) estimate log_kd_se; log(kdeg) uncertainty, unregularized obtained Fisher Information sample; Sample name XF; Original feature name Regularized_ests; dataframe average fraction new kdeg estimates, averaged across replicates regularized using priors informed entire dataset. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) avg_log_kdeg; Weighted average log(kdeg) replicate, weighted sample feature-specific read depth sd_log_kdeg; Standard deviation log(kdeg) estimates nreads; Total number reads mapping feature condition sdp; Prior standard deviation fraction new estimate regularization theta_o; Prior mean fraction new estimate regularization sd_post; Posterior uncertainty log_kdeg_post; Posterior mean log(kdeg) estimate kdeg; exp(log_kdeg_post) kdeg_sd; kdeg uncertainty XF; Original feature name Effects_df; dataframe estimates effect size (change logit(fn)) comparing experimental condition reference sample feature. dataframe also includes p-values obtained moderated t-test. columns dataframe : Feature_ID; Numerical ID feature Exp_ID; Numerical ID experimental condition (Exp_ID metadf) L2FC(kdeg); Log2 fold change (L2FC) kdeg estimate change logit(fn) NSS TRUE effect; LFC(kdeg) se; Uncertainty L2FC_kdeg pval; P-value obtained using effect_size, se, z-test padj; pval adjusted multiple testing using Benjamini-Hochberg procedure XF; Original feature name Mut_rates; list two elements. 1st element dataframe s4U induced mutation rate estimates, mut column represents experimental ID rep column represents replicate ID. 2nd element single background mutation rate estimate used Hyper_Parameters; vector two elements, named b. hyperparameters estimated uncertainties feature, represent two parameters Scaled Inverse Chi-Square distribution. Importantly, number additional degrees freedom provided sharing uncertainty information across dataset, used moderated t-test. Mean_Variance_lms; linear model objects obtained uncertainty vs. read count regression model. One model run Exp_ID","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"Unless user supplies estimates pnew pold, first step fast_analysis estimate background (pold) metabolic label (refer s4U simplicity, though bakR compatible metabolic labels s6G) induced (pnew) mutation rates. Several pnew pold estimation strategies implemented bakR. pnew estimation, two strategies likelihood maximization binomial mixture model (default) sampling full posterior U-content adjusted Poisson mixture model HMC (StanRateEst set TRUE bakRFit). default pnew estimation strategy involves combining mutational data features sample-wide mutational data vectors (# T--C conversions, # Ts, # reads vectors). data vectors downsampled (prevent float overflow) used maximize likelihood two-component binomial mixture model. two components correspond reads old new RNA, three estimated paramters fraction reads new (nuisance parameter case), old new read mutation rates. alternative strategy involves running fully Bayesian implementation similar mixture model using Stan, probalistic programming language bakR makes use several functions. strategy can yield accurate mutation rate estimates label times much shorter longer average half-lives sequenced RNA (.e., fraction news mostly close 0 1, respectively). improve efficiency approach, small subset RNA features analyzed, number set RateEst_size parameter bakRFit. default, number set 30, average NR-seq dataset yields several minute runtime mutation rate estimation. Estimation pold can performed three strategies: two strategies discussed pnew estimation, third strategy relies presence -s4U control data. -s4U control data present, default pold estimation strategy use average mutation rate reads -s4U control datasets global pold estimate. Thus, single pold estimate used samples. likelihood maximization strategy can used setting no_ctl TRUE, strategy becomes default strategy -s4U data present. addition, version 1.0.0 bakR (released late June 2023), users can decide estimate pold +s4U sample independently setting multi_pold TRUE. case, independent -s4U datasets can longer used mutation rate estimation purposes, thus strategies pold estimation identical set pnew estimation strategies. mutation rates estimated, fraction news feature sample estimated. approach utilized MLE using L-BFGS-B algorithm implemented stats::optim. assumed likelihood function derived Poisson mixture model rates adjusted according feature's empirical U-content (average number Us present sequencing reads mapping feature particular sample). Fraction new estimates converted degradation rate constant estimates using solution simple ordinary differential equation model RNA metabolism. fraction new kdegs estimated, uncertainty parameters estimated using Fisher Information. limit large datasets, variance MLE inversely proportional Fisher Information evaluated MLE. Mixture models typically singular, meaning Fisher information matrix positive definite asymptotic results variance necessarily hold. mutation rates estimated priori fixed > 0, problems eliminated. addition, assessing uncertainty replicate fraction new estimates, size dataset raw number sequencing reads map particular feature. number often large (>100) increases validity invoking asymptotics. version 1.0.0, users can opt alternative uncertainty estimation strategy setting Fisher FALSE. strategy makes use standard error estimator binomial random variables rate success parameter. can uniquely identify new old reads, variance estimate fraction reads new fn*(1-fn)/n. uncertainty estimate typically underestimate fraction new replicate uncertainties. showed bakR paper though Fisher information strategy often significantly overestimates uncertainties low coverage extreme fraction new features. Therefore, bullish, underconservative uncertainty quantification can useful datasets low mutation rates, extreme label times, low sequecning depth. found false discovery rates still well controlled using alternative uncertainty quantification strategy. kdegs uncertainties estimated, replicate estimates pooled regularized. two key steps downstream analysis. 1st, uncertainty feature used fit linear ln(uncertainty) vs. log10(read depth) trend, uncertainties individual features shrunk towards regression line. uncertainty feature combination Fisher Information asymptotic uncertainty well amount variability seen estimates. Regularization uncertainty estimates performed using analytic results Normal distribution likelihood known mean unknown variance conjugate priors. prior parameters estimated regression amount variability regression line. strength regularization can tuned adjusting prior_weight parameter, larger numbers yielding stronger shrinkage towards regression line. 2nd step regularize average kdeg estimates. done using analytic results Normal distribution likelihood model unknown mean known variance conjugate priors. prior parameters estimated population wide kdeg distribution (using mean standard deviation mean standard deviation normal prior). 1st step, known mean assumed average kdeg, averaged across replicates weighted number reads mapping feature replicate. 2nd step, known variance assumed obtained following regularization uncertainty estimates. Effect sizes (changes kdeg) obtained difference log(kdeg) means reference experimental sample(s), log(kdeg)s assumed independent variance effect size sum log(kdeg) variances. P-values assessing significance effect size obtained using moderated t-test number degrees freedom determined uncertainty regression hyperparameters adjusted multiple testing using Benjamini- Hochberg procedure control false discovery rates (FDRs). cases, assumed ODE model RNA metabolism accurately model dynamics biological system analyzed. cases, best compare logit(fraction new)s directly rather converting fraction new log(kdeg). analysis strategy implemented NSS set TRUE. Comparing logit(fraction new) valid single metabolic label time used samples. example, label time 1 hour used NR-seq data WT cells 2 hour label time used KO cells, comparison longer valid differences logit(fraction new) stem differences kinetics label times.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fast_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Efficiently analyze nucleotide recoding data — fast_analysis","text":"","code":"# \\donttest{  # Simulate small dataset sim <- Simulate_bakRData(300, nreps = 2)  # Fit fast model to get fast_df Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0500 0.000990 #> 2     1     2 0.0499 0.000990 #> 3     2     1 0.0498 0.000990 #> 4     2     2 0.0497 0.000990 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Fit fast model with fast_analysis Fast_Fit <- fast_analysis(Fit$Data_lists$Fast_df) #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew     pold #>   <int> <dbl>  <dbl>    <dbl> #> 1     1     1 0.0500 0.000990 #> 2     1     2 0.0499 0.000990 #> 3     2     1 0.0498 0.000990 #> 4     2     2 0.0497 0.000990 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps. # }"},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Curate data in bakRFnData object for statistical modeling — fn_process","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"fn_process creates data structures necessary analyze nucleotide recoding RNA-seq data MLE Hybrid implementations bakRFit. input fn_process must object class bakRFnData.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"","code":"fn_process(   obj,   totcut = 50,   totcut_all = 10,   Chase = FALSE,   FOI = c(),   concat = TRUE )"},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"obj object class bakRFnData totcut Numeric; transcripts less number sequencing reads replicate experimental conditions filtered totcut_all Numeric; transcripts less number sequencing reads sample filtered Chase Boolean; TRUE, pulse-chase analysis strategy implemented FOI Features interest; character vector containing names features analyze. FOI non-null concat TRUE, minimally reliable FOIs combined reliable features passing set filters (totcut totcut_all). concat FALSE, minimally reliable FOIs kept. minimally reliable FOI one passes filtering minimally stringent parameters. concat Boolean; TRUE, FOI concatenated output reliableFeatures","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"returns list objects can passed TL_stan /fast_analysis. objects : Stan_data; list can passed TL_stan Hybrid_Fit = TRUE. Consists metadata well data Stan analyze. Data analyzed consists equal length vectors. contents Stan_data : NE; Number datapoints 'Stan' analyze (NE = Number Elements) NF; Number features dataset TP; Numerical indicator s4U feed (0 = s4U feed, 1 = s4U fed) FE; Numerical indicator feature num_mut; Number U--C mutations observed particular set reads MT; Numerical indicator experimental condition (Exp_ID metadf) nMT; Number experimental conditions R; Numerical indicator replicate nrep; Number replicates (maximum across experimental conditions) nrep_vect; Vector number replicates experimental condition tl; Vector label times experimental condition Avg_Reads; Standardized log10(average read counts) particular feature particular condition, averaged replicates sdf; Dataframe maps numerical feature ID original feature name. Also read depth information sample_lookup; Lookup table relating MT R original sample name Fn_est; data frame containing fraction new estimates +s4U samples: sample; Original sample name XF; Original feature name fn; Fraction new estimate n; Number reads Feature_ID; Numerical ID feature Replicate; Numerical ID replicate Exp_ID; Numerical ID experimental condition tl; s4U label time logit_fn; logit fraction new estimate kdeg; degradation rate constant estimate log_kdeg; log degradation rate constant estimate logit_fn_se; Uncertainty logit(fraction new) estimate log_kd_se; Uncertainty log(kdeg) estimate Count_Matrix; matrix read count information. column represents sample row represents feature. entry raw number read counts mapping particular feature particular sample. Column names corresponding sample names row names corresponding feature names. Ctl_data; Identical content Fn_est -s4U data (thus fn estimates set 0). NULL -s4U data present","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"fn_process first filters features less totcut reads sample. creates necessary data structures analysis bakRFit visualization functions (namely plotMA). 1st step executed fn_process find names features deemed \"reliable\". reliable feature one sufficient read coverage every single sample (.e., > totcut_all reads samples) sufficient read coverage replicates least one experimental condition (.e., > totcut reads replicates one experimental conditions). done call reliableFeatures. 2nd step extract reliableFeatures fns dataframe bakRFnData object. process, numerical ID given reliableFeature, numerical ID corresponding order arranged using dplyr::arrange. 3rd step prepare data structures can passed fast_analysis TL_stan (usually accessed via bakRFit helper function).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fn_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Curate data in bakRFnData object for statistical modeling — fn_process","text":"","code":"# \\donttest{  # Load cB data(\"cB_small\")  # Load metadf data(\"metadf\")  # Create bakRData bakRData <- bakRData(cB_small, metadf)  # Preprocess data data_for_bakR <- cBprocess(obj = bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... # }"},{"path":"https://simonlabcode.github.io/bakR/reference/fns.html","id":null,"dir":"Reference","previous_headings":"","what":"Example fraction news (fns) data frame — fns","title":"Example fraction news (fns) data frame — fns","text":"Subset fraction new estimates dataset published Luo et al. (2020). Fraction new estimates, uncertainties, read counts included 300 genes keep file size small.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example fraction news (fns) data frame — fns","text":"","code":"data(fns)"},{"path":"https://simonlabcode.github.io/bakR/reference/fns.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example fraction news (fns) data frame — fns","text":"dataframe 1,800 rows 5 variables. Input bakRFndata sample Sample name XF Name feature (e.g., ENSEMBL gene ID) fn Estimate fraction reads feature new se Uncertainty fraction new estimate (optional bakRFnData) n Number sequencing reads","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fns.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Example fraction news (fns) data frame — fns","text":"Luo et al. (2020) Biochemistry. 59(42), 4121-4142","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/fns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example fraction news (fns) data frame — fns","text":"","code":"data(fns) data(metadf) bakRFndataobj <- bakRFnData(fns, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/metadf.html","id":null,"dir":"Reference","previous_headings":"","what":"Example meatdf data frame — metadf","title":"Example meatdf data frame — metadf","text":"metadf dataframe describing data present cB file can loaded data(cB_small). contents discussed great detail Getting_started vignette.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/metadf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example meatdf data frame — metadf","text":"","code":"data(metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/metadf.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example meatdf data frame — metadf","text":"dataframe 6 rows 2 variables: row names samples corresponding cB tl time s4U labeling, hours Exp_ID numerical ID reference experimental conditions; 1 reference 2 single experimental condition","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/metadf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example meatdf data frame — metadf","text":"","code":"data(cB_small) data(metadf) bakRdat <- bakRData(cB_small, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakRData object constructor for internal use — new_bakRData","title":"bakRData object constructor for internal use — new_bakRData","text":"function efficiently creates object class bakRData without performing rigorous checks","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakRData object constructor for internal use — new_bakRData","text":"","code":"new_bakRData(cB, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakRData object constructor for internal use — new_bakRData","text":"cB Dataframe columns corresponding feature ID, number Ts, number mutations, sample ID, number identical observations metadf Dataframe detailing s4U label time experimental ID sample","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRFnData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakRFnData object constructor for internal use — new_bakRFnData","title":"bakRFnData object constructor for internal use — new_bakRFnData","text":"function efficiently creates object class bakRFnData without performing rigorous checks","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRFnData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakRFnData object constructor for internal use — new_bakRFnData","text":"","code":"new_bakRFnData(fns, metadf)"},{"path":"https://simonlabcode.github.io/bakR/reference/new_bakRFnData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakRFnData object constructor for internal use — new_bakRFnData","text":"fns Dataframe columns corresponding sample names (sample), feature IDs (XF), fraction new estimates (fn), number sequencing reads (nreads) metadf Dataframe detailing s4U label time experimental ID sample","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","title":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","text":"function outputs L2FC(kdeg) MA plot. Plots colored according statistical significance sign L2FC(kdeg)","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","text":"","code":"plotMA(   obj,   Model = c(\"MLE\", \"Hybrid\", \"MCMC\"),   FDR = 0.05,   Exps = 2,   Exp_shape = FALSE )"},{"path":"https://simonlabcode.github.io/bakR/reference/plotMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","text":"obj Object class bakRFit outputted bakRFit function Model String identifying implementation want generate MA plot FDR False discovery rate control significance assessment Exps Vector Experimental IDs include plot; must contain elements within 2:(# experimental IDs). NULL, data Experimental IDs plotted. Exp_shape Logical indicating whether use Experimental ID factor determining point shape volcano plot","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","text":"ggplot object. point represents transcript. x-axis log-10 transformed replicate average read counts, y-axis log-2 fold-change degradation rate constant.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotMA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creating L2FC(kdeg) MA plot from fit objects — plotMA","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates sim <- Simulate_bakRData(500, nreps = 2)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0499 0.00101 #> 2     1     2 0.0498 0.00101 #> 3     2     1 0.0500 0.00101 #> 4     2     2 0.0500 0.00101 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Volcano plot plotMA(Fit, Model = \"MLE\")   # }"},{"path":"https://simonlabcode.github.io/bakR/reference/plotVolcano.html","id":null,"dir":"Reference","previous_headings":"","what":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","title":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","text":"function creates L2FC(kdeg) volcano plot. Plots colored according statistical significance sign L2FC(kdeg).","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotVolcano.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","text":"","code":"plotVolcano(obj, FDR = 0.05, Exps = 2, Exp_shape = FALSE)"},{"path":"https://simonlabcode.github.io/bakR/reference/plotVolcano.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","text":"obj Object contained within output bakRFit. , either Fast_Fit (MLE implementation fit), Stan_Fit (MCMC implementation fit), Hybrid_Fit (Hybrid implementation fit) FDR False discovery rate control significance assessment Exps Vector Experimental IDs include plot; must contain elements within 2:(# experimental IDs). NULL, data Experimental IDs plotted. Exp_shape Logical indicating whether use Experimental ID factor determining point shape volcano plot","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotVolcano.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","text":"ggplot object. point represents transcript. x-axis log-2 fold change degradation rate constant y-axis log-10 transformed multiple test adjusted p value.","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/plotVolcano.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creating L2FC(kdeg) volcano plot from fit objects — plotVolcano","text":"","code":"# \\donttest{ # Simulate data for 500 genes and 2 replicates sim <- Simulate_bakRData(500, nreps = 2)  # Fit data with fast implementation Fit <- bakRFit(sim$bakRData) #> Finding reliable Features #> Filtering out unwanted or unreliable features #> Processing data... #> Estimating pnew with likelihood maximization #> Estimating unlabeled mutation rate with -s4U data #> Estimated pnews and polds for each sample are: #> # A tibble: 4 × 4 #> # Groups:   mut [2] #>     mut  reps   pnew    pold #>   <int> <dbl>  <dbl>   <dbl> #> 1     1     1 0.0500 0.00100 #> 2     1     2 0.0496 0.00100 #> 3     2     1 0.0498 0.00100 #> 4     2     2 0.0497 0.00100 #> Estimating fraction labeled #> Estimating per replicate uncertainties #> Estimating read count-variance relationship #> Averaging replicate data and regularizing estimates #> Assessing statistical significance #> All done! Run QC_checks() on your bakRFit object to assess the  #>             quality of your data and get recommendations for next steps.  # Volcano plot plotVolcano(Fit$Fast_Fit)   # }"},{"path":"https://simonlabcode.github.io/bakR/reference/reliableFeatures.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","title":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","text":"function identifies features (e.g., transcripts, exons, etc.) mutation rate set threshold control (-s4U) sample reads set threshold samples. -s4U sample, read count cutoff considered. Additional filtering options relevant working short RNA-seq read data. includes filtering features extremely low empirical U-content (.e., average number Us sequencing reads feature) reads least 3 Us .","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/reliableFeatures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","text":"","code":"reliableFeatures(   obj,   high_p = 0.2,   totcut = 50,   totcut_all = 10,   Ucut = 0.25,   AvgU = 4 )"},{"path":"https://simonlabcode.github.io/bakR/reference/reliableFeatures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","text":"obj Object class bakRData high_p highest mutation rate accepted control samples totcut Numeric; transcripts less number sequencing reads replicate experimental conditions filtered totcut_all Numeric; transcripts less number sequencing reads sample filtered Ucut Must fraction reads 2 less Us less cutoff samples AvgU Must average number Us greater ","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/reliableFeatures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","text":"vector gene names passed reliability filter","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/reliableFeatures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify features (e.g., transcripts) with high quality data — reliableFeatures","text":"","code":"# \\donttest{  # Load cB data(\"cB_small\")  # Load metadf data(\"metadf\")  # Create bakRData bakRData <- bakRData(cB_small, metadf)  # Find reliable features features_to_keep <- reliableFeatures(obj = bakRData) # }"},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakR Data object validator — validate_bakRData","title":"bakR Data object validator — validate_bakRData","text":"functions ensures input bakRData object construction valid","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakR Data object validator — validate_bakRData","text":"","code":"validate_bakRData(obj)"},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakR Data object validator — validate_bakRData","text":"obj object class bakRData","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRFnData.html","id":null,"dir":"Reference","previous_headings":"","what":"bakRFnData object validator — validate_bakRFnData","title":"bakRFnData object validator — validate_bakRFnData","text":"functions ensures input bakRFnData object construction valid","code":""},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRFnData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bakRFnData object validator — validate_bakRFnData","text":"","code":"validate_bakRFnData(obj)"},{"path":"https://simonlabcode.github.io/bakR/reference/validate_bakRFnData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bakRFnData object validator — validate_bakRFnData","text":"obj object class bakRFnData","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-100","dir":"Changelog","previous_headings":"","what":"bakR 1.0.0","title":"bakR 1.0.0","text":"Functions visualizing (VisualizeDropout), quantifying (QuantifyDropout), correcting (CorrectDropout) metabolic label-induced dropout RNA library preparation added. New simulation function (simulate_relative_bakRData) better captures relative nature RNA-seq can accurately simulate dropout. New experimental function (DissectMechanism) determining likely observed differential expression driven transcriptional post-transcriptional regulation. DissectMechanism rewrite extension previously developed NSSHeat2 function, improvement now deprecated NSSHeat. Can now provide fraction new estimates (e.g., tool like GRAND-SLAM) input bakR. GRAND-SLAM input functionality supported new GSprocess function facilitate converting GRAND-SLAM output bakR input. FnPCA deprecated favor FnPCA2 accepts input differently fixes bugs. Read count filtering now includes two filters. One read count samples must pass, one replicates single Exp_ID need pass. facilitates identifying large increases decreaes expression. Several new vignettes discuss much new functionality discussed . Several small bug fixes","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-044","dir":"Changelog","previous_headings":"","what":"bakR 0.4.4","title":"bakR 0.4.4","text":"Small edit configuration files address compilation issues can arise systems. Deals “file big” errors” package installation source.","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-043","dir":"Changelog","previous_headings":"","what":"bakR 0.4.3","title":"bakR 0.4.3","text":"Implemented long read sequencing data analysis strategy. Run bakRFit() Long = TRUE use k-means clustering (k = 2) mutation rate fraction new estimation. Need Ckmeans.1d.dp package installed (installed bakR installation).","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-042","dir":"Changelog","previous_headings":"","what":"bakR 0.4.2","title":"bakR 0.4.2","text":"Fixed bug reliableFeatures. high_p supposed maximum allowable mutation rate (# mutations/# Ts) reads -s4U controls, instead maximum allowable average number T--C mutations reads controls.","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-041","dir":"Changelog","previous_headings":"","what":"bakR 0.4.1","title":"bakR 0.4.1","text":"Fixed bug cBprocess didn’t properly check features interest provided FOI argument valid.","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-040","dir":"Changelog","previous_headings":"","what":"bakR 0.4.0","title":"bakR 0.4.0","text":"CRAN release: 2023-03-14 Added QC_check(), function perform quality control analysis bakRFit objects. Looks problems data impair bakR’s performance, generates number diagnostic visualizations, makes suggestions next. Fixed plot coloring bug plotMA() plotVolcano(). Fixed bug led problems number -s4U replicates > +s4U replicates one Exp_IDs Implemented improved U-content adjustment MCMC implementation. Also impacts accuracy StanRateEst = TRUE mutation rate estimation strategy. Increased default number features use StanRateEst mutation rate estimation strategy. Improved scaling NSSHeat() output matrix columns. Created new function NSSHeat2() implements different mechanism scoring function NSSHeat().","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-030","dir":"Changelog","previous_headings":"","what":"bakR 0.3.0","title":"bakR 0.3.0","text":"Optimized data preprocessing data.table Increased simulation flexibility Added edge case error catching","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-025","dir":"Changelog","previous_headings":"","what":"bakR 0.2.5","title":"bakR 0.2.5","text":"Added checks bakRData validator Fixed bug NSSHeatmap prevented adjusting padj cutoff","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-024","dir":"Changelog","previous_headings":"","what":"bakR 0.2.4","title":"bakR 0.2.4","text":"CRAN release: 2022-10-10 Addressed NOTEs prepare CRAN submission Removed previously deprecated function sim_bakRData()","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-023","dir":"Changelog","previous_headings":"","what":"bakR 0.2.3","title":"bakR 0.2.3","text":"Expanded discussion NSS analysis vignette","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-022","dir":"Changelog","previous_headings":"","what":"bakR 0.2.2","title":"bakR 0.2.2","text":"Fixed non-steady-state (NSS) uncertainty quantification Fixed uncertainty quantification pulse-chase analysis Fixed fraction new estimation pulse-chase analysis","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-021","dir":"Changelog","previous_headings":"","what":"bakR 0.2.1","title":"bakR 0.2.1","text":"Added pulse-chase analysis option","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-020","dir":"Changelog","previous_headings":"","what":"bakR 0.2.0","title":"bakR 0.2.0","text":"Improved default mutation rate estimation strategy Updated vignettes added back non-steady state analysis strategy discussion Better commenting fast_analysis (instead opting refactorization)","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-011","dir":"Changelog","previous_headings":"","what":"bakR 0.1.1","title":"bakR 0.1.1","text":"Changed ordering vignettes website Got rid unnecessary stan models functions Fixed TL_stan output documentation Corrected missing namespace issues","code":""},{"path":"https://simonlabcode.github.io/bakR/news/index.html","id":"bakr-010","dir":"Changelog","previous_headings":"","what":"bakR 0.1.0","title":"bakR 0.1.0","text":"Made bakR public","code":""}]
